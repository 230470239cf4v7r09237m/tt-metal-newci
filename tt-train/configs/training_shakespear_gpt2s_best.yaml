training_config:
  project_name: "tt_train_nano_gpt"
# model_path: "nano_gpt"
  seed: 5489
  model_save_interval: 100
  batch_size: 4
  num_epochs: 300
  max_steps: 5000
  learning_rate: 0.0003
  weight_decay: 0.01
  use_kahan_summation: false
  gradient_accumulation_steps: 16

  transformer_config:
    num_heads: 12
    embedding_dim: 768
    dropout_prob: 0.0
    num_blocks: 12
    vocab_size: 96
    max_sequence_length: 1024
    experimental:
      use_composite_layernorm: false

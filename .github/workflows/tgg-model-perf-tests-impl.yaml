name: "[internal] TGG model perf tests impl"

on:
  workflow_call:

jobs:
  tgg-model-perf-tests:
    strategy:
      fail-fast: false
      matrix:
        test-group: [
          # {
          #   name: "TGG LLM model perf tests",
          #   model-type: "LLM",
          #   arch: wormhole_b0,
          #   runs-on: ["arch-wormhole_b0", "config-tgg", "in-service", "bare-metal", "pipeline-perf"],
          #   cmd: './tests/scripts/run_tests.sh --tt-arch wormhole_b0 --pipeline-type llm_model_perf_tgg_device --dispatch-mode ""'
          # },
          {
            name: "TGG CNN model perf tests",
            model-type: "CNN",
            arch: wormhole_b0,
            runs-on: ["arch-wormhole_b0", "config-tgg", "in-service", "bare-metal", "pipeline-perf"],
            cmd: './tests/scripts/run_tests.sh --tt-arch wormhole_b0 --pipeline-type cnn_model_perf_tgg_device --dispatch-mode ""'
          },
        ]
    name: ${{ matrix.test-group.name }}
    env:
      TT_METAL_ENV: ${{ vars.TT_METAL_ENV }}
      ARCH_NAME: ${{ matrix.test-group.arch }}
      LOGURU_LEVEL: INFO
      LD_LIBRARY_PATH: ${{ github.workspace }}/build/lib
    runs-on: ${{ matrix.test-group.runs-on }}
    steps:
      - uses: tenstorrent-metal/metal-workflows/.github/actions/checkout-with-submodule-lfs@v2.0.0
      - name: Enable performance mode
        run: |
          sudo cpupower frequency-set -g performance
      - uses: ./.github/actions/ensure-active-weka-mount
      - name: Set up dynamic env vars for build
        run: |
          echo "TT_METAL_HOME=$(pwd)" >> $GITHUB_ENV
          echo "PYTHONPATH=$(pwd)" >> $GITHUB_ENV
      - uses: actions/download-artifact@v4
        with:
          name: TTMetal_build_${{ matrix.test-group.arch }}
      - name: Extract files
        run: tar -xvf ttm_${{ matrix.test-group.arch }}.tar
      - uses: ./.github/actions/install-python-deps
      - name: Run model perf regression tests
        timeout-minutes: 60
        run: |
          source ${{ github.workspace }}/python_env/bin/activate
          cd $TT_METAL_HOME
          export PYTHONPATH=$TT_METAL_HOME
          exit 1
          ${{ matrix.test-group.cmd }}
      - name: Bisect failure (if previous step failed)
        if: failure()
        uses: ./.github/actions/bisect
        with:
          cmd: |
            source ${{ github.workspace }}/python_env/bin/activate
            cd $TT_METAL_HOME
            export PYTHONPATH=$TT_METAL_HOME
            ${{ matrix.test-group.cmd }}

      #- name: Get Recent Passing Commit (if previous step failed)
      #  if: failure()
      #  id: get-passing-commit
      #  shell: bash
      #  run: |
      #    set -euo pipefail
      #    workflow_ref="${{ github.workflow_ref}}"
      #    workflow_filename=$(basename "${workflow_ref%%@*}")

      #    # Get the last passing workflow run on the main branch
      #    # RESULTS=$(curl -s "https://api.github.com/repos/${{ github.repository }}/actions/workflows/${workflow_filename}/runs?branch=main&status=completed" )
      #    # echo "Results: $RESULTS"
      #    # SUCCESS_RESULTS=$(curl -s "https://api.github.com/repos/${{ github.repository }}/actions/workflows/${workflow_filename}/runs?branch=main&status=success" )
      #    # echo "Results: $SUCCESS_RESULTS"

      #    RUN_ID=$(curl -s "https://api.github.com/repos/${{ github.repository }}/actions/workflows/${workflow_filename}/runs?branch=main&status=success" \
      #      | jq -r '.workflow_runs[0].head_sha')
      #    if [ -z "$RUN_ID" ]; then
      #      echo "No passing run found on main."
      #      exit 1
      #    fi
      #    echo "Passing commit: $RUN_ID"
      #    echo "passed_commit=$RUN_ID" >> $GITHUB_ENV

      #- name: Start Git Bisect
      #  if: env.passed_commit
      #  run: |
      #    # Initialize git bisect
      #    git bisect start
      #    git bisect bad $GITHUB_SHA  # Current (failing) commit
      #    git bisect good ${{ env.passed_commit }}

      #    # Run the bisect process
      #    echo "TODO: run bisect"
      #    exit 1
      #    git bisect run bash -c "
      #      set -e
      #      source ${{ github.workspace }}/python_env/bin/activate
      #      cd \$TT_METAL_HOME
      #      export PYTHONPATH=\$TT_METAL_HOME
      #      ${{ matrix.test-group.cmd }}
      #    "

      - name: Check perf report exists
        id: check-perf-report
        if: ${{ !cancelled() }}
        run: |
          ls -hal
          export PERF_REPORT_FILENAME=Models_Perf_$(date +%Y_%m_%d).csv
          ls -hal $PERF_REPORT_FILENAME
          echo "perf_report_filename=$PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"
      - name: Upload perf report
        if: ${{ !cancelled() && steps.check-perf-report.conclusion == 'success' }}
        uses: actions/upload-artifact@v4
        with:
          name: perf-report-csv-${{ matrix.test-group.model-type }}-${{ matrix.test-group.arch }}-${{ matrix.test-group.machine-type }}
          path: "${{ steps.check-perf-report.outputs.perf_report_filename }}"
      - name: Disable performance mode
        if: always()
        run: |
          sudo cpupower frequency-set -g ondemand

name: Run perf regressions on models and output report

on:
  workflow_dispatch:
  push:
    branches: ["main", "rkim/perf-model-regs"]
  schedule:
    - cron: "0 2 * * *"

jobs:
  build-and-test-measure-perf:
    strategy:
      # Do not fail-fast because we need to ensure all tests go to completion
      # so we try not to get hanging machines
      fail-fast: false
      matrix:
        arch: [grayskull]
    env:
      TT_METAL_ENV: ${{ vars.TT_METAL_ENV }}
      ARCH_NAME: ${{ matrix.arch }}
    environment: dev
    runs-on: perf-${{ matrix.arch }}
    steps:
      - uses: actions/checkout@v3
        with:
          submodules: recursive
          token: ${{ secrets.CHECKOUT_TOKEN }}
          lfs: true
      - name: Set up dynamic env vars for build
        run: |
          echo "TT_METAL_HOME=$(pwd)" >> $GITHUB_ENV
          echo "PYTHONPATH=$(pwd)" >> $GITHUB_ENV
      - name: Build tt-metal and libs
        run: make build
      - name: Run performance regressions
        run: |
          source build/python_env/bin/activate
          python -m pip install -r tests/python_api_testing/requirements.txt
          ./tests/scripts/run_performance.sh
      - name: Check perf report exists
        id: check-perf-report
        run: |
          ls -hal
          export PERF_REPORT_FILENAME=Models_Perf_$(date +%Y_%m_%d).csv
          ls -hal $PERF_REPORT_FILENAME
          echo "perf_report_filename=$PERF_REPORT_FILENAME" >> "$GITHUB_OUTPUT"
      - name: Upload perf report
        uses: actions/upload-artifact@v3
        with:
          name: perf-report-csv
          path: "${{ steps.check-perf-report.outputs.perf_report_filename }}"

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33745436",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import math\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torch import nn, optim\n",
    "import argparse\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf02200",
   "metadata": {},
   "source": [
    "tt metal libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "172b5f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/farbabi/git/tt-metal\n"
     ]
    }
   ],
   "source": [
    "cd /home/farbabi/git/tt-metal/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b991ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, os\n",
    "from pathlib import Path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb5b83f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TT_METAL_ENV=dev\n",
      "env: TT_METAL_HOME=/home/farbabi/git/tt-metal\n"
     ]
    }
   ],
   "source": [
    "%env TT_METAL_ENV=dev\n",
    "%env TT_METAL_HOME=/home/farbabi/git/tt-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "679f6416",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"../../..\")\n",
    "sys.path.append(\"../../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e587127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/farbabi/git/tt-metal/tests/python_api_testing/models/synthetic_gradients', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/home/farbabi/git/tt-metal/build/python_env/lib/python3.8/site-packages', '/home/farbabi/git/tt-metal/libs', '../..', '../../..', '../../../..']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e5ddc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/farbabi/git/tt-metal'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94148e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "cddf81e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs import tt_lib as ttl\n",
    "from tests.python_api_testing.models.utility_functions import tilize_to_list, untilize, comp_allclose_and_pcc\n",
    "from libs.tt_lib.utils import pad_activation, pad_weight, tt2torch, tt2torch_rm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eebb92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                 Device\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | SOC descriptors loaded /home/farbabi/git/tt-metal/tt_metal/device/grayskull_120_arch.yaml\n",
      "\u001b[38;2;000;128;000m                 Device\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Network descriptor loaded \n",
      "Device reservations file does not exist at /tmp/tenstorrent/tt_device_reservations.yaml, using 13 detected devices set \n",
      "\u001b[0mDetected 13 PCI devices\n",
      "\u001b[0mOpening TT_PCI_INTERFACE_ID 0 for netlist target_device_id: 0\n",
      "\u001b[0mPCIEIntfId   0x0\n",
      "\u001b[0mVID:DID      0x1e52:0xfaca\n",
      "\u001b[0mSubVID:SubID 0x1e52:0x3\n",
      "\u001b[0mBSF          41:0:0\n",
      "\u001b[0mBAR          0x20000000000  size: 48MB\n",
      "\u001b[0mHARVESTING DISABLED = 0x0 (memory: 0x0 logic: 0x0)\n",
      "\u001b[0mHARVESTING DISABLED = 0x0 (memory: 0x0 logic: 0x0)\n",
      "\u001b[0mDisable PCIE DMA\n",
      "\u001b[0m\u001b[38;2;000;128;000m              LLRuntime\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | AI CLK for device 0 is:   1202 MHz\n"
     ]
    }
   ],
   "source": [
    "device = ttl.device.CreateDevice(ttl.device.Arch.GRAYSKULL, 0)\n",
    "ttl.device.InitializeDevice(device)\n",
    "host = ttl.device.GetHost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "064cc389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/farbabi/git/tt-metal'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2fb850a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.20.3\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dbc5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.1307,), (0.3081,)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e47da902",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be23960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7daa7779",
   "metadata": {},
   "outputs": [],
   "source": [
    "#device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43f9a032",
   "metadata": {},
   "outputs": [],
   "source": [
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac4e4cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "test_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                   'pin_memory': True\n",
    "                   }\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c3dbc7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainset = datasets.MNIST('tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TRAINSET', download=True, train=True, transform=transform)\n",
    "testset = datasets.MNIST('tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TESTSET', download=True, train=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, **train_kwargs)\n",
    "testloader = torch.utils.data.DataLoader(testset, **test_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810f42dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cd55f2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e634cca3",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6604cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cea6eb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "figure = plt.figure()\n",
    "num_of_images = 60\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d14b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca0375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_criterion = nn.MSELoss(reduction = 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c0e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_size = 256\n",
    "hidden_size_syn = 1024\n",
    "output_size = 10\n",
    "learning_rate = 3e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d126db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization(model, learning_rate = learning_rate):\n",
    "    optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e5691",
   "metadata": {},
   "source": [
    "# Adding Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe885954",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(network, self).__init__()\n",
    "        \n",
    "        self.layer = nn.Sequential(nn.Linear(input_dim, output_dim),\n",
    "                                   nn.BatchNorm1d(output_dim),\n",
    "                                   nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046bc313",
   "metadata": {},
   "outputs": [],
   "source": [
    "class syn_network(nn.Module):\n",
    "    def __init__(self, hidden_dim, syn_hid_dim = 1024):\n",
    "        super(syn_network, self).__init__()\n",
    "\n",
    "        # dni network\n",
    "        self.layer = nn.Sequential(nn.Linear(hidden_dim, syn_hid_dim),\n",
    "           nn.BatchNorm1d(syn_hid_dim),\n",
    "           nn.ReLU(),\n",
    "           nn.Linear(syn_hid_dim, syn_hid_dim),\n",
    "           nn.BatchNorm1d(syn_hid_dim),\n",
    "           nn.ReLU(),\n",
    "           nn.Linear(syn_hid_dim, hidden_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd9cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization(model, learning_rate = learning_rate):\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        m.weight.data.fill_(0.0)\n",
    "        m.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193da3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hook():\n",
    "    def __init__(self, module, backward = False):\n",
    "        if backward == False:\n",
    "            self.hook = module.register_forward_hook(self.hook_activations)\n",
    "        else:\n",
    "            self.hook = module.register_full_backward_hook(self.hook_gradients)\n",
    "            \n",
    "    def hook_activations(self, module, inputs, outputs):\n",
    "        self.outputs = outputs\n",
    "        \n",
    "    def hook_gradients(self, module, grad_input, grad_output):\n",
    "        self.grad_output = grad_output\n",
    "        \n",
    "    def hook_close(self):\n",
    "        self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fac864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_syn(model_syn, sg_criterion, g_pred, z, optimizer_syn):\n",
    "    model_syn.train()\n",
    "    optimizer_syn.zero_grad()\n",
    "    loss = sg_criterion(g_pred, z.clone().detach())\n",
    "    loss.backward()\n",
    "    optimizer_syn.step()\n",
    "    model_syn.eval()\n",
    "    return model_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5267150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_update_syntarget(h, model_layer, model_syn, hook_gradients_i, pre_sg = False):\n",
    "    g_sg = model_syn(h.clone().detach())\n",
    "    h.backward(g_sg.clone().detach())\n",
    "    z_pre = None\n",
    "    if pre_sg:\n",
    "        grad_ln = hook_gradients_i.grad_output[0]\n",
    "        z_pre = torch.matmul(grad_ln.detach().clone(), model_layer[0].weight.clone().detach())\n",
    "    return g_sg, z_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c9dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(models, device, testloader, epoch, results):\n",
    "    print_threshold = 1\n",
    "    store_threshold = 1\n",
    "    model_test = nn.Sequential(models[0].layer, models[1].layer, models[2].layer, \n",
    "                               models[3].layer, models[4].layer, models[5].layer)\n",
    "    model_test.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, target in testloader:\n",
    "            images, target = images.to(device), target.to(device)\n",
    "            images = images.view(images.shape[0], -1)\n",
    "            if images.shape[0] != 256:\n",
    "                    continue\n",
    "            output = model_test(images)\n",
    "            test_loss = torch.nn.functional.nll_loss(output, target, reduction = 'sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss/= len(testloader.dataset)\n",
    "\n",
    "    for i in [round(test_loss,6), round(100.0*correct/len(testloader.dataset),4), round(100-100. * correct / len(testloader.dataset),4)]:\n",
    "        results.append(str(i))\n",
    "\n",
    "    if print_threshold != False:\n",
    "        if epoch % print_threshold == 0:\n",
    "            print(\"Test loss: {:.6f} | Test Accuracy: {}/{} ({:.4f}%)\\n\".format(\n",
    "            test_loss, correct, len(testloader.dataset),\n",
    "            100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8848958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(models, syn_models, device, trainloader, optimizers, optimizers_syn, criterion, sg_criterion, epoch, hook_gradients, results):\n",
    "\n",
    "    print_threshold = 1\n",
    "    store_threshold = 1\n",
    "    eps = 1e-5\n",
    "    training_loss = 0\n",
    "        \n",
    "    for module in models:\n",
    "        module.train()\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(trainloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        if images.shape[0] != 256:\n",
    "                continue\n",
    "\n",
    "        # Training pass\n",
    "        for opt in optimizers:\n",
    "            opt.zero_grad()\n",
    "\n",
    "        # feed forward layer0 and update by g_sg\n",
    "        h0 = models[0].layer(images)\n",
    "        g_sg0, _ = backward_update_syntarget(h0, models[0].layer, syn_models[0].layer, hook_gradients[0], pre_sg = False)\n",
    "        optimizers[0].step()\n",
    "        #####\n",
    "        \n",
    "        # feed forward layer1 and update by g_sg\n",
    "        h1 = models[1].layer(h0.clone().detach().requires_grad_(True))\n",
    "        g_sg1, z0 = backward_update_syntarget(h1, models[1].layer, syn_models[1].layer, hook_gradients[1], pre_sg = True)\n",
    "        optimizers[1].step()\n",
    "        # train previous layer synthetic model\n",
    "        syn_models[0].layer = training_syn(syn_models[0].layer, sg_criterion, g_sg0, z0, optimizers_syn[0])\n",
    "        #####\n",
    "        \n",
    "        # feed forward layer2 and update by g_sg\n",
    "        h2 = models[2].layer(h1.clone().detach().requires_grad_(True))\n",
    "        g_sg2, z1 = backward_update_syntarget(h2, models[2].layer, syn_models[2].layer, hook_gradients[2], pre_sg = True)\n",
    "        optimizers[2].step()\n",
    "        # train previous layer synthetic model\n",
    "        syn_models[1].layer = training_syn(syn_models[1].layer, sg_criterion, g_sg1, z1, optimizers_syn[1])\n",
    "        #####\n",
    "        \n",
    "        # feed forward layer3 and update by g_sg\n",
    "        h3 = models[3].layer(h2.clone().detach().requires_grad_(True))\n",
    "        g_sg3, z2 = backward_update_syntarget(h3, models[3].layer, syn_models[3].layer, hook_gradients[3], pre_sg = True)\n",
    "        optimizers[3].step()\n",
    "        # train previous layer synthetic model\n",
    "        syn_models[2].layer = training_syn(syn_models[2].layer, sg_criterion, g_sg2, z2, optimizers_syn[2])\n",
    "        #####\n",
    "        \n",
    "        # feed forward layer4 and update by g_sg\n",
    "        h4 = models[4].layer(h3.clone().detach().requires_grad_(True))\n",
    "        g_sg4, z3 = backward_update_syntarget(h4, models[4].layer, syn_models[4].layer, hook_gradients[4], pre_sg = True)\n",
    "        optimizers[4].step()\n",
    "        # train previous layer synthetic model\n",
    "        syn_models[3].layer = training_syn(syn_models[3].layer, sg_criterion, g_sg3, z3, optimizers_syn[3])\n",
    "        #####\n",
    "\n",
    "        # feed forward layer 5 and backprop / update layer 5\n",
    "        h5 = models[5].layer(h4.clone().detach().requires_grad_(True))\n",
    "        loss = criterion(h5, labels)\n",
    "        loss.backward()\n",
    "        grad_ln5 = hook_gradients[5].grad_output[0]\n",
    "        z4 = torch.matmul(grad_ln5.detach().clone(), models[5].layer[0].weight.clone().detach())\n",
    "        optimizers[5].step()\n",
    "\n",
    "        syn_models[4].layer = training_syn(syn_models[4].layer, sg_criterion, g_sg4, z4, optimizers_syn[4])\n",
    "\n",
    "        training_loss += loss.item()\n",
    "        training_loss_norm = training_loss/len(trainloader)\n",
    "\n",
    "    for i in [epoch, round(training_loss_norm,6)]:\n",
    "        results.append(str(i))\n",
    "\n",
    "    if print_threshold != False:\n",
    "        if epoch % print_threshold == 0:\n",
    "            print(\"Epoch {} \\nTraining loss: {}\".format(epoch, training_loss_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1efe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    model_version = 'FC_FD_MNIST_V01'\n",
    "    print_threshold = 1\n",
    "    store_threshold = 1\n",
    "    if print_threshold != False:\n",
    "        print(time.asctime(), f' {model_version} execution started...')\n",
    "    input_size = 784\n",
    "    hidden_size = 256\n",
    "    hidden_size_syn = 1024\n",
    "    output_size = 10\n",
    "    batch_size = 256\n",
    "    epochs = 2000\n",
    "    \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    print('Device: ', device.type, '\\n')\n",
    "    \n",
    "    train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "    test_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                   'pin_memory': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "        \n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                              ])\n",
    "    trainset = datasets.MNIST('./PATH_TO_STORE_TRAINSET', download=True, train=True, transform=transform)\n",
    "    testset = datasets.MNIST('./PATH_TO_STORE_TESTSET', download=True, train=False, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, **train_kwargs)\n",
    "    testloader = torch.utils.data.DataLoader(testset, **test_kwargs)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    sg_criterion = nn.MSELoss(reduction = 'sum')\n",
    "    \n",
    "    syn_models, optimizers_fc, optimizers_syn = [], [], []\n",
    "    \n",
    "    # building models\n",
    "    fc_models = [network(input_size, hidden_size).to(device), network(hidden_size, hidden_size).to(device), \n",
    "             network(hidden_size, hidden_size).to(device), network(hidden_size, hidden_size).to(device),\n",
    "             network(hidden_size, hidden_size).to(device), network(hidden_size, output_size).to(device)]\n",
    "\n",
    "    for i in range(5):\n",
    "        syn_models.append(syn_network(hidden_size).to(device))\n",
    "        \n",
    "    for syn_model in syn_models:\n",
    "        syn_model.apply(init_weights)\n",
    "        \n",
    "    # setting optimizers    \n",
    "    for fc_model in fc_models:\n",
    "        optimizers_fc.append(optimization(fc_model))\n",
    "        \n",
    "    for syn_model in syn_models:\n",
    "        optimizers_syn.append(optimization(syn_model))\n",
    "    \n",
    "    # setting hooks\n",
    "    hook_gradients = [Hook(model.layer[0], backward = True) for model in fc_models]\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizers_fc[5], milestones=[3e5, 4e5], gamma = 0.1)\n",
    "\n",
    "    with open(f'./results_{model_version}.csv', 'w', newline='') as f:\n",
    "        f.write(\"epoch, training_loss, test_loss, test_accuracy, test_error, timestamp, run_time\\n\")\n",
    "\n",
    "    time0 = time.time()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        results = []\n",
    "        results_syn = []\n",
    "        train(fc_models, syn_models, device, trainloader, optimizers_fc, optimizers_syn, criterion, sg_criterion, epoch, hook_gradients, results)\n",
    "        test(fc_models, device, testloader, epoch, results)\n",
    "        scheduler.step()\n",
    "        if epoch % store_threshold == 0:\n",
    "            results.append(time.asctime())\n",
    "            results.append(round((time.time()-time0)/60, 6))\n",
    "            if epoch % store_threshold*1000 == 0:\n",
    "                fc_models_state = []\n",
    "                for module in fc_models:\n",
    "                    fc_models_state.append(module.state_dict())\n",
    "                syn_models_state = []\n",
    "                for module in syn_models:\n",
    "                    syn_models_state.append(module.state_dict())\n",
    "                torch.save(fc_models_state, f'./model_{model_version}.pt')\n",
    "                torch.save(syn_models_state, f'./model_syn_{model_version}.pt')\n",
    "            with open(f'./results_{model_version}.csv', 'a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(results)\n",
    "    if print_threshold != False:\n",
    "        print(\"\\nTraining Time (in minutes) =\",(time.time()-time0)/60, \"\\nEnd Time:\", time.asctime(), \"\\nEpochs:\", epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b027b01c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ef56a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_models = [network(input_size, hidden_size).to(device), network(hidden_size, hidden_size).to(device), \n",
    "         network(hidden_size, hidden_size).to(device), network(hidden_size, hidden_size).to(device),\n",
    "         network(hidden_size, hidden_size).to(device), network(hidden_size, output_size).to(device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9edc4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in fc_models:\n",
    "    module.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5edefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_models_state = []\n",
    "for module in fc_models:\n",
    "    fc_models_state.append(module.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06c92fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_models_state = []\n",
    "for module in syn_models:\n",
    "    syn_models_state.append(module.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4051d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_gradients = [Hook(model.layer[0], backward = True) for model in fc_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a52e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in fc_models:\n",
    "    print(i.layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47d09fd",
   "metadata": {},
   "source": [
    "### Testing Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0f063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_size = 256\n",
    "hidden_size_syn = 1024\n",
    "output_size = 10\n",
    "learning_rate = 3e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cbc00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375cbe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_criterion = nn.MSELoss(reduction = 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7888658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = network(784, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6549a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = network(256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4115e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = network(256, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model0, model1, model2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2343b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer0 = optimization(model0, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5139e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1 = optimization(model1, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77a8a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer2 = optimization(model2, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d1ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = [optimizer0, optimizer1, optimizer2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d984ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_syn0 = syn_network(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb498aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_syn1 = syn_network(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68623e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_syn2 = syn_network(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f8b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_models = [model_syn0, model_syn1, model_syn2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_syn0 = optimization(model_syn0, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cf40ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_syn1 = optimization(model_syn1, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea686418",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_syn2 = optimization(model_syn2, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e228b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers_syn = [optimizer_syn0, optimizer_syn1, optimizer_syn2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310750d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_syn0.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e99a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_syn1.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7888e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_syn2.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebeb385",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_gradients = [Hook(layer[0], backward = True) for layer in [model0.layer, model1.layer, model2.layer]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cccab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = dataiter.next()\n",
    "images = images.view(images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23abd5d",
   "metadata": {},
   "source": [
    "### With images as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4689fa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for opt in optimizers:\n",
    "    opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff1280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994292d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a141fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].layer[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d867f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = models[0].layer(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada1c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_gradients[1].grad_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce4b76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].layer[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b80ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_sg0 = model_syn0.layer(h0.clone().detach().requires_grad_(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce19f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_sg0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0ad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_sg0, _ = backward_update_syntarget(h0, models[0].layer, syn_models[0].layer, hook_gradients[0], pre_sg = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b239fd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g_sg0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e0f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers[0].step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d630744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_gradients[1].grad_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2a95ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = models[1].layer(h0.clone().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b5f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_sg1, z0 = backward_update_syntarget(h1, models[1].layer, syn_models[1].layer, hook_gradients[1], pre_sg = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab07d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers[1].step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f5a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_models[0].layer = training_syn(syn_models[0].layer, sg_criterion, g_sg0, z0, optimizers_syn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7932c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = models[2].layer(h1.clone().detach().requires_grad_(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9211eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(h2, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ae838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c5c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_ln2 = hook_gradients[2].grad_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9054af",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = torch.matmul(grad_ln2.detach().clone(), models[2].layer[0].weight.clone().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers[2].step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb03fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_models[1].layer = training_syn(syn_models[1].layer, sg_criterion, g_sg1, z1, optimizers_syn[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05015e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed forward layer 5 and backprop / update layer 5\n",
    "h5 = model.layer5(h4.clone().detach().requires_grad_(True))\n",
    "loss = criterion(h5, labels)\n",
    "loss.backward()\n",
    "grad_ln5 = hook_gradients[5].grad_output[0]\n",
    "z4 = torch.matmul(grad_ln5.detach().clone(), model.layer5[0].weight.clone().detach())\n",
    "optimizer5.step()\n",
    "\n",
    "model_syn4 = training_syn(model_syn4, sg_criterion, g_sg4, z4, optimizer_syn4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13a1e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_update_syntarget(h, model_layer, model_syn, hook_gradients_i, pre_sg = False):\n",
    "    g_sg = model_syn(h.clone().detach())\n",
    "    h.backward(g_sg.clone().detach())\n",
    "    z_pre = None\n",
    "    if pre_sg:\n",
    "        grad_ln = hook_gradients_i.grad_output[0]\n",
    "        z_pre = torch.matmul(grad_ln.detach().clone(), model_layer[0].weight.clone().detach())\n",
    "    return g_sg, z_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60170e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_syn0 = training_syn(syn_models[0], sg_criterion, g_sg0, z0, optimizer_syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396b8543",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # feed forward layer1 and update by g_sg\n",
    "        h1 = model.layer1(h0.clone().detach().requires_grad_(True))\n",
    "        z0, g_sg1 = backward_update_syntarget(h1, model.layer1, model_syn1, hook_gradients[1])\n",
    "        optimizer1.step()\n",
    "        \n",
    "        model_syn0 = training_syn(model_syn0, sg_criterion, g_sg0, z0, optimizer_syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1080378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h4.backward(g_sg4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e1ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5 = model.layer5(h4.clone().detach().requires_grad_(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "h6 = model.layer6(h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f435777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(h6, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7438504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b27c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layer4[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56458809",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb5 = hook_gradients[0].grad_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6055d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa8c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu5 = hook_activations[1].outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdd735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4347be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh5_dh4 = deriv_act_aft_pre(model.layer5[0].weight, mu5, h5, eps, model.layer5[1].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b6c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh5_dh4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c621de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu5 = mu5.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bf6bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight5 = model.layer5[0].weight.clone().detach(); weight5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34290884",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_out = h5.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21eb89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma5 = model.layer5[1].weight.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a2ca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layer5[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e346d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb90c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b21409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mu5.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c13741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a5905",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_mean = torch.mean(mu5, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1603fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a760b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_var = ((mu5 - batch_mean)**2).sum(dim = 0)/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c3d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_var = torch.var(mu5, dim = 0, unbiased = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7a89d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b822aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = (1 - 1/m) / torch.sqrt(mu_var + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3edc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "part1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198ac56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_out[h_out > 0.0] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e5a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea82bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b491d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c8a311",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e27f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean_var(x, mean, var, epoch):\n",
    "    mean = mean * (epoch -1)/epoch + torch.mean(x, dim = 0)/epoch #New average = old average * (n-1)/n + new value /n\n",
    "    var = var * (epoch -1)/epoch + torch.var(x, dim = 0, unbiased = False)/epoch\n",
    "    \n",
    "    return mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf29642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean, running_var = running_mean_var(mu5, batch_mean, batch_var, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd57d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_param = {'mode': 'train', 'eps': 1e-5, 'momentum': 0.1, 'running_mean': running_mean, 'running_var': running_var}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e893a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebee6180",
   "metadata": {},
   "outputs": [],
   "source": [
    "(h_out * gamma5 * part1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214c5a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c700abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(h_out * gamma5 * part1) * weight5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b1597",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul((h_out * gamma5 * part1) , weight5.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5489ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_t = nn.Linear(256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6330898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69bf69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_t = linear_t(h_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c62e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f707971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_t = linear_t.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddb9b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_t = linear_t.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d1dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8f2f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(h_out, weight_t.T) + bias_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde93ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b145fae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh5_dh4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1215bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "z4 = torch.mul(gb5, dh5_dh4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfbd0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_syn4 = training_syn(model_syn4, sg_criterion, h4, z4, optimizer_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c1650",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layer4[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc8801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_activations[0].outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c64679",
   "metadata": {},
   "source": [
    "### Manual from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b34cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = nn.Linear(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d2d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm1 = nn.BatchNorm1d(2, eps = 0, affine = False,track_running_stats = False, momentum = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd76d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear2 = nn.Linear(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b3eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_activations = [Hook(linear1), Hook(linear2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_gradients = [Hook(linear1, backward = True),Hook(linear2, backward = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a99a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1 = optim.SGD(nn.Sequential(linear1, batch_norm1).parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec61ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer2 = optim.SGD(linear2.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd11d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_a = optim.SGD(nn.Sequential(linear1, linear2).parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ac87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    linear1.weight[0] = torch.tensor([0.1, 0.2])\n",
    "    linear1.weight[1] = torch.tensor([0.3, 0.4])\n",
    "    linear1.bias[0] = 0.1\n",
    "    linear1.bias[1] = 0.3\n",
    "    linear2.weight[0] = torch.tensor([0.5, 0.6])\n",
    "    linear2.weight[1] = torch.tensor([0.7, 0.8])\n",
    "    linear2.bias[0] = 0.2\n",
    "    linear2.bias[1] = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13185a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c5caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e33926",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca23075",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[4., 0.5], [1., 3.]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b9cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20f84f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = linear1(x); mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89190650",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_activations[0].outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881c558",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = batch_norm1(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632e35b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer1.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bda5904",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu2 = linear2(h1.clone().detach())\n",
    "print(mu2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe922349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu2 = linear2(h1)\n",
    "# print(mu2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35692f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([[2.3, 1.0], [0.4, 0.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078f3cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f4826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(mu2, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34b9228",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acccefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad2_bw = hook_gradients[1].grad_output[0]\n",
    "print(grad2_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dh1 = torch.matmul(grad2_bw, linear2.weight)\n",
    "print(dL_dh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a4a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dw2 = torch.matmul(grad2_bw.T, h1)\n",
    "print(dL_dw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0558aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight update\n",
    "linear2_updated_w = linear2.weight - 0.1* dL_dw2\n",
    "print(linear2_updated_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b655112",
   "metadata": {},
   "source": [
    "#### finding dh1_dmu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42258495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mu = grad2_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef5487",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mu.shape[0]; m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f01b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_var = torch.sqrt(torch.var(mu, unbiased = False, axis = 0)); sqrt_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0387717",
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = (1-1/m)/sqrt_var; part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa369a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93de48b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigx = torch.sum(mu, axis = 0); sigx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cb5cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "part2a = 1/m - 2*sigx/(m**2); part2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5e2e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "part2b = mu - 1/m * (sigx); part2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad1d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "part2_top = torch.matmul(part2a, part2b); part2_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "part2 = part2_top/(2.0*torch.pow(torch.var(mu, unbiased = False, axis = 0), 1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57afcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082132dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh1_dmu1 = part1 - part2; dh1_dmu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca8a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dh1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde03af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dmu1 = torch.matmul(dL_dh1, dh1_dmu1); dL_dmu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3f2036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7385152f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef850cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac25968",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer2.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b31ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6e076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grad1_manual = dL_dh1 * dh1_dmu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47559e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.backward(grad1_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c6dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad1 to be calculated manually\n",
    "grad1_bw = hook_gradients[0].grad_output[0]\n",
    "print(grad1_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c98205",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dw1 = torch.matmul(grad1_bw.T, x)\n",
    "print(dL_dw1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8184851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight update\n",
    "linear1_updated_w = linear1.weight - 0.1* dL_dw1\n",
    "print(linear1_updated_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e7e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1d9ea7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linear1_updated_w = linear1.weight\n",
    "print(linear1_updated_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b33eb26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linear1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ca5c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9762a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer_a.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243307c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_norm = nn.BatchNorm1d(2, eps = 0, affine = False,track_running_stats = False, momentum = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ff73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_norm = nn.BatchNorm1d(4, eps = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d305dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb241b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn = syn_network(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fa1442",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f973544",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7bfd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.tensor([[1.0, 0.0, 5.0, 9.0], [22.0, 3.0, 4.0, 7.0], [2.0, 23.0, 42.0, 7.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d10eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.tensor([[10.0, 0.0, 50.0, 90.0], [20.0, 43.0, 4.0, 40.0], [-20.0, 3.0, -44.0, 270.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3232af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.tensor([[13.0, 0.0, -30.0, 90.0], [-4.0, 3.0, -4.0, 4.0],[1.0, 0.0, 5.0, 9.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d34410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mu = linear(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e0687",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59127c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_out = batch_norm(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5f8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7804487",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_out = relu(norm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01c834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6050f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = batch_norm.weight; gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de289162",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_sg = syn(relu_out.clone().detach().requires_grad_(True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743972ee",
   "metadata": {},
   "source": [
    "#### optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(linear, batch_norm, relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db83e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimization(model, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c16d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b366ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd7b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dw = loss_grad(inp, relu_out, mu, g_sg, eps, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc2131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94561dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_before = linear.weight.clone().detach(); weight_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915b4338",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21457d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_out.backward(dL_dw.clone().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c2457",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aa3349",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51a95ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5e1899",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_after = linear.weight.clone().detach(); weight_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e5d7cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(weight_before == weight_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd15b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d355d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([0, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac5dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(h2, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640d2c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb6260",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eaf1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linear.weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fb3b06",
   "metadata": {},
   "source": [
    "### From https://stackoverflow.com/questions/67968913/derivative-of-batchnorm2d-in-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a66eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network_1st(nn.Module):\n",
    "    def __init__(self, channel_in, channel_out, conv_kernel_size = 1, pooling_kernel_size = 1):\n",
    "        super(network_1st, self).__init__()\n",
    "               \n",
    "        self.conv2d = nn.Conv2d(channel_in, channel_out, kernel_size=conv_kernel_size)\n",
    "        self.batchnorm2d = nn.BatchNorm2d(channel_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mu = self.conv2d(x)\n",
    "        out = self.batchnorm2d(mu)\n",
    "        \n",
    "        return mu, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5821b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = dataiter.next()\n",
    "#images = images.view(images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d294d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.rand(1, 1, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23e0fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.rand(1, 1, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9b0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network_1st(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d7cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_gradients = [Hook(model.batchnorm2d, backward = True) for model in [model]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5212b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, out = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2638fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a24956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loss = criterion(out, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = abs(target - out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5576522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b9e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_backward = hook_gradients[0].grad_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c959b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970f227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_batchnorm2d(input, output, grad_output, layer):\n",
    "    gamma = layer.weight\n",
    "    gamma = gamma.view(1,-1,1,1) # edit\n",
    "    # beta = layer.bias\n",
    "    # avg = layer.running_mean\n",
    "    # var = layer.running_var\n",
    "    eps = layer.eps\n",
    "    B = input.shape[0] * input.shape[2] * input.shape[3] # edit\n",
    "\n",
    "    # add new\n",
    "    mean = input.mean(dim = (0,2,3), keepdim = True)\n",
    "    variance = input.var(dim = (0,2,3), unbiased=False, keepdim = True)\n",
    "    x_hat = (input - mean)/(torch.sqrt(variance + eps))\n",
    "    \n",
    "    dL_dxi_hat = grad_output * gamma\n",
    "    # dL_dvar = (-0.5 * dL_dxi_hat * (input - avg) / ((var + eps) ** 1.5)).sum((0, 2, 3), keepdim=True) \n",
    "    # dL_davg = (-1.0 / torch.sqrt(var + eps) * dL_dxi_hat).sum((0, 2, 3), keepdim=True) + dL_dvar * (-2.0 * (input - avg)).sum((0, 2, 3), keepdim=True) / B\n",
    "    dL_dvar = (-0.5 * dL_dxi_hat * (input - mean)).sum((0, 2, 3), keepdim=True)  * ((variance + eps) ** -1.5) # edit\n",
    "    dL_davg = (-1.0 / torch.sqrt(variance + eps) * dL_dxi_hat).sum((0, 2, 3), keepdim=True) + (dL_dvar * (-2.0 * (input - mean)).sum((0, 2, 3), keepdim=True) / B) #edit\n",
    "    \n",
    "    dL_dxi = (dL_dxi_hat / torch.sqrt(variance + eps)) + (2.0 * dL_dvar * (input - mean) / B) + (dL_davg / B) # dL_dxi_hat / sqrt()\n",
    "    # dL_dgamma = (grad_output * output).sum((0, 2, 3), keepdim=True) \n",
    "    dL_dgamma = (grad_output * x_hat).sum((0, 2, 3), keepdim=True) # edit\n",
    "    dL_dbeta = (grad_output).sum((0, 2, 3), keepdim=True)\n",
    "    return dL_dxi, dL_dgamma, dL_dbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e494d3f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dL_dxi, dL_dgamma, dL_dbeta = backward_batchnorm2d(images, out, loss, model.batchnorm2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d10cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd29999",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dxi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3f8487",
   "metadata": {},
   "source": [
    "### 1D Batch Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277477e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network_1d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(network_1d, self).__init__()\n",
    "               \n",
    "        self.batchnorm1d = nn.BatchNorm1d(output_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.batchnorm1d(x)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4cb3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images, labels = dataiter.next()\n",
    "#images = images.view(images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09992c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images = torch.rand(2, 1, 3, 3, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2df46f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images = images.view(images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a4b26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.tensor([[0.7, 0.1, -1.3, 1.1, 0.5, 0.3, .6, -0.6, 0.2],\n",
    "        [0.7, 0.3, 0.1, 0.6, 0.8, 0.9, 0.5, 2., 0.0]], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea343c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([[0.9, 0.2, -1.2, 1.0, 0.4, 0.8, 0.4, -0.1, 0.9],\n",
    "        [0.4, 0.2, 0.3, 0.6, 0.5, 0.6, 0.1, 2.4, 0.1]], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bc2b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5692f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network_1d(9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cebf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = torch.tensor([0.9, 1., 0.89, 0.92, 1., 1., 0.96, 1., 0.94], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45f1795",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.batchnorm1d.weight = torch.nn.Parameter(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.tensor([0.0, 0.1, 0.0, 0.0, 0.05, 0.06, 0.0, 0.03, 0.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d842246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.batchnorm1d.bias = torch.nn.Parameter(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d40fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_gradients = [Hook(model.batchnorm1d, backward = True) for model in [model]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3955bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2608b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7105c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177b2b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a57e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_y_pred = 2*(y_pred - target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4c4624",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47432451",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (y_pred - target).pow(2).sum()\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab200a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3351df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_backward = hook_gradients[0].grad_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdeed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a7248",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(images.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e486b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.batchnorm1d.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d9b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_status(**kwargs):\n",
    "    print(\"\\n\")\n",
    "    for arg_name in kwargs:\n",
    "        t= kwargs[arg_name]\n",
    "        t_name=arg_name\n",
    "    print(\"Status of tensor \"+t_name+\":\\n\")\n",
    "    print(\"==============\")\n",
    "    print(\"Data: \"+str(t.data))\n",
    "    print(\"grad: \"+str(t.grad) if t.is_leaf else str(None))\n",
    "    print(\"grad_fn: \"+str(t.grad_fn))\n",
    "    print(\"is_leaf: \"+str(t.is_leaf))\n",
    "    print(\"requires_grad:\"+str(t.requires_grad))\n",
    "    print(\"==============\\n\")\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c51d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_status(y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df19cb6b",
   "metadata": {},
   "source": [
    "#### Comp Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb854e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_fn = y_pred.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff78b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_fn.next_functions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26537dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_graph(g, level=0):\n",
    "    if g == None: return\n",
    "    print('*'*level*4, g)\n",
    "    for subg in g.next_functions:\n",
    "        print_graph(subg[0], level+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b9e311",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_graph(y_pred.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f579078",
   "metadata": {},
   "source": [
    "### Manual Batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4614750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm_forward(x, gamma, beta, eps):\n",
    "\n",
    "    N, D = x.shape\n",
    "\n",
    "    #step1: calculate mean\n",
    "    mu = 1./N * torch.sum(x, dim = 0)\n",
    "\n",
    "    #step2: subtract mean vector of every trainings example\n",
    "    xmu = x - mu\n",
    "\n",
    "    #step3: following the lower branch - calculation denominator\n",
    "    sq = xmu ** 2\n",
    "\n",
    "    #step4: calculate variance\n",
    "    var = 1./N * torch.sum(sq, dim = 0)\n",
    "\n",
    "    #step5: add eps for numerical stability, then sqrt\n",
    "    sqrtvar = torch.sqrt(var + eps)\n",
    "\n",
    "    #step6: invert sqrtwar\n",
    "    ivar = 1./sqrtvar\n",
    "\n",
    "    #step7: execute normalization\n",
    "    xhat = xmu * ivar\n",
    "\n",
    "    #step8: Nor the two transformation steps\n",
    "    gammax = gamma * xhat\n",
    "\n",
    "    #step9\n",
    "    out = gammax + beta\n",
    "\n",
    "    #store intermediate\n",
    "    cache = (xhat,gamma,xmu,ivar,sqrtvar,var,eps)\n",
    "\n",
    "    return out, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7acd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.tensor([[0.7, 0.1, -1.3, 1.1, 0.5, 0.3, .6, -0.6, 0.2],\n",
    "        [0.7, 0.3, 0.1, 0.6, 0.8, 0.9, 0.5, 2., 0.0]], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04e5216",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = torch.tensor([0.9, 1., 0.89, 0.92, 1., 1., 0.96, 1., 0.94], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca1d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.tensor([0.0, 0.1, 0.0, 0.0, 0.05, 0.06, 0.0, 0.03, 0.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b89340",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8fd48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "man_out, cache = batchnorm_forward(images, gamma, beta, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823d6b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45af248",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph(man_out.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd04ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "man_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e77629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5916fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm_backward(dout, cache):\n",
    "\n",
    "    #unfold the variables stored in cache\n",
    "    xhat,gamma,xmu,ivar,sqrtvar,var,eps = cache\n",
    "\n",
    "    #get the dimensions of the input/output\n",
    "    N,D = dout.shape\n",
    "\n",
    "    #step9\n",
    "    dbeta = torch.sum(dout, dim=0)\n",
    "    dgammax = dout #not necessary, but more understandable\n",
    "\n",
    "    #step8\n",
    "    dgamma = torch.sum(dgammax*xhat, dim=0)\n",
    "    dxhat = dgammax * gamma\n",
    "\n",
    "    #step7\n",
    "    divar = torch.sum(dxhat*xmu, dim=0)\n",
    "    dxmu1 = dxhat * ivar\n",
    "\n",
    "    #step6\n",
    "    dsqrtvar = -1. /(sqrtvar**2) * divar\n",
    "\n",
    "    #step5\n",
    "    dvar = 0.5 * 1. /torch.sqrt(var+eps) * dsqrtvar\n",
    "\n",
    "    #step4\n",
    "    dsq = 1. /N * torch.ones((N,D)) * dvar\n",
    "\n",
    "    #step3\n",
    "    dxmu2 = 2 * xmu * dsq\n",
    "\n",
    "    #step2\n",
    "    dx1 = (dxmu1 + dxmu2)\n",
    "    dmu = -1 * torch.sum(dxmu1+dxmu2, dim=0)\n",
    "\n",
    "    #step1\n",
    "    dx2 = 1. /N * torch.ones((N,D)) * dmu\n",
    "\n",
    "    #step0\n",
    "    dx = dx1 + dx2\n",
    "\n",
    "    return dx, dgamma, dbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f9333",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchnorm_backward(grad_y_pred, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6a8180",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938eabd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.batchnorm1d.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.batchnorm1d.bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd50cc9",
   "metadata": {},
   "source": [
    "### Manual Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde6c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network_linear(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(network_linear, self).__init__()\n",
    "               \n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387b4bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dout, cache):\n",
    "    x, weight = cache\n",
    "    \n",
    "    dw = torch.matmul(dout.T, x)\n",
    "    db = dout.sum(dim = 0)\n",
    "    dx = torch.matmul(dout, weight)\n",
    "    return dx, dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bd3eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network_linear(9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d9ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20802e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d81e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc7f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_gradients_linear = [Hook(model.linear, backward = True) for model in [model]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295baa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_linear_pred = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a7307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_linear_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d6a40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_linear = (y_linear_pred - target).pow(2).sum(); loss_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f66594",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_linear.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b5acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_grad_backward = hook_gradients_linear[0].grad_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214820bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_grad_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c86760",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.linear.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c61e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.linear.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc23160",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dout_linear = 2*(y_linear_pred - target); dL_dout_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d125dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_db = dL_dout_linear.sum(dim = 0); dL_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57bf25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dw_linear = torch.matmul(dL_dout_linear.T, images); dL_dw_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0977d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd765753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dL_dx = torch.matmul(dL_dout_linear, model.linear.weight); dL_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec634b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0977208",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = images, model.linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e35ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_backward(dL_dout_linear, cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fdbae3",
   "metadata": {},
   "source": [
    "### Manual ReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af1f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network_relu(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(network_relu, self).__init__()\n",
    "               \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfab7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dout, x):\n",
    "    x = x.clone()\n",
    "    x[x > 0.0] = 1.0\n",
    "    x[x <= 0.0] = 0.0\n",
    "    dx = torch.mul(dout, x)\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91933fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network_relu(9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2973c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6aeab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f003d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_gradients_relu = [Hook(model.relu, backward = True) for model in [model]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbaee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_relu_pred = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d20404",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_relu_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd0461",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_relu = (y_relu_pred - target).pow(2).sum(); loss_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f7d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_relu.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67738465",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_grad_backward = hook_gradients_relu[0].grad_output[0]; relu_grad_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48a898b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dL_dout_relu = 2*(y_relu_pred - target); dL_dout_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc7cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e8e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ff5386",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_backward(dL_dout_relu, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d6a86e",
   "metadata": {},
   "source": [
    "### Manual Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2031f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network_conv2d(nn.Module):\n",
    "    def __init__(self, channel_in, channel_out, kernel_size, padding):\n",
    "        super(network_conv2d, self).__init__()\n",
    "               \n",
    "        self.conv2d = nn.Conv2d(channel_in, channel_out, kernel_size=kernel_size, padding = padding)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv2d(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880edd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_backward(dout, cache):\n",
    "\n",
    "    return dx, dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4c6970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dout, cache):\n",
    "    x, weight = cache\n",
    "    \n",
    "    dw = torch.matmul(dout.T, x)\n",
    "    db = dout.sum(dim = 0)\n",
    "    dx = torch.matmul(dout, weight)\n",
    "    return dx, dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f1d966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f8c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network_conv2d(9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c5988",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdab229",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b55db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_gradients_relu = [Hook(model.relu, backward = True) for model in [model]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420cbb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_relu_pred = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660c9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_relu_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c58208",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_relu = (y_relu_pred - target).pow(2).sum(); loss_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e384f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_relu.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aab286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_grad_backward = hook_gradients_relu[0].grad_output[0]; relu_grad_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52b4fe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dL_dout_relu = 2*(y_relu_pred - target); dL_dout_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cc65be",
   "metadata": {},
   "outputs": [],
   "source": [
    "images2d = torch.tensor([[[[0.7, 0.1, -1.3, 1.1, 0.5],\n",
    "                        [0.1, 1.6, -0.6, 0.2, 0.0],\n",
    "                        [0.4, 3.6, -0.9, -0.2, 0.0],\n",
    "                        [0.3, .6, -0.6, 5.2, 0.3],\n",
    "                        [0.6, -1.6, -0.7, 2.2, 0.4]],\n",
    "                        [[0.7, 0.3, 0.1, 0.6, 0.8],\n",
    "                        [1.9, 1.5, 2.1, 0.3, 1.1],\n",
    "                        [0.4, 0.2, 1., 2.0, 1.1],\n",
    "                        [0.1, 3.5, 2.1, 0.3, 0.4],\n",
    "                        [0.7, 0.2, 1., 0.6, 0.4]]]], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d1241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target2d = torch.tensor([[[[0.8, 0.2, -1.1, 1.0, 0.4],\n",
    "                        [0.5, 1.6, -0.8, 0.1, 0.1],\n",
    "                        [0.3, 3.0, -0.9, -0.0, 0.6],\n",
    "                        [0.5, .2, -0.4, 5.0, 0.4],\n",
    "                        [0.9, -1.6, -0.5, 2.3, 0.8]],\n",
    "                        [[0.7, 0.9, 0.1, 0.0, 0.0],\n",
    "                        [1.8, 1.4, 2.8, 0.5, 1.8],\n",
    "                        [0.7, 0.5, 1.3, 2.5, 1.4],\n",
    "                        [0.7, 3.5, 2.4, 0.4, 0.5],\n",
    "                        [0.2, 0.6, 1.7, 0.0, 0.9]]]], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f40feb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a11c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8c09c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network_conv2d(9, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef796159",
   "metadata": {},
   "source": [
    "## gp.ai MNIST test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bfe6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch equivalent model\n",
    "class network(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(network, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(784, 256)\n",
    "        self.batchnorm1d_1 = nn.BatchNorm1d(256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.linear2 = nn.Linear(256, 256)\n",
    "        self.batchnorm1d_2 = nn.BatchNorm1d(256)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.linear2 = nn.Linear(256, 10)\n",
    "        self.batchnorm1d_2 = nn.BatchNorm1d(10)\n",
    "        self.relu2 = nn.ReLU()        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        lin1_out = self.linear1(x)\n",
    "        bn1_out =  self.batchnorm1d_1(lin1_out)\n",
    "        relu1_out = self.relu1(bn1_out)\n",
    "        \n",
    "        lin2_out = self.linear2(relu1_out)\n",
    "        bn2_out =  self.batchnorm1d_2(lin2_out)\n",
    "        relu2_out = self.relu1(bn2_out)\n",
    "        \n",
    "        lin2_out = self.linear2(relu2_out)\n",
    "        bn2_out =  self.batchnorm1d_2(lin2_out)\n",
    "        out = self.relu1(bn2_out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc3902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_input = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aa630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"../FC_MNIST_V_gpai/logs/model_FC_MNIST_V_gpai.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0b0e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2759feb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict['batchnorm1d_1.running_var'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe010a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = [1e-5] + [0 for _ in range(32 * 32 - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56541b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257feff5",
   "metadata": {},
   "source": [
    "# Batch Norm from https://d2l.ai/chapter_convolutional-modern/batch-norm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f4a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network_1d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(network_1d, self).__init__()\n",
    "               \n",
    "        self.batchnorm1d = nn.BatchNorm1d(output_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.batchnorm1d(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a5032",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_torch = network_1d(9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d260fb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50fa6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_torch_out = bn_torch(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac4aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_torch.batchnorm1d.running_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323f87ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_torch.batchnorm1d.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288c4b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_torch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08859ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a7c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cb9a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.is_grad_enabled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742769d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tt_batch_norm(X, gamma_tt, beta_tt, moving_mean, moving_var, eps_tt, momentum):\n",
    "        mean = X.mean(dim=0)\n",
    "        var = ((X - mean) ** 2).mean(dim=0)\n",
    "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "        # Update the mean and variance using moving average\n",
    "        moving_mean = (1.0 - momentum) * moving_mean + momentum * mean\n",
    "        moving_var = (1.0 - momentum) * moving_var + momentum * var\n",
    "        Y = gamma * X_hat + beta  # Scale and shift\n",
    "        print(X_hat, gamma, beta, Y)\n",
    "        return Y, moving_mean.data, moving_var.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec849a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, num_features, num_dims):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(shape))\n",
    "        self.moving_mean = torch.zeros(shape)\n",
    "        self.moving_var = torch.ones(shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # If X is not on the main memory, copy moving_mean and moving_var to\n",
    "        # the device where X is located\n",
    "        if self.moving_mean.device != X.device:\n",
    "            self.moving_mean = self.moving_mean.to(X.device)\n",
    "            self.moving_var = self.moving_var.to(X.device)\n",
    "        # Save the updated moving_mean and moving_var\n",
    "        Y, self.moving_mean, self.moving_var = batch_norm(X, self.gamma, self.beta, self.moving_mean, self.moving_var, eps=1e-5, momentum=0.1)\n",
    "        print('Y:', Y,'moving_mean:', self.moving_mean, 'moving_var:', self.moving_var, '\\n')\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f915d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1d499f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc1a7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dba405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
    "    # Use is_grad_enabled to determine whether we are in training mode\n",
    "    if not torch.is_grad_enabled():\n",
    "        # In prediction mode, use mean and variance obtained by moving average\n",
    "        print('pred mode') \n",
    "        print(moving_mean, moving_var, '\\n')\n",
    "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
    "    else:\n",
    "        print('train mode')\n",
    "        assert len(X.shape) in (2, 4)\n",
    "        if len(X.shape) == 2:\n",
    "            # When using a fully connected layer, calculate the mean and\n",
    "            # variance on the feature dimension\n",
    "            mean = X.mean(dim=0)\n",
    "            var = ((X - mean) ** 2).mean(dim=0)\n",
    "        else:\n",
    "            # When using a two-dimensional convolutional layer, calculate the\n",
    "            # mean and variance on the channel dimension (axis=1). Here we\n",
    "            # need to maintain the shape of X, so that the broadcasting\n",
    "            # operation can be carried out later\n",
    "            mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
    "            var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
    "        # In training mode, the current mean and variance are used\n",
    "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "        # Update the mean and variance using moving average\n",
    "        moving_mean = (1.0 - momentum) * moving_mean + momentum * mean\n",
    "        moving_var = (1.0 - momentum) * moving_var + momentum * var\n",
    "    Y = gamma * X_hat + beta  # Scale and shift\n",
    "    print(X_hat, gamma, beta, Y)\n",
    "    return Y, moving_mean.data, moving_var.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e456ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    # num_features: the number of outputs for a fully connected layer or the\n",
    "    # number of output channels for a convolutional layer. num_dims: 2 for a\n",
    "    # fully connected layer and 4 for a convolutional layer\n",
    "    def __init__(self, num_features, num_dims):\n",
    "        super().__init__()\n",
    "        if num_dims == 2:\n",
    "            shape = (1, num_features)\n",
    "        else:\n",
    "            shape = (1, num_features, 1, 1)\n",
    "        # The scale parameter and the shift parameter (model parameters) are\n",
    "        # initialized to 1 and 0, respectively\n",
    "        self.gamma = nn.Parameter(torch.ones(shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(shape))\n",
    "        # The variables that are not model parameters are initialized to 0 and\n",
    "        # 1\n",
    "        self.moving_mean = torch.zeros(shape)\n",
    "        self.moving_var = torch.ones(shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # If X is not on the main memory, copy moving_mean and moving_var to\n",
    "        # the device where X is located\n",
    "        if self.moving_mean.device != X.device:\n",
    "            self.moving_mean = self.moving_mean.to(X.device)\n",
    "            self.moving_var = self.moving_var.to(X.device)\n",
    "        # Save the updated moving_mean and moving_var\n",
    "        Y, self.moving_mean, self.moving_var = batch_norm(\n",
    "            X, self.gamma, self.beta, self.moving_mean,\n",
    "            self.moving_var, eps=1e-5, momentum=0.1)\n",
    "        print('Y:', Y,'moving_mean:', self.moving_mean, 'moving_var:', self.moving_var, '\\n')\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6543b6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.tensor([[0.7, 0.1, -1.3, 1.1, 0.5, 0.3, .6, -0.6, 0.2],\n",
    "        [0.7, 0.3, 0.1, 0.6, 0.8, 0.9, 0.5, 2., 0.0]], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d1e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = torch.tensor([0.9, 1., 0.89, 0.92, 1., 1., 0.96, 1., 0.94], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944c920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.tensor([0.0, 0.1, 0.0, 0.0, 0.05, 0.06, 0.0, 0.03, 0.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17dcbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce492bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e36e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = BatchNorm(9, num_dims=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150d8d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_out = bn(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccdd734",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31814cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_torch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.moving_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ea4bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytorchMnistModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, state_dict):\n",
    "        super(PytorchMnistModel, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.batchnorm1d_1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.batchnorm1d_2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.linear3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.batchnorm1d_3 = nn.BatchNorm1d(output_dim)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.load_state_dict(state_dict)\n",
    "\n",
    "    def forward(self, X):\n",
    "        x, labels = X\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        lin1_out = self.linear1(x)\n",
    "        bn1_out =  self.batchnorm1d_1(lin1_out)\n",
    "        relu1_out = self.relu1(bn1_out)\n",
    "\n",
    "        lin2_out = self.linear2(relu1_out)\n",
    "        bn2_out =  self.batchnorm1d_2(lin2_out)\n",
    "        relu2_out = self.relu1(bn2_out)\n",
    "\n",
    "        lin3_out = self.linear3(relu2_out)\n",
    "        bn3_out =  self.batchnorm1d_3(lin3_out)\n",
    "        relu3_out = self.relu3(bn3_out)\n",
    "\n",
    "        out = nn.functional.softmax(relu3_out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be9cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69631f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(testset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7310c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_mnist_model = PytorchMnistModel(784, 256, 10, state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4853143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_input = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28803994",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_out = pytorch_mnist_model(first_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b7f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, label = first_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9551e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bc8c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9deca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_mnist_model(first_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd0207",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytorchBatchNorm1D(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(PytorchBatchNorm1D, self).__init__()\n",
    "\n",
    "        self.batchnorm1d_1 = nn.BatchNorm1d(input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "       # x, labels = X\n",
    "       # x = x.view(x.shape[0], -1)\n",
    "\n",
    "        bn1_out =  self.batchnorm1d_1(x)\n",
    "\n",
    "        return bn1_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36abb2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.tensor([[0.54, 0.1, -1.3, 1.1, 0.5, 0.3, .6, -0.6, 0.2],\n",
    "        [0.7, 0.3, 0.1, 0.6, 0.8, 0.9, 0.5, 2., 0.0]], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff88b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0d37bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = torch.tensor([0.9, 1., 0.89, 0.92, 1., 1., 0.96, 1., 0.94], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44004eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.tensor([0.0, 0.1, 0.0, 0.0, 0.05, 0.06, 0.0, 0.03, 0.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ffe7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean = torch.tensor([0.1, 0.07, 0.09, 0.11, 0.12, 0.086, 0.06, 0.2, 0.21], requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2daaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_var =   torch.tensor([0.44, 0.87, 0.96, 0.92, 1.2, 0.12, 0.43, 0.76, 0.91], requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f5b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6760323",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d = PytorchBatchNorm1D(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19812c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b11d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = torch.nn.Parameter(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98fcf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.nn.Parameter(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60650ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.batchnorm1d_1.weight = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc8517",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.batchnorm1d_1.bias = beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ab142",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.batchnorm1d_1.running_mean = running_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bbcc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.batchnorm1d_1.running_var = running_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da3ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.batchnorm1d_1.eps = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03167e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_out = pytorch_bn1d(images); torch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ad8152",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pytorch_bn1d.state_dict(), 'bn1d.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a5c145",
   "metadata": {},
   "source": [
    "### Manual for TT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477910a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_plus_eps = running_var + eps; var_plus_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61563904",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_var = torch.sqrt(var_plus_eps); sqrt_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b120079",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_inv = torch.reciprocal(sqrt_var); sqrt_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b8e637",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_minus_mean = images - running_mean; x_minus_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd7e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_div_sqrt = x_minus_mean * sqrt_inv; x_div_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050390ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gamma = x_div_sqrt * gamma; x_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7475a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x_gamma + beta; y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36fc47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(f\"bn1d.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d259ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4de5331",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt32 = torch.randn(1, 1, 32, 32, requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e89619",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d989230",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt32.reshape(1, 1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a96f4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_32 = {'batchnorm1d_1.weight': torch.randn(32, requires_grad = False), 'batchnorm1d_1.bias': torch.randn(32, requires_grad = False),\n",
    "                'batchnorm1d_1.running_mean': torch.randn(32, requires_grad = False), 'batchnorm1d_1.running_var': torch.randn(32, requires_grad = False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1b8200",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a33319",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(state_dict_32, 'bn1d_32.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f4182f",
   "metadata": {},
   "source": [
    "# ttmetal Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7181c71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/farbabi/git/tt-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f9429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, os\n",
    "from pathlib import Path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d39d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env TT_METAL_ENV=dev\n",
    "%env TT_METAL_HOME=/home/farbabi/git/tt-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dffac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f\"{Path}(__file__).parent\"\n",
    "sys.path.append(f\"{f}/..\")\n",
    "sys.path.append(f\"{f}/../..\")\n",
    "sys.path.append('/home/farbabi/git/tt-metal/python_api_testing/models')\n",
    "sys.path.append('/home/farbabi/git/tt-metal/python_api_testing/sweep_tests')\n",
    "sys.path.append('/home/farbabi/git/tt-metal/python_api_testing/models/synthetic_gradients')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761043d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b3aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs import tt_lib as ttl\n",
    "from models.utility_functions import tilize_to_list, untilize, comp_allclose_and_pcc, tt2torch, torch2tt_tensor\n",
    "from libs.tt_lib.utils import pad_activation, pad_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d5a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_dim = 32\n",
    "batch_size = 1\n",
    "eps = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f27874",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ttl.device.CreateDevice(ttl.device.Arch.GRAYSKULL, 0)\n",
    "ttl.device.InitializeDevice(device)\n",
    "host = ttl.device.GetHost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d755462",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(f\"tests/python_api_testing/models/synthetic_gradients/lfs/synthetic_grads/sg_mnist_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5212abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1 = state_dict[\"fc1.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ce862",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3a9485",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1 = torch.randn(1, 1, 256, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e504435",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e7065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tilized_gamma = tilize_to_list(gamma1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be066db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1.shape[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1318b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_tt = ttm.tensor.Tensor(tilized_gamma, *gamma1.shape[-2:], ttm.tensor.DataType.BFLOAT16, ttm.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5417fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1 = torch.randn(1, 1, 1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abff11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1_targ = torch.zeros(1, 1, 32, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2509eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1_targ[:, :, :1, :] = beta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a74f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tilized_beta = tilize_to_list(beta1_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9283058",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_tt = ttm.tensor.Tensor(tilized_beta, beta1_targ.shape[-], ttm.tensor.DataType.BFLOAT16, ttm.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9023df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(1, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5b0999",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_reshape = inputs.reshape(1, 1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033fd5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9d48bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_targ = torch.zeros(1, 1, 32, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c76b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_targ[:, :, :1, :] = inputs_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d039b74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ca049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_targ.reshape(32, 1024)[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf310389",
   "metadata": {},
   "outputs": [],
   "source": [
    "tilized_inputs = tilize_to_list(inputs_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca54f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_tt = ttm.tensor.Tensor(tilized_inputs, inputs_targ.shape, ttm.tensor.DataType.BFLOAT16, ttm.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b7f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_T = ttm.tensor.transpose(gamma_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82691827",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_T.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e053e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ttm.tensor.matmul(inputs_tt, gamma1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_plus_bias = ttm.tensor.bcast(output, beta_tt, ttm.tensor.BcastOpMath.ADD, ttm.tensor.BcastOpDim.H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cacd9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_plus_bias.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8f98cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_torch = torch.nn.Linear(1024, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7f818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1_torch = gamma1.view(256, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81e2859",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809286b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_torch.weight = nn.Parameter(gamma1_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fbc0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1_torch = beta1.view(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f693d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_torch.bias = nn.Parameter(beta1_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231dad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_out = linear_torch(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2047b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0ac63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_plus_bias.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c55cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_out_cpu = output_plus_bias.to(host)\n",
    "tt_out_cpu_pytorch = torch.Tensor(tt_out_cpu.data()).reshape(tt_out_cpu.shape())[:, 0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d2d7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_out_cpu_pytorch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1092654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_pcc(torch_out, tt_out_cpu_pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed96b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_out[0][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1face8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_out_cpu_pytorch[0][0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09892b95",
   "metadata": {},
   "source": [
    "## tt Batch Norm Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aba0b8",
   "metadata": {},
   "source": [
    "pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d546d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.tensor([[0.7, 0.1, -1.3, 1.1, 0.5, 0.3, .6, -0.6, 0.2],\n",
    "        [0.7, 0.3, 0.1, 0.6, 0.8, 0.9, 0.5, 2., 0.0]], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f1ea2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = torch.tensor([0.9, 1., 0.89, 0.92, 1., 1., 0.96, 1., 0.94], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2323f873",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.tensor([0.0, 0.1, 0.0, 0.0, 0.05, 0.06, 0.0, 0.03, 0.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "f5ec485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0a8d9251",
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "484993f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean = torch.tensor([0.1, 0.07, 0.09, 0.11, 0.12, 0.086, 0.06, 0.2, 0.21], requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "88947dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_var =   torch.tensor([0.44, 0.87, 0.96, 0.92, 1.2, 0.12, 0.43, 0.76, 0.91], requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdebc82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytorchBatchNorm1D(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(PytorchBatchNorm1D, self).__init__()\n",
    "\n",
    "        self.batchnorm1d_1 = nn.BatchNorm1d(input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "       # x, labels = X\n",
    "       # x = x.view(x.shape[0], -1)\n",
    "\n",
    "        bn1_out =  self.batchnorm1d_1(x)\n",
    "\n",
    "        return bn1_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "78946294",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d = PytorchBatchNorm1D(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "82d14c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = torch.nn.Parameter(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "b4e4e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.nn.Parameter(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9fc954a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.batchnorm1d_1.weight = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "11a30a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.batchnorm1d_1.bias = beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "59056b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.batchnorm1d_1.running_mean = running_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "d7e509ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.batchnorm1d_1.running_var = running_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8a0ca445",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.batchnorm1d_1.eps = eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e56e2bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.3001e-07, -8.5346e-01, -8.8909e-01,  9.1273e-01, -9.2849e-01,\n",
       "         -9.3449e-01,  8.1135e-01, -9.6970e-01,  8.9625e-01],\n",
       "        [-5.3001e-07,  1.0535e+00,  8.8909e-01, -9.1273e-01,  1.0285e+00,\n",
       "          1.0545e+00, -8.1135e-01,  1.0297e+00, -8.9625e-01]],\n",
       "       grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out = pytorch_bn1d(images); torch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "181ba446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
    "    # Use is_grad_enabled to determine whether we are in training mode\n",
    "    if not torch.is_grad_enabled():\n",
    "        # In prediction mode, use mean and variance obtained by moving average\n",
    "        print('pred mode') \n",
    "        print(moving_mean, moving_var, '\\n')\n",
    "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
    "    else:\n",
    "        print('train mode')\n",
    "        assert len(X.shape) in (2, 4)\n",
    "        if len(X.shape) == 2:\n",
    "            # When using a fully connected layer, calculate the mean and\n",
    "            # variance on the feature dimension\n",
    "            mean = X.mean(dim=0)\n",
    "            print('mean:', mean)\n",
    "            var = ((X - mean) ** 2).mean(dim=0)\n",
    "            print('var:', var)\n",
    "        else:\n",
    "            # When using a two-dimensional convolutional layer, calculate the\n",
    "            # mean and variance on the channel dimension (axis=1). Here we\n",
    "            # need to maintain the shape of X, so that the broadcasting\n",
    "            # operation can be carried out later\n",
    "            mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
    "            var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
    "        # In training mode, the current mean and variance are used\n",
    "        var_plus_eps = var + eps\n",
    "        print('var_plus_eps:\\n', var_plus_eps)\n",
    "        sqrt_var_eps = torch.sqrt(var_plus_eps)\n",
    "        print('sqrt_var_eps:\\n', sqrt_var_eps)\n",
    "        inv_sqrt_var_eps = 1 / sqrt_var_eps\n",
    "        print('inv_sqrt_var_eps:\\n', inv_sqrt_var_eps)\n",
    "        x_minus_mean = X - mean\n",
    "        print('x_minus_mean:\\n', x_minus_mean)\n",
    "        x_div_sqrt_var = x_minus_mean * inv_sqrt_var_eps\n",
    "        print('x_div_sqrt_var:\\n', x_div_sqrt_var)\n",
    "        # Update the mean and variance using moving average\n",
    "        moving_mean = (1.0 - momentum) * moving_mean + momentum * mean\n",
    "        moving_var = (1.0 - momentum) * moving_var + momentum * var\n",
    "    Y = gamma * x_div_sqrt_var + beta  # Scale and shift\n",
    "    print('x_div_sqrt_var:', x_div_sqrt_var,'\\n','gamma:', gamma,'\\n','beta:', beta,'\\n', 'Y:', Y)\n",
    "    return Y, moving_mean.data, moving_var.data, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "aec510b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    # num_features: the number of outputs for a fully connected layer or the\n",
    "    # number of output channels for a convolutional layer. num_dims: 2 for a\n",
    "    # fully connected layer and 4 for a convolutional layer\n",
    "    def __init__(self, num_features, num_dims, gamma, beta, moving_mean, moving_var, epsilon):\n",
    "        super().__init__()\n",
    "        if num_dims == 2:\n",
    "            shape = (1, num_features)\n",
    "        else:\n",
    "            shape = (1, num_features, 1, 1)\n",
    "        # The scale parameter and the shift parameter (model parameters) are\n",
    "        # initialized to 1 and 0, respectively\n",
    "#         self.gamma = nn.Parameter(torch.ones(shape))\n",
    "#         self.beta = nn.Parameter(torch.zeros(shape))\n",
    "#         # The variables that are not model parameters are initialized to 0 and\n",
    "#         # 1\n",
    "#         self.moving_mean = torch.zeros(shape)\n",
    "#         self.moving_var = torch.ones(shape)\n",
    "        \n",
    "        self.gamma = nn.Parameter(gamma)\n",
    "        self.beta = nn.Parameter(beta)\n",
    "        # The variables that are not model parameters are initialized to 0 and\n",
    "        # 1\n",
    "        self.moving_mean = moving_mean\n",
    "        self.moving_var = moving_var\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, X):\n",
    "        # If X is not on the main memory, copy moving_mean and moving_var to\n",
    "        # the device where X is located\n",
    "        if self.moving_mean.device != X.device:\n",
    "            self.moving_mean = self.moving_mean.to(X.device)\n",
    "            self.moving_var = self.moving_var.to(X.device)\n",
    "        # Save the updated moving_mean and moving_var\n",
    "        Y, self.moving_mean, self.moving_var, mean = batch_norm(X, self.gamma, self.beta, self.moving_mean, self.moving_var, eps=self.epsilon, momentum=0.1)\n",
    "        print('Y:', Y,'\\nmoving_mean:', self.moving_mean, '\\nmoving_var:', self.moving_var, '\\n')\n",
    "        return Y, mean, self.moving_mean, self.moving_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dd3d05e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7f581e16a310>"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "fa75e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = BatchNorm(9, 2, gamma, beta, running_mean, running_var, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "a4e74859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm()"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "537c7be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mode\n",
      "mean: tensor([ 0.7000,  0.2000, -0.6000,  0.8500,  0.6500,  0.6000,  0.5500,  0.7000,\n",
      "         0.1000], grad_fn=<MeanBackward1>)\n",
      "var: tensor([0.0000, 0.0100, 0.4900, 0.0625, 0.0225, 0.0900, 0.0025, 1.6900, 0.0100],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "var_plus_eps:\n",
      " tensor([1.0000e-03, 1.1000e-02, 4.9100e-01, 6.3500e-02, 2.3500e-02, 9.1000e-02,\n",
      "        3.5000e-03, 1.6910e+00, 1.1000e-02], grad_fn=<AddBackward0>)\n",
      "sqrt_var_eps:\n",
      " tensor([0.0316, 0.1049, 0.7007, 0.2520, 0.1533, 0.3017, 0.0592, 1.3004, 0.1049],\n",
      "       grad_fn=<SqrtBackward0>)\n",
      "inv_sqrt_var_eps:\n",
      " tensor([31.6228,  9.5346,  1.4271,  3.9684,  6.5233,  3.3150, 16.9031,  0.7690,\n",
      "         9.5346], grad_fn=<MulBackward0>)\n",
      "x_minus_mean:\n",
      " tensor([[ 0.0000, -0.1000, -0.7000,  0.2500, -0.1500, -0.3000,  0.0500, -1.3000,\n",
      "          0.1000],\n",
      "        [ 0.0000,  0.1000,  0.7000, -0.2500,  0.1500,  0.3000, -0.0500,  1.3000,\n",
      "         -0.1000]], grad_fn=<SubBackward0>)\n",
      "x_div_sqrt_var:\n",
      " tensor([[ 0.0000, -0.9535, -0.9990,  0.9921, -0.9785, -0.9945,  0.8452, -0.9997,\n",
      "          0.9535],\n",
      "        [ 0.0000,  0.9535,  0.9990, -0.9921,  0.9785,  0.9945, -0.8452,  0.9997,\n",
      "         -0.9535]], grad_fn=<MulBackward0>)\n",
      "x_div_sqrt_var: tensor([[ 0.0000, -0.9535, -0.9990,  0.9921, -0.9785, -0.9945,  0.8452, -0.9997,\n",
      "          0.9535],\n",
      "        [ 0.0000,  0.9535,  0.9990, -0.9921,  0.9785,  0.9945, -0.8452,  0.9997,\n",
      "         -0.9535]], grad_fn=<MulBackward0>) \n",
      " gamma: Parameter containing:\n",
      "tensor([0.9000, 1.0000, 0.8900, 0.9200, 1.0000, 1.0000, 0.9600, 1.0000, 0.9400],\n",
      "       requires_grad=True) \n",
      " beta: Parameter containing:\n",
      "tensor([0.0000, 0.1000, 0.0000, 0.0000, 0.0500, 0.0600, 0.0000, 0.0300, 0.0000],\n",
      "       requires_grad=True) \n",
      " Y: tensor([[ 0.0000, -0.8535, -0.8891,  0.9127, -0.9285, -0.9345,  0.8113, -0.9697,\n",
      "          0.8963],\n",
      "        [ 0.0000,  1.0535,  0.8891, -0.9127,  1.0285,  1.0545, -0.8113,  1.0297,\n",
      "         -0.8963]], grad_fn=<AddBackward0>)\n",
      "Y: tensor([[ 0.0000, -0.8535, -0.8891,  0.9127, -0.9285, -0.9345,  0.8113, -0.9697,\n",
      "          0.8963],\n",
      "        [ 0.0000,  1.0535,  0.8891, -0.9127,  1.0285,  1.0545, -0.8113,  1.0297,\n",
      "         -0.8963]], grad_fn=<AddBackward0>) \n",
      "moving_mean: tensor([ 0.2140,  0.0947, -0.0411,  0.2506,  0.2207,  0.1837,  0.1531,  0.2950,\n",
      "         0.1891]) \n",
      "moving_var: tensor([0.3564, 0.7075, 0.9148, 0.7627, 0.9783, 0.1224, 0.3490, 1.0888, 0.7399]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "bn_out, mean_torch, moving_mean_torch, moving_var_torch  = bn(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "23872c21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.7000,  0.2000, -0.6000,  0.8500,  0.6500,  0.6000,  0.5500,  0.7000,\n",
       "         0.1000], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ed2fec7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.8535, -0.8891,  0.9127, -0.9285, -0.9345,  0.8113, -0.9697,\n",
       "          0.8963],\n",
       "        [ 0.0000,  1.0535,  0.8891, -0.9127,  1.0285,  1.0545, -0.8113,  1.0297,\n",
       "         -0.8963]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d4d237fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.3001e-07, -8.5346e-01, -8.8909e-01,  9.1273e-01, -9.2849e-01,\n",
       "         -9.3449e-01,  8.1135e-01, -9.6970e-01,  8.9625e-01],\n",
       "        [-5.3001e-07,  1.0535e+00,  8.8909e-01, -9.1273e-01,  1.0285e+00,\n",
       "          1.0545e+00, -8.1135e-01,  1.0297e+00, -8.9625e-01]],\n",
       "       grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "31719823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensor.DataType.BFLOAT16\n",
    "RSUM = ttl.tensor.ReduceOpMath.SUM\n",
    "RW = ttl.tensor.ReduceOpDim.W\n",
    "BCSUB = ttl.tensor.BcastOpMath.SUB\n",
    "BCW = ttl.tensor.BcastOpDim.W\n",
    "\n",
    "\n",
    "# RH = tensor.ReduceOpDim.H\n",
    "# BCH = tensor.BcastOpDim.H\n",
    "# BCHW = tensor.BcastOpDim.HW\n",
    "# BCMUL = tensor.BcastOpMath.MUL\n",
    "# BCADD = tensor.BcastOpMath.ADD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "bcf6ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ec9b3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_size = images.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "6ed79de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "76d7bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "80b1554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "a5b6d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_reshaped = images.view(images.shape[0], 1, 1, images.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "ff50aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_padded = pad_activation(images_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "76680ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_tilized = tilize_to_list(images_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6b19ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_tt = ttl.tensor.Tensor(images_tilized, [batch_size, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "4b263e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_reshaped = gamma.view(1, 1, 1, gamma.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "222d3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_padded = pad_weight(gamma_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "bebfc302",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_tilized = tilize_to_list(gamma_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "99816e62",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_tt = ttl.tensor.Tensor(gamma_tilized, [1, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "75a29026",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_reshaped = beta.view(1, 1, 1, beta.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "621ef2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_padded = pad_weight(beta_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "dfd4eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_tilized = tilize_to_list(beta_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "a22a889a",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_tt = ttl.tensor.Tensor(beta_tilized, [1, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "a0ee2edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 32, 32]"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_tt.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7ac10fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_tor = images_tt.to(host).data()\n",
    "images_tor = torch.Tensor(images_tor).reshape((batch_size,1,H,W))\n",
    "images_tor = untilize(images_tor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "88e9e5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 32, 32])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_tor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "4bc07970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6992, 0.2988, 0.0996, 0.5977, 0.7969, 0.8984, 0.5000, 2.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_tor[1][0][0][0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "528df491",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_padded = images_tor.mean(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1df5adad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "3282c90f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.6992,  0.1992, -0.5986,  0.8457,  0.6484,  0.5986,  0.5488,  0.7012,\n",
       "         0.0996,  0.0000,  0.0000,  0.0000])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_padded[0][0][0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "21ff81bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ((images_padded - mean_padded) ** 2).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5adfa2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32])"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fecf24d3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([6.1033e-07, 1.0001e-02, 4.9000e-01, 6.2518e-02, 2.2502e-02, 9.0002e-02,\n",
       "        2.5014e-03, 1.6900e+00, 1.0000e-02, 0.0000e+00, 0.0000e+00, 0.0000e+00],\n",
       "       grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var[0][0][0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "3c984f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reshaped = mean_padded.view(1, 1, 32, 32)\n",
    "mean_tilized = tilize_to_list(mean_reshaped)\n",
    "mean_tt = ttl.tensor.Tensor(mean_tilized, [1, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "6e0eee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_reshaped = var.view(1, 1, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "c12ef778",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_tilized = tilize_to_list(var_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "cf22e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_tt = ttl.tensor.Tensor(var_tilized, [1, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "f5886bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_torch = torch.tensor([[[W*[eps]]]])\n",
    "epsilon_padded = pad_activation(epsilon_torch)\n",
    "epsilon_tilized = tilize_to_list(epsilon_padded)\n",
    "eps_tt = ttl.tensor.Tensor(epsilon_tilized, [1, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "07f95cb9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=4\n",
      "Compiling RISCID=0\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Generating defines for TRISCs\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=1\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=2\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=3\n"
     ]
    }
   ],
   "source": [
    "var_plus_eps = ttl.tensor.add(eps_tt, var_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "12cabfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ [[[0.000999451, 0.0109253, 0.490234, 0.0634766, 0.0234375, 0.0908203, 0.00349426, 1.6875, 0.0109253, 0.000999451, 0.000999451, 0.000999451, 0.000999451, 0.000999451, 0.000999451, 0.000999451, 0.000999451, 0.000999451, 0.000999451, 0.000999451, 0.000999451, 0.000999451, 0.000999451, 0.000999451, 0.000999451, 0.000999451, 0.000999451, 0.000999451, 0.000999451, 0.000999451, 0.000999451, 0.000999451],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]] dtype=bfloat16 ]\n"
     ]
    }
   ],
   "source": [
    "var_plus_eps.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "bf30abe9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=4\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Generating defines for TRISCs\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=0\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=1\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=2\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=3\n"
     ]
    }
   ],
   "source": [
    "sqrt_var = ttl.tensor.sqrt(var_plus_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "83bedc48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ [[[0.0314941, 0.105957, 0.738281, 0.251953, 0.15625, 0.306641, 0.059082, 1.34375, 0.105957, 0.0314941, 0.0314941, 0.0314941, 0.0314941, 0.0314941, 0.0314941, 0.0314941, 0.0314941, 0.0314941, 0.0314941, 0.0314941, 0.0314941, 0.0314941, 0.0314941, 0.0314941, 0.0314941, 0.0314941, 0.0314941, 0.0314941, 0.0314941, 0.0314941, 0.0314941, 0.0314941],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20],\n",
      "    [8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20, 8.13152e-20]]] dtype=bfloat16 ]\n"
     ]
    }
   ],
   "source": [
    "sqrt_var.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "8d4c9efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=4\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Generating defines for TRISCs\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=0\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=1\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=2\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=3\n"
     ]
    }
   ],
   "source": [
    "sqrt_inv = ttl.tensor.recip(sqrt_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "7bbe0b14",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ [[[31.5, 9.375, 1.35156, 3.9375, 6.375, 3.25, 16.5, 0.742188, 9.375, 31.5, 31.5, 31.5, 31.5, 31.5, 31.5, 31.5, 31.5, 31.5, 31.5, 31.5, 31.5, 31.5, 31.5, 31.5, 31.5, 31.5, 31.5, 31.5, 31.5, 31.5, 31.5, 31.5],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19],\n",
      "    [1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19, 1.22498e+19]]] dtype=bfloat16 ]\n"
     ]
    }
   ],
   "source": [
    "sqrt_inv.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6ee07c14",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean_padded = pad_activation(running_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "d41325d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean_tilized = tilize_to_list(running_mean_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4857ee97",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean_tt = ttl.tensor.Tensor(running_mean_tilized, [1, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "d05b302b",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_var_padded = pad_activation(running_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "f875ad50",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_var_tilized = tilize_to_list(running_var_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "75860e7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_var_tt = ttl.tensor.Tensor(running_var_tilized, [1, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "e217e6ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 32, 32]"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_tt.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "b12b93a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_minus_mean_ttt = images_padded - mean_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "d8e568c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 7.8124e-04, -9.9219e-02, -7.0137e-01,  2.5430e-01, -1.4844e-01,\n",
       "        -2.9863e-01,  5.1172e-02, -1.3012e+00,  1.0039e-01,  0.0000e+00,\n",
       "         0.0000e+00,  0.0000e+00], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_minus_mean_ttt[0][0][0][0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "bde7c54e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 32, 32])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_minus_mean_ttt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "26818aaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "#x_minus_mean_torch_padded = pad_activation(x_minus_mean_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "2147c40d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#x_minus_mean_torch_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "651c2d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_inv_data = sqrt_inv.to(host).data()\n",
    "sqrt_inv_data = torch.Tensor(sqrt_inv_data).reshape((1,1,H,W))\n",
    "sqrt_inv_data = untilize(sqrt_inv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "50c0248d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 32, 32])"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sqrt_inv_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "17db120a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_div_sqrt_torch = torch.mul(x_minus_mean_ttt, sqrt_inv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b6b924c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0246, -0.9302, -0.9479,  1.0013, -0.9463, -0.9706,  0.8443, -0.9657,\n",
       "         0.9412,  0.0000,  0.0000,  0.0000], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_div_sqrt_torch[0][0][0][0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "83b3285c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.9000, 1.0000, 0.8900, 0.9200, 1.0000, 1.0000, 0.9600, 1.0000, 0.9400,\n",
       "        0.0000, 0.0000, 0.0000], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gamma_padded[0][0][0][0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "473a879a",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gamma_torch = torch.mul(x_div_sqrt_torch, gamma_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "61cae11d",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = torch.add(x_gamma_torch, beta_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "feca30a4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.0221, -0.8302, -0.8437,  0.9212, -0.8963, -0.9106,  0.8106, -0.9357,\n",
       "         0.8847,  0.0000,  0.0000,  0.0000], grad_fn=<SliceBackward0>)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0][0][0][0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "10fedd32",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.3001e-07, -8.5346e-01, -8.8909e-01,  9.1273e-01, -9.2849e-01,\n",
       "         -9.3449e-01,  8.1135e-01, -9.6970e-01,  8.9625e-01],\n",
       "        [-5.3001e-07,  1.0535e+00,  8.8909e-01, -9.1273e-01,  1.0285e+00,\n",
       "          1.0545e+00, -8.1135e-01,  1.0297e+00, -8.9625e-01]],\n",
       "       grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "33acbedc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(False,\n",
       " 'Max ATOL Delta: 0.048714399337768555, Max RTOL Delta: 1.0, PCC: 0.999841819898014')"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "comp_allclose_and_pcc(bn_out[1], Y[1][0][0][0:9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db23ea45",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "9a476c5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum_torch = torch.tensor([[[W*[momentum]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "83dde38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum_padded = pad_activation(momentum_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "e781c0a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum_tilized = tilize_to_list(momentum_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "16af9561",
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum_tt = ttl.tensor.Tensor(momentum_tilized, [1, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "311c8550",
   "metadata": {},
   "outputs": [],
   "source": [
    "ones_tt = ttl.tensor.fill_ones_rm(1, 1, H, W, 1, W, momentum_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bbbf1c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ttl.tensor.fill_rm()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "adb05888",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=4\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Generating defines for TRISCs\n",
      "Compiling RISCID=0\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=1\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=2\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=3\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=4\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=0\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Generating defines for TRISCs\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=1\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=2\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=3\n"
     ]
    }
   ],
   "source": [
    "running_mean_left = ttl.tensor.mul(ttl.tensor.sub(ones_tt, momentum_tt), running_mean_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "858b9753",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean_right = ttl.tensor.mul(momentum_tt, mean_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "c108f4ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean_tt_new = ttl.tensor.add(running_mean_left, running_mean_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "6867d5b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean_tt_new_data = running_mean_tt_new.to(host).data()\n",
    "running_mean_tt_new_data = torch.Tensor(running_mean_tt_new_data).reshape((1,1,H,W))\n",
    "running_mean_tt_new_data = untilize(running_mean_tt_new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "9d2d05b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2139,  0.0947, -0.0408,  0.2500,  0.2207,  0.1836,  0.1523,  0.2949,\n",
       "         0.1895,  0.0000,  0.0000,  0.0000])"
      ]
     },
     "execution_count": 122,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_mean_tt_new_data[0][0][0][0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "fa29e5f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2140,  0.0947, -0.0411,  0.2506,  0.2207,  0.1837,  0.1531,  0.2950,\n",
       "         0.1891])"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moving_mean_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "772d4524",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_var_left = ttl.tensor.mul(ttl.tensor.sub(one_tt, momentum_tt), running_var_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "0a587785",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_var_right = ttl.tensor.mul(momentum_tt, var_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "f46353e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_var_tt_new = ttl.tensor.add(running_var_left, running_var_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "28033c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_var_tt_new_data = running_var_tt_new.to(host).data()\n",
    "running_var_tt_new_data = torch.Tensor(running_var_tt_new_data).reshape((1,1,H,W))\n",
    "running_var_tt_new_data = untilize(running_var_tt_new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "5632c304",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3574, 0.7070, 0.9180, 0.7656, 0.9805, 0.1226, 0.3477, 1.0859, 0.7422,\n",
       "        0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 136,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_var_tt_new_data[0][0][0][0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "19259773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.3564, 0.7075, 0.9148, 0.7627, 0.9783, 0.1224, 0.3490, 1.0888, 0.7399])"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "moving_var_torch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d563f4f1",
   "metadata": {},
   "source": [
    "### Functionalizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "43926be6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tt_batch_norm(x, gamma, beta, running_mean, running_var, eps:float, momentum:float, mode = 'train'):\n",
    "    H = 32\n",
    "    W = 32\n",
    "    batch_size = 2\n",
    "    # Use is_grad_enabled to determine whether we are in training mode\n",
    "    if mode == 'inference':\n",
    "        # In prediction mode, use mean and variance obtained by moving average\n",
    "        print('pred mode') \n",
    "        var_plus_eps = ttl.tensor.add(eps, running_var)\n",
    "        sqrt_var = ttl.tensor.sqrt(var_plus_eps)\n",
    "        sqrt_inv = ttl.tensor.recip(sqrt_var)\n",
    "        x_minus_mean = ttl.tensor.sub(x, running_mean)\n",
    "        x_div_sqrt = ttl.tensor.mul(x_minus_mean, sqrt_inv)\n",
    "        x_gamma = ttl.tensor.mul(x_div_sqrt, gamma)\n",
    "        Y = ttl.tensor.add(x_gamma, beta)\n",
    "    else:\n",
    "        print('train mode')\n",
    "        x_tor = x.to(host).data()\n",
    "        x_tor = torch.Tensor(x_tor).reshape((batch_size,1,H,W))\n",
    "        x_tor = untilize(x_tor)\n",
    "        mean = x_tor.mean(dim=0)\n",
    "        var = ((x_tor - mean) ** 2).mean(dim=0)\n",
    "        var_reshaped = var.view(1, 1, 32, 32)\n",
    "        var_tilized = tilize_to_list(var_reshaped)\n",
    "        var_tt = ttl.tensor.Tensor(var_tilized, [1, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)\n",
    "        \n",
    "\n",
    "        # In training mode, the current mean and variance are used\n",
    "        epsilon_torch = torch.tensor([[[W*[eps]]]])\n",
    "        epsilon_padded = pad_activation(epsilon_torch)\n",
    "        epsilon_tilized = tilize_to_list(epsilon_padded)\n",
    "        eps_tt = ttl.tensor.Tensor(epsilon_tilized, [1, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)\n",
    "\n",
    "        var_plus_eps = ttl.tensor.add(eps_tt, var_tt)\n",
    "        sqrt_var = ttl.tensor.sqrt(var_plus_eps)\n",
    "        sqrt_inv = ttl.tensor.recip(sqrt_var)\n",
    "        sqrt_inv_data = sqrt_inv.to(host).data()\n",
    "        sqrt_inv_data = torch.Tensor(sqrt_inv_data).reshape((1,1,H,W))\n",
    "        sqrt_inv_data = untilize(sqrt_inv_data)\n",
    "        x_minus_mean = x_tor - mean\n",
    "        x_div_sqrt_tor = torch.mul(x_minus_mean, sqrt_inv_data)\n",
    "\n",
    "        # Update the mean and variance using moving average\n",
    "        momentum_torch = torch.tensor([[[W*[momentum]]]])\n",
    "        momentum_padded = pad_activation(momentum_torch)\n",
    "        momentum_tilized = tilize_to_list(momentum_padded)\n",
    "        momentum_tt = ttl.tensor.Tensor(momentum_tilized, [1, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)\n",
    "        ones_tt = ttl.tensor.fill_ones_rm(1, 1, H, W, 1, W, momentum_tt)\n",
    "\n",
    "        running_mean_left = ttl.tensor.mul(ttl.tensor.sub(ones_tt, momentum_tt), running_mean)\n",
    "        mean_reshaped = mean.view(1, 1, 32, 32)\n",
    "        mean_tilized = tilize_to_list(mean_reshaped)\n",
    "        mean_tt = ttl.tensor.Tensor(mean_tilized, [1, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)\n",
    "        running_mean_right = ttl.tensor.mul(momentum_tt, mean_tt)\n",
    "        running_mean = ttl.tensor.add(running_mean_left, running_mean_right)\n",
    "        \n",
    "        running_var_left = ttl.tensor.mul(ttl.tensor.sub(ones_tt, momentum_tt), running_var)\n",
    "        running_var_right = ttl.tensor.mul(momentum_tt, var_tt)\n",
    "        running_var = ttl.tensor.add(running_var_left, running_var_right)\n",
    "\n",
    "    gamma_tor = gamma.to(host).data()\n",
    "    gamma_tor = torch.Tensor(gamma_tor).reshape((1,1,H,W))\n",
    "    gamma_tor = untilize(gamma_tor)\n",
    "    \n",
    "    beta_tor = beta.to(host).data()\n",
    "    beta_tor = torch.Tensor(beta_tor).reshape((1,1,H,W))\n",
    "    beta_tor = untilize(beta_tor)\n",
    "    \n",
    "    x_gamma_tor = torch.mul(x_div_sqrt_tor, gamma_tor)\n",
    "    \n",
    "    Y = torch.add(x_gamma_tor, beta_tor)\n",
    "    Y_tilized = tilize_to_list(Y)\n",
    "    Y_tt = ttl.tensor.Tensor(Y_tilized, [batch_size, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)\n",
    "     \n",
    "    return Y_tt, running_mean.data, running_var.data, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "id": "b372815b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ttBatchNorm(nn.Module):\n",
    "    # num_features: the number of outputs for a fully connected layer or the\n",
    "    # number of output channels for a convolutional layer. num_dims: 2 for a\n",
    "    # fully connected layer and 4 for a convolutional layer\n",
    "    def __init__(self, num_features, num_dims, gamma, beta, running_mean, running_var, epsilon: float):\n",
    "        super().__init__()\n",
    "        if num_dims == 2:\n",
    "            shape = (1, num_features)\n",
    "        else:\n",
    "            shape = (1, num_features, 1, 1)\n",
    "        # The scale parameter and the shift parameter (model parameters) are\n",
    "        # initialized to 1 and 0, respectively\n",
    "#         self.gamma = nn.Parameter(torch.ones(shape))\n",
    "#         self.beta = nn.Parameter(torch.zeros(shape))\n",
    "#         # The variables that are not model parameters are initialized to 0 and\n",
    "#         # 1\n",
    "#         self.moving_mean = torch.zeros(shape)\n",
    "#         self.moving_var = torch.ones(shape)\n",
    "        \n",
    "        self.gamma = gamma\n",
    "        self.beta = beta\n",
    "        # The variables that are not model parameters are initialized to 0 and\n",
    "        # 1\n",
    "        self.running_mean = running_mean\n",
    "        self.running_var = running_var\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, X):\n",
    "        # Save the updated moving_mean and moving_var\n",
    "        Y, self.running_mean, self.running_var, mean = tt_batch_norm(X, self.gamma, self.beta, self.running_mean, self.running_var, eps=self.epsilon, momentum=0.1)\n",
    "        print('Y:', Y,'\\nmoving_mean:', self.running_mean, '\\nmoving_var:', self.running_var, '\\n')\n",
    "        return Y, mean, self.running_mean, self.running_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 203,
   "id": "6c6816b6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tt_bn = ttBatchNorm(32, 2, gamma_tt, beta_tt, running_mean_tt, running_var_tt, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "id": "af4dcc35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mode\n",
      "Y: <tt_lib.tensor.Tensor object at 0x7f581d9d5130> \n",
      "moving_mean: <bound method PyCapsule.data of <tt_lib.tensor.Tensor object at 0x7f581d9d5eb0>> \n",
      "moving_var: <bound method PyCapsule.data of <tt_lib.tensor.Tensor object at 0x7f581d9d5cb0>> \n",
      "\n"
     ]
    }
   ],
   "source": [
    "Y_out, mean_out, running_mean_out, running_var_out = tt_bn(images_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "id": "bbcaf6d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ [[[0, -0.832031, -0.835938, 0.902344, -0.910156, -0.914062, 0.785156, -0.9375, 0.875, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]],\n",
      "\n",
      "\n",
      "  [[[0, 1.03125, 0.835938, -0.902344, 1.00781, 1.03125, -0.785156, 0.996094, -0.875, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
      "    [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]] dtype=bfloat16 ]\n"
     ]
    }
   ],
   "source": [
    "Y_out.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7be4e674",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

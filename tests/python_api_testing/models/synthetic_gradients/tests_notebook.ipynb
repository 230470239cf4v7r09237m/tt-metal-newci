{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "33745436",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/farbabi/git/tt-metal/build/python_env/lib/python3.8/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch \n",
    "import torchvision.transforms as transforms\n",
    "from torch.autograd import Variable\n",
    "import numpy as np\n",
    "import math\n",
    "from torchvision import datasets\n",
    "import matplotlib.pyplot as plt\n",
    "from time import time\n",
    "from torch import nn, optim\n",
    "import argparse\n",
    "import csv\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bcf02200",
   "metadata": {},
   "source": [
    "tt metal libs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "172b5f5c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/farbabi/git/tt-metal\n"
     ]
    }
   ],
   "source": [
    "cd /home/farbabi/git/tt-metal/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7b991ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, os\n",
    "from pathlib import Path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb5b83f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: TT_METAL_ENV=dev\n",
      "env: TT_METAL_HOME=/home/farbabi/git/tt-metal\n"
     ]
    }
   ],
   "source": [
    "%env TT_METAL_ENV=dev\n",
    "%env TT_METAL_HOME=/home/farbabi/git/tt-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "679f6416",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.append(\"../..\")\n",
    "sys.path.append(\"../../..\")\n",
    "sys.path.append(\"../../../..\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e587127c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/home/farbabi/git/tt-metal/tests/python_api_testing/models/synthetic_gradients', '/usr/lib/python38.zip', '/usr/lib/python3.8', '/usr/lib/python3.8/lib-dynload', '', '/home/farbabi/git/tt-metal/build/python_env/lib/python3.8/site-packages', '/home/farbabi/git/tt-metal/libs', '../..', '../../..', '../../../..']\n"
     ]
    }
   ],
   "source": [
    "print(sys.path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8e5ddc1c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/farbabi/git/tt-metal'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "94148e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.listdir() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cddf81e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs import tt_lib as ttl\n",
    "from tests.python_api_testing.models.utility_functions import tilize_to_list, untilize, comp_allclose_and_pcc\n",
    "from libs.tt_lib.utils import pad_activation, pad_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9eebb92d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m                 Device\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | SOC descriptors loaded /home/farbabi/git/tt-metal/tt_metal/device/grayskull_120_arch.yaml\n",
      "\u001b[38;2;000;128;000m                 Device\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Network descriptor loaded \n",
      "Device reservations file does not exist at /tmp/tenstorrent/tt_device_reservations.yaml, using 13 detected devices set \n",
      "\u001b[0mDetected 13 PCI devices\n",
      "\u001b[0mOpening TT_PCI_INTERFACE_ID 0 for netlist target_device_id: 0\n",
      "\u001b[0mPCIEIntfId   0x0\n",
      "\u001b[0mVID:DID      0x1e52:0xfaca\n",
      "\u001b[0mSubVID:SubID 0x1e52:0x3\n",
      "\u001b[0mBSF          41:0:0\n",
      "\u001b[0mBAR          0x20000000000  size: 48MB\n",
      "\u001b[0mHARVESTING DISABLED = 0x0 (memory: 0x0 logic: 0x0)\n",
      "\u001b[0mHARVESTING DISABLED = 0x0 (memory: 0x0 logic: 0x0)\n",
      "\u001b[0mDisable PCIE DMA\n",
      "\u001b[0m\u001b[38;2;000;128;000m              LLRuntime\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | AI CLK for device 0 is:   1202 MHz\n"
     ]
    }
   ],
   "source": [
    "device = ttl.device.CreateDevice(ttl.device.Arch.GRAYSKULL, 0)\n",
    "ttl.device.InitializeDevice(device)\n",
    "host = ttl.device.GetHost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "064cc389",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/farbabi/git/tt-metal'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "os.getcwd() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "2fb850a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.20.3\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6dbc5fc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.1307,), (0.3081,)),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e47da902",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "be23960e",
   "metadata": {},
   "outputs": [],
   "source": [
    "use_cuda = torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "7daa7779",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m              LLRuntime\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Resetting device AICLK\n",
      "\u001b[38;2;000;128;000m              LLRuntime\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Setting silicon device power state to LONG_IDLE\n"
     ]
    }
   ],
   "source": [
    "#device = torch.device(\"cuda\" if use_cuda else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "43f9a032",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device.type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac4e4cbe",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "test_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "if use_cuda:\n",
    "    cuda_kwargs = {'num_workers': 1,\n",
    "                   'pin_memory': True\n",
    "                   }\n",
    "    train_kwargs.update(cuda_kwargs)\n",
    "    test_kwargs.update(cuda_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "9c3dbc7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TRAINSET/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 9912422/9912422 [00:00<00:00, 63913664.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TRAINSET/MNIST/raw/train-images-idx3-ubyte.gz to tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TRAINSET/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TRAINSET/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 51481382.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TRAINSET/MNIST/raw/train-labels-idx1-ubyte.gz to tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TRAINSET/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TRAINSET/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:00<00:00, 7304166.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TRAINSET/MNIST/raw/t10k-images-idx3-ubyte.gz to tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TRAINSET/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TRAINSET/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 8158684.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TRAINSET/MNIST/raw/t10k-labels-idx1-ubyte.gz to tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TRAINSET/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-images-idx3-ubyte.gz to tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TESTSET/MNIST/raw/train-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 9912422/9912422 [00:00<00:00, 65405477.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TESTSET/MNIST/raw/train-images-idx3-ubyte.gz to tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TESTSET/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/train-labels-idx1-ubyte.gz to tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TESTSET/MNIST/raw/train-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████| 28881/28881 [00:00<00:00, 57601376.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TESTSET/MNIST/raw/train-labels-idx1-ubyte.gz to tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TESTSET/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-images-idx3-ubyte.gz to tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TESTSET/MNIST/raw/t10k-images-idx3-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████| 1648877/1648877 [00:00<00:00, 19232071.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TESTSET/MNIST/raw/t10k-images-idx3-ubyte.gz to tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TESTSET/MNIST/raw\n",
      "\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz\n",
      "Downloading http://yann.lecun.com/exdb/mnist/t10k-labels-idx1-ubyte.gz to tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TESTSET/MNIST/raw/t10k-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████████████████████████████████████| 4542/4542 [00:00<00:00, 9794616.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TESTSET/MNIST/raw/t10k-labels-idx1-ubyte.gz to tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TESTSET/MNIST/raw\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "trainset = datasets.MNIST('tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TRAINSET', download=True, train=True, transform=transform)\n",
    "testset = datasets.MNIST('tests/python_api_testing/models/synthetic_gradients/PATH_TO_STORE_TESTSET', download=True, train=False, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, **train_kwargs)\n",
    "testloader = torch.utils.data.DataLoader(testset, **test_kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "810f42dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 1, 28, 28])\n",
      "torch.Size([2])\n"
     ]
    }
   ],
   "source": [
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "\n",
    "print(images.shape)\n",
    "print(labels.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "1cd55f2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          ...,\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]],\n",
       "\n",
       "\n",
       "        [[[-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          ...,\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242],\n",
       "          [-0.4242, -0.4242, -0.4242,  ..., -0.4242, -0.4242, -0.4242]]]])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "e634cca3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 7])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6604cd5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7f5e08901e50>"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[0].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "6cea6eb8",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "index 2 is out of bounds for dimension 0 with size 2",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[39], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m plt\u001b[38;5;241m.\u001b[39msubplot(\u001b[38;5;241m6\u001b[39m, \u001b[38;5;241m10\u001b[39m, index)\n\u001b[1;32m      5\u001b[0m plt\u001b[38;5;241m.\u001b[39maxis(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moff\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m plt\u001b[38;5;241m.\u001b[39mimshow(\u001b[43mimages\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m]\u001b[49m\u001b[38;5;241m.\u001b[39mnumpy()\u001b[38;5;241m.\u001b[39msqueeze(), cmap\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mgray_r\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mIndexError\u001b[0m: index 2 is out of bounds for dimension 0 with size 2"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "figure = plt.figure()\n",
    "num_of_images = 60\n",
    "for index in range(1, num_of_images + 1):\n",
    "    plt.subplot(6, 10, index)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(images[index].numpy().squeeze(), cmap='gray_r')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d14b26",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ca0375f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_criterion = nn.MSELoss(reduction = 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d7c0e31",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_size = 256\n",
    "hidden_size_syn = 1024\n",
    "output_size = 10\n",
    "learning_rate = 3e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d126db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization(model, learning_rate = learning_rate):\n",
    "    optimizer = optim.SGD(model.parameters(), lr = learning_rate)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "124e5691",
   "metadata": {},
   "source": [
    "# Adding Batch Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe885954",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(network, self).__init__()\n",
    "        \n",
    "        self.layer = nn.Sequential(nn.Linear(input_dim, output_dim),\n",
    "                                   nn.BatchNorm1d(output_dim),\n",
    "                                   nn.ReLU())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "046bc313",
   "metadata": {},
   "outputs": [],
   "source": [
    "class syn_network(nn.Module):\n",
    "    def __init__(self, hidden_dim, syn_hid_dim = 1024):\n",
    "        super(syn_network, self).__init__()\n",
    "\n",
    "        # dni network\n",
    "        self.layer = nn.Sequential(nn.Linear(hidden_dim, syn_hid_dim),\n",
    "           nn.BatchNorm1d(syn_hid_dim),\n",
    "           nn.ReLU(),\n",
    "           nn.Linear(syn_hid_dim, syn_hid_dim),\n",
    "           nn.BatchNorm1d(syn_hid_dim),\n",
    "           nn.ReLU(),\n",
    "           nn.Linear(syn_hid_dim, hidden_dim))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd9cc8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimization(model, learning_rate = learning_rate):\n",
    "    optimizer = optim.Adam(model.parameters(), lr = learning_rate)\n",
    "    return optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8e2bd5b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_weights(m):\n",
    "    if isinstance(m, nn.Linear):\n",
    "        m.weight.data.fill_(0.0)\n",
    "        m.bias.data.fill_(0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d193da3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hook():\n",
    "    def __init__(self, module, backward = False):\n",
    "        if backward == False:\n",
    "            self.hook = module.register_forward_hook(self.hook_activations)\n",
    "        else:\n",
    "            self.hook = module.register_full_backward_hook(self.hook_gradients)\n",
    "            \n",
    "    def hook_activations(self, module, inputs, outputs):\n",
    "        self.outputs = outputs\n",
    "        \n",
    "    def hook_gradients(self, module, grad_input, grad_output):\n",
    "        self.grad_output = grad_output\n",
    "        \n",
    "    def hook_close(self):\n",
    "        self.hook.remove()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fac864",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_syn(model_syn, sg_criterion, g_pred, z, optimizer_syn):\n",
    "    model_syn.train()\n",
    "    optimizer_syn.zero_grad()\n",
    "    loss = sg_criterion(g_pred, z.clone().detach())\n",
    "    loss.backward()\n",
    "    optimizer_syn.step()\n",
    "    model_syn.eval()\n",
    "    return model_syn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5267150",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_update_syntarget(h, model_layer, model_syn, hook_gradients_i, pre_sg = False):\n",
    "    g_sg = model_syn(h.clone().detach())\n",
    "    h.backward(g_sg.clone().detach())\n",
    "    z_pre = None\n",
    "    if pre_sg:\n",
    "        grad_ln = hook_gradients_i.grad_output[0]\n",
    "        z_pre = torch.matmul(grad_ln.detach().clone(), model_layer[0].weight.clone().detach())\n",
    "    return g_sg, z_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46c9dfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(models, device, testloader, epoch, results):\n",
    "    print_threshold = 1\n",
    "    store_threshold = 1\n",
    "    model_test = nn.Sequential(models[0].layer, models[1].layer, models[2].layer, \n",
    "                               models[3].layer, models[4].layer, models[5].layer)\n",
    "    model_test.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for images, target in testloader:\n",
    "            images, target = images.to(device), target.to(device)\n",
    "            images = images.view(images.shape[0], -1)\n",
    "            if images.shape[0] != 256:\n",
    "                    continue\n",
    "            output = model_test(images)\n",
    "            test_loss = torch.nn.functional.nll_loss(output, target, reduction = 'sum').item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "            \n",
    "    test_loss/= len(testloader.dataset)\n",
    "\n",
    "    for i in [round(test_loss,6), round(100.0*correct/len(testloader.dataset),4), round(100-100. * correct / len(testloader.dataset),4)]:\n",
    "        results.append(str(i))\n",
    "\n",
    "    if print_threshold != False:\n",
    "        if epoch % print_threshold == 0:\n",
    "            print(\"Test loss: {:.6f} | Test Accuracy: {}/{} ({:.4f}%)\\n\".format(\n",
    "            test_loss, correct, len(testloader.dataset),\n",
    "            100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8848958",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(models, syn_models, device, trainloader, optimizers, optimizers_syn, criterion, sg_criterion, epoch, hook_gradients, results):\n",
    "\n",
    "    print_threshold = 1\n",
    "    store_threshold = 1\n",
    "    eps = 1e-5\n",
    "    training_loss = 0\n",
    "        \n",
    "    for module in models:\n",
    "        module.train()\n",
    "\n",
    "    for batch_idx, (images, labels) in enumerate(trainloader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        # Flatten MNIST images into a 784 long vector\n",
    "        images = images.view(images.shape[0], -1)\n",
    "        if images.shape[0] != 256:\n",
    "                continue\n",
    "\n",
    "        # Training pass\n",
    "        for opt in optimizers:\n",
    "            opt.zero_grad()\n",
    "\n",
    "        # feed forward layer0 and update by g_sg\n",
    "        h0 = models[0].layer(images)\n",
    "        g_sg0, _ = backward_update_syntarget(h0, models[0].layer, syn_models[0].layer, hook_gradients[0], pre_sg = False)\n",
    "        optimizers[0].step()\n",
    "        #####\n",
    "        \n",
    "        # feed forward layer1 and update by g_sg\n",
    "        h1 = models[1].layer(h0.clone().detach().requires_grad_(True))\n",
    "        g_sg1, z0 = backward_update_syntarget(h1, models[1].layer, syn_models[1].layer, hook_gradients[1], pre_sg = True)\n",
    "        optimizers[1].step()\n",
    "        # train previous layer synthetic model\n",
    "        syn_models[0].layer = training_syn(syn_models[0].layer, sg_criterion, g_sg0, z0, optimizers_syn[0])\n",
    "        #####\n",
    "        \n",
    "        # feed forward layer2 and update by g_sg\n",
    "        h2 = models[2].layer(h1.clone().detach().requires_grad_(True))\n",
    "        g_sg2, z1 = backward_update_syntarget(h2, models[2].layer, syn_models[2].layer, hook_gradients[2], pre_sg = True)\n",
    "        optimizers[2].step()\n",
    "        # train previous layer synthetic model\n",
    "        syn_models[1].layer = training_syn(syn_models[1].layer, sg_criterion, g_sg1, z1, optimizers_syn[1])\n",
    "        #####\n",
    "        \n",
    "        # feed forward layer3 and update by g_sg\n",
    "        h3 = models[3].layer(h2.clone().detach().requires_grad_(True))\n",
    "        g_sg3, z2 = backward_update_syntarget(h3, models[3].layer, syn_models[3].layer, hook_gradients[3], pre_sg = True)\n",
    "        optimizers[3].step()\n",
    "        # train previous layer synthetic model\n",
    "        syn_models[2].layer = training_syn(syn_models[2].layer, sg_criterion, g_sg2, z2, optimizers_syn[2])\n",
    "        #####\n",
    "        \n",
    "        # feed forward layer4 and update by g_sg\n",
    "        h4 = models[4].layer(h3.clone().detach().requires_grad_(True))\n",
    "        g_sg4, z3 = backward_update_syntarget(h4, models[4].layer, syn_models[4].layer, hook_gradients[4], pre_sg = True)\n",
    "        optimizers[4].step()\n",
    "        # train previous layer synthetic model\n",
    "        syn_models[3].layer = training_syn(syn_models[3].layer, sg_criterion, g_sg3, z3, optimizers_syn[3])\n",
    "        #####\n",
    "\n",
    "        # feed forward layer 5 and backprop / update layer 5\n",
    "        h5 = models[5].layer(h4.clone().detach().requires_grad_(True))\n",
    "        loss = criterion(h5, labels)\n",
    "        loss.backward()\n",
    "        grad_ln5 = hook_gradients[5].grad_output[0]\n",
    "        z4 = torch.matmul(grad_ln5.detach().clone(), models[5].layer[0].weight.clone().detach())\n",
    "        optimizers[5].step()\n",
    "\n",
    "        syn_models[4].layer = training_syn(syn_models[4].layer, sg_criterion, g_sg4, z4, optimizers_syn[4])\n",
    "\n",
    "        training_loss += loss.item()\n",
    "        training_loss_norm = training_loss/len(trainloader)\n",
    "\n",
    "    for i in [epoch, round(training_loss_norm,6)]:\n",
    "        results.append(str(i))\n",
    "\n",
    "    if print_threshold != False:\n",
    "        if epoch % print_threshold == 0:\n",
    "            print(\"Epoch {} \\nTraining loss: {}\".format(epoch, training_loss_norm))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d1efe50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    model_version = 'FC_FD_MNIST_V01'\n",
    "    print_threshold = 1\n",
    "    store_threshold = 1\n",
    "    if print_threshold != False:\n",
    "        print(time.asctime(), f' {model_version} execution started...')\n",
    "    input_size = 784\n",
    "    hidden_size = 256\n",
    "    hidden_size_syn = 1024\n",
    "    output_size = 10\n",
    "    batch_size = 256\n",
    "    epochs = 2000\n",
    "    \n",
    "    use_cuda = torch.cuda.is_available()\n",
    "    device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
    "    print('Device: ', device.type, '\\n')\n",
    "    \n",
    "    train_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "    test_kwargs = {'batch_size': batch_size, 'shuffle': True}\n",
    "    if use_cuda:\n",
    "        cuda_kwargs = {'num_workers': 1,\n",
    "                   'pin_memory': True}\n",
    "        train_kwargs.update(cuda_kwargs)\n",
    "        test_kwargs.update(cuda_kwargs)\n",
    "        \n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              transforms.Normalize((0.1307,), (0.3081,)),\n",
    "                              ])\n",
    "    trainset = datasets.MNIST('./PATH_TO_STORE_TRAINSET', download=True, train=True, transform=transform)\n",
    "    testset = datasets.MNIST('./PATH_TO_STORE_TESTSET', download=True, train=False, transform=transform)\n",
    "    trainloader = torch.utils.data.DataLoader(trainset, **train_kwargs)\n",
    "    testloader = torch.utils.data.DataLoader(testset, **test_kwargs)\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    sg_criterion = nn.MSELoss(reduction = 'sum')\n",
    "    \n",
    "    syn_models, optimizers_fc, optimizers_syn = [], [], []\n",
    "    \n",
    "    # building models\n",
    "    fc_models = [network(input_size, hidden_size).to(device), network(hidden_size, hidden_size).to(device), \n",
    "             network(hidden_size, hidden_size).to(device), network(hidden_size, hidden_size).to(device),\n",
    "             network(hidden_size, hidden_size).to(device), network(hidden_size, output_size).to(device)]\n",
    "\n",
    "    for i in range(5):\n",
    "        syn_models.append(syn_network(hidden_size).to(device))\n",
    "        \n",
    "    for syn_model in syn_models:\n",
    "        syn_model.apply(init_weights)\n",
    "        \n",
    "    # setting optimizers    \n",
    "    for fc_model in fc_models:\n",
    "        optimizers_fc.append(optimization(fc_model))\n",
    "        \n",
    "    for syn_model in syn_models:\n",
    "        optimizers_syn.append(optimization(syn_model))\n",
    "    \n",
    "    # setting hooks\n",
    "    hook_gradients = [Hook(model.layer[0], backward = True) for model in fc_models]\n",
    "    \n",
    "    scheduler = torch.optim.lr_scheduler.MultiStepLR(optimizers_fc[5], milestones=[3e5, 4e5], gamma = 0.1)\n",
    "\n",
    "    with open(f'./results_{model_version}.csv', 'w', newline='') as f:\n",
    "        f.write(\"epoch, training_loss, test_loss, test_accuracy, test_error, timestamp, run_time\\n\")\n",
    "\n",
    "    time0 = time.time()\n",
    "    for epoch in range(1, epochs+1):\n",
    "        results = []\n",
    "        results_syn = []\n",
    "        train(fc_models, syn_models, device, trainloader, optimizers_fc, optimizers_syn, criterion, sg_criterion, epoch, hook_gradients, results)\n",
    "        test(fc_models, device, testloader, epoch, results)\n",
    "        scheduler.step()\n",
    "        if epoch % store_threshold == 0:\n",
    "            results.append(time.asctime())\n",
    "            results.append(round((time.time()-time0)/60, 6))\n",
    "            if epoch % store_threshold*1000 == 0:\n",
    "                fc_models_state = []\n",
    "                for module in fc_models:\n",
    "                    fc_models_state.append(module.state_dict())\n",
    "                syn_models_state = []\n",
    "                for module in syn_models:\n",
    "                    syn_models_state.append(module.state_dict())\n",
    "                torch.save(fc_models_state, f'./model_{model_version}.pt')\n",
    "                torch.save(syn_models_state, f'./model_syn_{model_version}.pt')\n",
    "            with open(f'./results_{model_version}.csv', 'a', newline='') as file:\n",
    "                writer = csv.writer(file)\n",
    "                writer.writerow(results)\n",
    "    if print_threshold != False:\n",
    "        print(\"\\nTraining Time (in minutes) =\",(time.time()-time0)/60, \"\\nEnd Time:\", time.asctime(), \"\\nEpochs:\", epochs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b027b01c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ef56a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_models = [network(input_size, hidden_size).to(device), network(hidden_size, hidden_size).to(device), \n",
    "         network(hidden_size, hidden_size).to(device), network(hidden_size, hidden_size).to(device),\n",
    "         network(hidden_size, hidden_size).to(device), network(hidden_size, output_size).to(device)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9edc4d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for module in fc_models:\n",
    "    module.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5edefc",
   "metadata": {},
   "outputs": [],
   "source": [
    "fc_models_state = []\n",
    "for module in fc_models:\n",
    "    fc_models_state.append(module.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e06c92fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_models_state = []\n",
    "for module in syn_models:\n",
    "    syn_models_state.append(module.state_dict())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c4051d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_gradients = [Hook(model.layer[0], backward = True) for model in fc_models]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a52e457",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in fc_models:\n",
    "    print(i.layer)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a47d09fd",
   "metadata": {},
   "source": [
    "### Testing Manually"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c0f063d",
   "metadata": {},
   "outputs": [],
   "source": [
    "input_size = 784\n",
    "hidden_size = 256\n",
    "hidden_size_syn = 1024\n",
    "output_size = 10\n",
    "learning_rate = 3e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42cbc00a",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "375cbe86",
   "metadata": {},
   "outputs": [],
   "source": [
    "sg_criterion = nn.MSELoss(reduction = 'sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7888658c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model0 = network(784, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6549a8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "model1 = network(256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4115e75",
   "metadata": {},
   "outputs": [],
   "source": [
    "model2 = network(256, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76ce6a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "models = [model0, model1, model2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2343b224",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer0 = optimization(model0, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5139e5f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1 = optimization(model1, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f77a8a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer2 = optimization(model2, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "740d1ad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers = [optimizer0, optimizer1, optimizer2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43d984ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_syn0 = syn_network(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bb498aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_syn1 = syn_network(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68623e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_syn2 = syn_network(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f8b245",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_models = [model_syn0, model_syn1, model_syn2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67cc184a",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_syn0 = optimization(model_syn0, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63cf40ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_syn1 = optimization(model_syn1, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea686418",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_syn2 = optimization(model_syn2, learning_rate=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e228b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers_syn = [optimizer_syn0, optimizer_syn1, optimizer_syn2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "310750d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_syn0.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5e99a41",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_syn1.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff7888e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_syn2.apply(init_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ebeb385",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_gradients = [Hook(layer[0], backward = True) for layer in [model0.layer, model1.layer, model2.layer]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37cccab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = dataiter.next()\n",
    "images = images.view(images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c23abd5d",
   "metadata": {},
   "source": [
    "### With images as input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4689fa33",
   "metadata": {},
   "outputs": [],
   "source": [
    "for opt in optimizers:\n",
    "    opt.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eff1280f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994292d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a141fa14",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].layer[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d867f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "h0 = models[0].layer(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ada1c6ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_gradients[1].grad_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ce4b76e",
   "metadata": {},
   "outputs": [],
   "source": [
    "models[0].layer[0].weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b80ef9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_sg0 = model_syn0.layer(h0.clone().detach().requires_grad_(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ce19f5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_sg0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b0ad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_sg0, _ = backward_update_syntarget(h0, models[0].layer, syn_models[0].layer, hook_gradients[0], pre_sg = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b239fd0",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "g_sg0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e0f13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers[0].step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d630744a",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_gradients[1].grad_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce2a95ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = models[1].layer(h0.clone().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42b5f12",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_sg1, z0 = backward_update_syntarget(h1, models[1].layer, syn_models[1].layer, hook_gradients[1], pre_sg = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ab07d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers[1].step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12f5a4e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_models[0].layer = training_syn(syn_models[0].layer, sg_criterion, g_sg0, z0, optimizers_syn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7932c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "h2 = models[2].layer(h1.clone().detach().requires_grad_(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9211eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(h2, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ae838b",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d27c5c08",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_ln2 = hook_gradients[2].grad_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9054af",
   "metadata": {},
   "outputs": [],
   "source": [
    "z1 = torch.matmul(grad_ln2.detach().clone(), models[2].layer[0].weight.clone().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "055c407f",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizers[2].step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb03fcba",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn_models[1].layer = training_syn(syn_models[1].layer, sg_criterion, g_sg1, z1, optimizers_syn[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05015e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# feed forward layer 5 and backprop / update layer 5\n",
    "h5 = model.layer5(h4.clone().detach().requires_grad_(True))\n",
    "loss = criterion(h5, labels)\n",
    "loss.backward()\n",
    "grad_ln5 = hook_gradients[5].grad_output[0]\n",
    "z4 = torch.matmul(grad_ln5.detach().clone(), model.layer5[0].weight.clone().detach())\n",
    "optimizer5.step()\n",
    "\n",
    "model_syn4 = training_syn(model_syn4, sg_criterion, g_sg4, z4, optimizer_syn4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f13a1e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_update_syntarget(h, model_layer, model_syn, hook_gradients_i, pre_sg = False):\n",
    "    g_sg = model_syn(h.clone().detach())\n",
    "    h.backward(g_sg.clone().detach())\n",
    "    z_pre = None\n",
    "    if pre_sg:\n",
    "        grad_ln = hook_gradients_i.grad_output[0]\n",
    "        z_pre = torch.matmul(grad_ln.detach().clone(), model_layer[0].weight.clone().detach())\n",
    "    return g_sg, z_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60170e07",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_syn0 = training_syn(syn_models[0], sg_criterion, g_sg0, z0, optimizer_syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396b8543",
   "metadata": {},
   "outputs": [],
   "source": [
    "        # feed forward layer1 and update by g_sg\n",
    "        h1 = model.layer1(h0.clone().detach().requires_grad_(True))\n",
    "        z0, g_sg1 = backward_update_syntarget(h1, model.layer1, model_syn1, hook_gradients[1])\n",
    "        optimizer1.step()\n",
    "        \n",
    "        model_syn0 = training_syn(model_syn0, sg_criterion, g_sg0, z0, optimizer_syn0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1080378b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h4.backward(g_sg4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c36e1ee5",
   "metadata": {},
   "outputs": [],
   "source": [
    "h5 = model.layer5(h4.clone().detach().requires_grad_(True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "075d287d",
   "metadata": {},
   "outputs": [],
   "source": [
    "h6 = model.layer6(h5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f435777e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(h6, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7438504e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b27c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layer4[0].weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56458809",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb5 = hook_gradients[0].grad_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6055d70",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa8c9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu5 = hook_activations[1].outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbdd735c",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4347be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh5_dh4 = deriv_act_aft_pre(model.layer5[0].weight, mu5, h5, eps, model.layer5[1].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01b6c37f",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh5_dh4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c621de6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu5 = mu5.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84bf6bf9",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight5 = model.layer5[0].weight.clone().detach(); weight5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "721d479e",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34290884",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_out = h5.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a21eb89b",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma5 = model.layer5[1].weight.clone().detach()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a2ca5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layer5[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e346d75e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb90c08e",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b21409e",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mu5.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c13741c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1a5905",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ba4248a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_mean = torch.mean(mu5, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1603fa40",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a760b0ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_var = ((mu5 - batch_mean)**2).sum(dim = 0)/m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5c3d6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_var = torch.var(mu5, dim = 0, unbiased = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e7a89d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu_var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b822aa4",
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = (1 - 1/m) / torch.sqrt(mu_var + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af3edc37",
   "metadata": {},
   "outputs": [],
   "source": [
    "part1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198ac56b",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_out[h_out > 0.0] = 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e5a3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ea82bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b491d5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c8a311",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e27f9a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def running_mean_var(x, mean, var, epoch):\n",
    "    mean = mean * (epoch -1)/epoch + torch.mean(x, dim = 0)/epoch #New average = old average * (n-1)/n + new value /n\n",
    "    var = var * (epoch -1)/epoch + torch.var(x, dim = 0, unbiased = False)/epoch\n",
    "    \n",
    "    return mean, var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf29642f",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean, running_var = running_mean_var(mu5, batch_mean, batch_var, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd57d054",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_param = {'mode': 'train', 'eps': 1e-5, 'momentum': 0.1, 'running_mean': running_mean, 'running_var': running_var}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e893a5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebee6180",
   "metadata": {},
   "outputs": [],
   "source": [
    "(h_out * gamma5 * part1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214c5a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c700abc",
   "metadata": {},
   "outputs": [],
   "source": [
    "(h_out * gamma5 * part1) * weight5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0b1597",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul((h_out * gamma5 * part1) , weight5.T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5489ff53",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_t = nn.Linear(256, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6330898f",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b69bf69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_t = linear_t(h_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c62e425",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2778370e",
   "metadata": {},
   "outputs": [],
   "source": [
    "h_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f707971d",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_t = linear_t.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddb9b36",
   "metadata": {},
   "outputs": [],
   "source": [
    "bias_t = linear_t.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f23d1dfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_t.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a8f2f05",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.matmul(h_out, weight_t.T) + bias_t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccde93ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "gb5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b145fae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh5_dh4.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b1215bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "z4 = torch.mul(gb5, dh5_dh4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dfbd0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_syn4 = training_syn(model_syn4, sg_criterion, h4, z4, optimizer_syn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40c1650",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.layer4[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cc8801d",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_activations[0].outputs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c64679",
   "metadata": {},
   "source": [
    "### Manual from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "957b34cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1 = nn.Linear(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6d2d28e",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm1 = nn.BatchNorm1d(2, eps = 0, affine = False,track_running_stats = False, momentum = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd76d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear2 = nn.Linear(2,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3b3eb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_activations = [Hook(linear1), Hook(linear2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea8c8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_gradients = [Hook(linear1, backward = True),Hook(linear2, backward = True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f9a99a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1 = optim.SGD(nn.Sequential(linear1, batch_norm1).parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ec61ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer2 = optim.SGD(linear2.parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cadd11d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer_a = optim.SGD(nn.Sequential(linear1, linear2).parameters(), lr = 0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9ac87b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    linear1.weight[0] = torch.tensor([0.1, 0.2])\n",
    "    linear1.weight[1] = torch.tensor([0.3, 0.4])\n",
    "    linear1.bias[0] = 0.1\n",
    "    linear1.bias[1] = 0.3\n",
    "    linear2.weight[0] = torch.tensor([0.5, 0.6])\n",
    "    linear2.weight[1] = torch.tensor([0.7, 0.8])\n",
    "    linear2.bias[0] = 0.2\n",
    "    linear2.bias[1] = 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c13185a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a5c5caa",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear1.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1e33926",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ca23075",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = torch.tensor([[4., 0.5], [1., 3.]], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72b9cdcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e20f84f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu = linear1(x); mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89190650",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_activations[0].outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9881c558",
   "metadata": {},
   "outputs": [],
   "source": [
    "h1 = batch_norm1(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "632e35b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer1.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bda5904",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu2 = linear2(h1.clone().detach())\n",
    "print(mu2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe922349",
   "metadata": {},
   "outputs": [],
   "source": [
    "# mu2 = linear2(h1)\n",
    "# print(mu2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35692f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([[2.3, 1.0], [0.4, 0.8]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "078f3cdb",
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20f4826e",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(mu2, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c34b9228",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6acccefe",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad2_bw = hook_gradients[1].grad_output[0]\n",
    "print(grad2_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a169e826",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dh1 = torch.matmul(grad2_bw, linear2.weight)\n",
    "print(dL_dh1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a4a2a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dw2 = torch.matmul(grad2_bw.T, h1)\n",
    "print(dL_dw2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0558aaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight update\n",
    "linear2_updated_w = linear2.weight - 0.1* dL_dw2\n",
    "print(linear2_updated_w)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b655112",
   "metadata": {},
   "source": [
    "#### finding dh1_dmu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42258495",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mu = grad2_bw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccef5487",
   "metadata": {},
   "outputs": [],
   "source": [
    "m = mu.shape[0]; m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f01b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_var = torch.sqrt(torch.var(mu, unbiased = False, axis = 0)); sqrt_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0387717",
   "metadata": {},
   "outputs": [],
   "source": [
    "part1 = (1-1/m)/sqrt_var; part1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa369a03",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93de48b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sigx = torch.sum(mu, axis = 0); sigx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6cb5cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "part2a = 1/m - 2*sigx/(m**2); part2a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf5e2e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "part2b = mu - 1/m * (sigx); part2b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ad1d098",
   "metadata": {},
   "outputs": [],
   "source": [
    "part2_top = torch.matmul(part2a, part2b); part2_top"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54de257d",
   "metadata": {},
   "outputs": [],
   "source": [
    "part2 = part2_top/(2.0*torch.pow(torch.var(mu, unbiased = False, axis = 0), 1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57afcdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "part2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "082132dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "dh1_dmu1 = part1 - part2; dh1_dmu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "feca8a40",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dh1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde03af6",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dmu1 = torch.matmul(dL_dh1, dh1_dmu1); dL_dmu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a3f2036",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7385152f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef850cfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dac25968",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer2.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0b31ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear2.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e6e076c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#grad1_manual = dL_dh1 * dh1_dmu1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47559e0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu.backward(grad1_manual)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c6dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# grad1 to be calculated manually\n",
    "grad1_bw = hook_gradients[0].grad_output[0]\n",
    "print(grad1_bw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3c98205",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dw1 = torch.matmul(grad1_bw.T, x)\n",
    "print(dL_dw1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8184851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# weight update\n",
    "linear1_updated_w = linear1.weight - 0.1* dL_dw1\n",
    "print(linear1_updated_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "016e7e64",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer1.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c1d9ea7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linear1_updated_w = linear1.weight\n",
    "print(linear1_updated_w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b33eb26",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "linear1.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ca5c64",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9762a1a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#optimizer_a.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "243307c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_norm = nn.BatchNorm1d(2, eps = 0, affine = False,track_running_stats = False, momentum = 0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "609ff73c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#batch_norm = nn.BatchNorm1d(4, eps = 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d305dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu = nn.ReLU()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fb241b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "syn = syn_network(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98fa1442",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f973544",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_norm.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f7bfd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.tensor([[1.0, 0.0, 5.0, 9.0], [22.0, 3.0, 4.0, 7.0], [2.0, 23.0, 42.0, 7.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d10eafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.tensor([[10.0, 0.0, 50.0, 90.0], [20.0, 43.0, 4.0, 40.0], [-20.0, 3.0, -44.0, 270.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3232af95",
   "metadata": {},
   "outputs": [],
   "source": [
    "inp = torch.tensor([[13.0, 0.0, -30.0, 90.0], [-4.0, 3.0, -4.0, 4.0],[1.0, 0.0, 5.0, 9.0]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45d34410",
   "metadata": {},
   "outputs": [],
   "source": [
    "#mu = linear(inp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e2e0687",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59127c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_out = batch_norm(mu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e5f8a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "norm_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7804487",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_out = relu(norm_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a01c834d",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6050f339",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = batch_norm.weight; gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de289162",
   "metadata": {},
   "outputs": [],
   "source": [
    "g_sg = syn(relu_out.clone().detach().requires_grad_(True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "743972ee",
   "metadata": {},
   "source": [
    "#### optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a66c829a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = nn.Sequential(linear, batch_norm, relu)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db83e565",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optimization(model, learning_rate=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db1c16d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b366ffa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7dfd7b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dw = loss_grad(inp, relu_out, mu, g_sg, eps, gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bc2131e",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94561dc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_before = linear.weight.clone().detach(); weight_before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "915b4338",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21457d30",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_out.backward(dL_dw.clone().detach())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad0c2457",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63aa3349",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c51a95ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa5e1899",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.param_groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b63a427",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_after = linear.weight.clone().detach(); weight_after"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0e5d7cf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(weight_before == weight_after)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd15b25e",
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d355d6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([0, 1, 1, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ac5dcc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = criterion(h2, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640d2c77",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49eb6260",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3eaf1bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linear.weight.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7fb3b06",
   "metadata": {},
   "source": [
    "### From https://stackoverflow.com/questions/67968913/derivative-of-batchnorm2d-in-pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a66eca",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network_1st(nn.Module):\n",
    "    def __init__(self, channel_in, channel_out, conv_kernel_size = 1, pooling_kernel_size = 1):\n",
    "        super(network_1st, self).__init__()\n",
    "               \n",
    "        self.conv2d = nn.Conv2d(channel_in, channel_out, kernel_size=conv_kernel_size)\n",
    "        self.batchnorm2d = nn.BatchNorm2d(channel_out)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        mu = self.conv2d(x)\n",
    "        out = self.batchnorm2d(mu)\n",
    "        \n",
    "        return mu, out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5821b971",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = dataiter.next()\n",
    "#images = images.view(images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d294d571",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.rand(1, 1, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23e0fa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.rand(1, 1, 5, 5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9b0007",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network_1st(1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d7cce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_gradients = [Hook(model.batchnorm2d, backward = True) for model in [model]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5212b45",
   "metadata": {},
   "outputs": [],
   "source": [
    "mu, out = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2638fad9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#criterion = nn.MSELoss(reduction='mean')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a24956",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#loss = criterion(out, target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abc2b0a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = abs(target - out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5576522c",
   "metadata": {},
   "outputs": [],
   "source": [
    "out.backward(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b9e084",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_backward = hook_gradients[0].grad_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06c959b6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "970f227f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def backward_batchnorm2d(input, output, grad_output, layer):\n",
    "    gamma = layer.weight\n",
    "    gamma = gamma.view(1,-1,1,1) # edit\n",
    "    # beta = layer.bias\n",
    "    # avg = layer.running_mean\n",
    "    # var = layer.running_var\n",
    "    eps = layer.eps\n",
    "    B = input.shape[0] * input.shape[2] * input.shape[3] # edit\n",
    "\n",
    "    # add new\n",
    "    mean = input.mean(dim = (0,2,3), keepdim = True)\n",
    "    variance = input.var(dim = (0,2,3), unbiased=False, keepdim = True)\n",
    "    x_hat = (input - mean)/(torch.sqrt(variance + eps))\n",
    "    \n",
    "    dL_dxi_hat = grad_output * gamma\n",
    "    # dL_dvar = (-0.5 * dL_dxi_hat * (input - avg) / ((var + eps) ** 1.5)).sum((0, 2, 3), keepdim=True) \n",
    "    # dL_davg = (-1.0 / torch.sqrt(var + eps) * dL_dxi_hat).sum((0, 2, 3), keepdim=True) + dL_dvar * (-2.0 * (input - avg)).sum((0, 2, 3), keepdim=True) / B\n",
    "    dL_dvar = (-0.5 * dL_dxi_hat * (input - mean)).sum((0, 2, 3), keepdim=True)  * ((variance + eps) ** -1.5) # edit\n",
    "    dL_davg = (-1.0 / torch.sqrt(variance + eps) * dL_dxi_hat).sum((0, 2, 3), keepdim=True) + (dL_dvar * (-2.0 * (input - mean)).sum((0, 2, 3), keepdim=True) / B) #edit\n",
    "    \n",
    "    dL_dxi = (dL_dxi_hat / torch.sqrt(variance + eps)) + (2.0 * dL_dvar * (input - mean) / B) + (dL_davg / B) # dL_dxi_hat / sqrt()\n",
    "    # dL_dgamma = (grad_output * output).sum((0, 2, 3), keepdim=True) \n",
    "    dL_dgamma = (grad_output * x_hat).sum((0, 2, 3), keepdim=True) # edit\n",
    "    dL_dbeta = (grad_output).sum((0, 2, 3), keepdim=True)\n",
    "    return dL_dxi, dL_dgamma, dL_dbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e494d3f9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dL_dxi, dL_dgamma, dL_dbeta = backward_batchnorm2d(images, out, loss, model.batchnorm2d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52d10cae",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfd29999",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dxi"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c3f8487",
   "metadata": {},
   "source": [
    "### 1D Batch Norm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277477e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network_1d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(network_1d, self).__init__()\n",
    "               \n",
    "        self.batchnorm1d = nn.BatchNorm1d(output_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.batchnorm1d(x)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4cb3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images, labels = dataiter.next()\n",
    "#images = images.view(images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09992c1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images = torch.rand(2, 1, 3, 3, requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2df46f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#images = images.view(images.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37a4b26a",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.tensor([[0.7, 0.1, -1.3, 1.1, 0.5, 0.3, .6, -0.6, 0.2],\n",
    "        [0.7, 0.3, 0.1, 0.6, 0.8, 0.9, 0.5, 2., 0.0]], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea343c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "target = torch.tensor([[0.9, 0.2, -1.2, 1.0, 0.4, 0.8, 0.4, -0.1, 0.9],\n",
    "        [0.4, 0.2, 0.3, 0.6, 0.5, 0.6, 0.1, 2.4, 0.1]], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63bc2b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5692f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network_1d(9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cebf11",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = torch.tensor([0.9, 1., 0.89, 0.92, 1., 1., 0.96, 1., 0.94], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a45f1795",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.batchnorm1d.weight = torch.nn.Parameter(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3f9e897",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.tensor([0.0, 0.1, 0.0, 0.0, 0.05, 0.06, 0.0, 0.03, 0.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d842246b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.batchnorm1d.bias = torch.nn.Parameter(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d40fee",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_gradients = [Hook(model.batchnorm1d, backward = True) for model in [model]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3955bd91",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2608b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf7105c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177b2b8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a57e38",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_y_pred = 2*(y_pred - target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc4c4624",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47432451",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = (y_pred - target).pow(2).sum()\n",
    "loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ab200a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3351df6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_backward = hook_gradients[0].grad_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbdeed60",
   "metadata": {},
   "outputs": [],
   "source": [
    "grad_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f1a7248",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(images.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79e486b2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model.batchnorm1d.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69d9b610",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tensor_status(**kwargs):\n",
    "    print(\"\\n\")\n",
    "    for arg_name in kwargs:\n",
    "        t= kwargs[arg_name]\n",
    "        t_name=arg_name\n",
    "    print(\"Status of tensor \"+t_name+\":\\n\")\n",
    "    print(\"==============\")\n",
    "    print(\"Data: \"+str(t.data))\n",
    "    print(\"grad: \"+str(t.grad) if t.is_leaf else str(None))\n",
    "    print(\"grad_fn: \"+str(t.grad_fn))\n",
    "    print(\"is_leaf: \"+str(t.is_leaf))\n",
    "    print(\"requires_grad:\"+str(t.requires_grad))\n",
    "    print(\"==============\\n\")\n",
    "    return \"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938c51d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor_status(y_pred = y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df19cb6b",
   "metadata": {},
   "source": [
    "#### Comp Graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eb854e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_fn = y_pred.grad_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17ff78b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "back_fn.next_functions[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26537dcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_graph(g, level=0):\n",
    "    if g == None: return\n",
    "    print('*'*level*4, g)\n",
    "    for subg in g.next_functions:\n",
    "        print_graph(subg[0], level+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46b9e311",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print_graph(y_pred.grad_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f579078",
   "metadata": {},
   "source": [
    "### Manual Batchnorm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4614750",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm_forward(x, gamma, beta, eps):\n",
    "\n",
    "    N, D = x.shape\n",
    "\n",
    "    #step1: calculate mean\n",
    "    mu = 1./N * torch.sum(x, dim = 0)\n",
    "\n",
    "    #step2: subtract mean vector of every trainings example\n",
    "    xmu = x - mu\n",
    "\n",
    "    #step3: following the lower branch - calculation denominator\n",
    "    sq = xmu ** 2\n",
    "\n",
    "    #step4: calculate variance\n",
    "    var = 1./N * torch.sum(sq, dim = 0)\n",
    "\n",
    "    #step5: add eps for numerical stability, then sqrt\n",
    "    sqrtvar = torch.sqrt(var + eps)\n",
    "\n",
    "    #step6: invert sqrtwar\n",
    "    ivar = 1./sqrtvar\n",
    "\n",
    "    #step7: execute normalization\n",
    "    xhat = xmu * ivar\n",
    "\n",
    "    #step8: Nor the two transformation steps\n",
    "    gammax = gamma * xhat\n",
    "\n",
    "    #step9\n",
    "    out = gammax + beta\n",
    "\n",
    "    #store intermediate\n",
    "    cache = (xhat,gamma,xmu,ivar,sqrtvar,var,eps)\n",
    "\n",
    "    return out, cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb7acd78",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.tensor([[0.7, 0.1, -1.3, 1.1, 0.5, 0.3, .6, -0.6, 0.2],\n",
    "        [0.7, 0.3, 0.1, 0.6, 0.8, 0.9, 0.5, 2., 0.0]], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f04e5216",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = torch.tensor([0.9, 1., 0.89, 0.92, 1., 1., 0.96, 1., 0.94], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dca1d253",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.tensor([0.0, 0.1, 0.0, 0.0, 0.05, 0.06, 0.0, 0.03, 0.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3b89340",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8fd48e",
   "metadata": {},
   "outputs": [],
   "source": [
    "man_out, cache = batchnorm_forward(images, gamma, beta, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "823d6b8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45af248",
   "metadata": {},
   "outputs": [],
   "source": [
    "print_graph(man_out.grad_fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd04ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "man_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5e77629",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5916fb5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batchnorm_backward(dout, cache):\n",
    "\n",
    "    #unfold the variables stored in cache\n",
    "    xhat,gamma,xmu,ivar,sqrtvar,var,eps = cache\n",
    "\n",
    "    #get the dimensions of the input/output\n",
    "    N,D = dout.shape\n",
    "\n",
    "    #step9\n",
    "    dbeta = torch.sum(dout, dim=0)\n",
    "    dgammax = dout #not necessary, but more understandable\n",
    "\n",
    "    #step8\n",
    "    dgamma = torch.sum(dgammax*xhat, dim=0)\n",
    "    dxhat = dgammax * gamma\n",
    "\n",
    "    #step7\n",
    "    divar = torch.sum(dxhat*xmu, dim=0)\n",
    "    dxmu1 = dxhat * ivar\n",
    "\n",
    "    #step6\n",
    "    dsqrtvar = -1. /(sqrtvar**2) * divar\n",
    "\n",
    "    #step5\n",
    "    dvar = 0.5 * 1. /torch.sqrt(var+eps) * dsqrtvar\n",
    "\n",
    "    #step4\n",
    "    dsq = 1. /N * torch.ones((N,D)) * dvar\n",
    "\n",
    "    #step3\n",
    "    dxmu2 = 2 * xmu * dsq\n",
    "\n",
    "    #step2\n",
    "    dx1 = (dxmu1 + dxmu2)\n",
    "    dmu = -1 * torch.sum(dxmu1+dxmu2, dim=0)\n",
    "\n",
    "    #step1\n",
    "    dx2 = 1. /N * torch.ones((N,D)) * dmu\n",
    "\n",
    "    #step0\n",
    "    dx = dx1 + dx2\n",
    "\n",
    "    return dx, dgamma, dbeta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45f9333",
   "metadata": {},
   "outputs": [],
   "source": [
    "batchnorm_backward(grad_y_pred, cache)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6a8180",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "938eabd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.batchnorm1d.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9113a0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.batchnorm1d.bias.grad"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bd50cc9",
   "metadata": {},
   "source": [
    "### Manual Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cde6c4b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network_linear(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(network_linear, self).__init__()\n",
    "               \n",
    "        self.linear = nn.Linear(input_dim, output_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.linear(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "387b4bf1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dout, cache):\n",
    "    x, weight = cache\n",
    "    \n",
    "    dw = torch.matmul(dout.T, x)\n",
    "    db = dout.sum(dim = 0)\n",
    "    dx = torch.matmul(dout, weight)\n",
    "    return dx, dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43bd3eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network_linear(9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23d9ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20802e1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d81e7d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44dc7f3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_gradients_linear = [Hook(model.linear, backward = True) for model in [model]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "295baa2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_linear_pred = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02a7307b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_linear_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1d6a40c",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_linear = (y_linear_pred - target).pow(2).sum(); loss_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24f66594",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_linear.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a35b5acf",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_grad_backward = hook_gradients_linear[0].grad_output[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "214820bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_grad_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8c86760",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.linear.weight.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c61e91e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.linear.bias.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6dc23160",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dout_linear = 2*(y_linear_pred - target); dL_dout_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d125dabf",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_db = dL_dout_linear.sum(dim = 0); dL_db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a57bf25a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dL_dw_linear = torch.matmul(dL_dout_linear.T, images); dL_dw_linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0977d061",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd765753",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dL_dx = torch.matmul(dL_dout_linear, model.linear.weight); dL_dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cec634b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# by function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0977208",
   "metadata": {},
   "outputs": [],
   "source": [
    "cache = images, model.linear.weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "221e35ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_backward(dL_dout_linear, cache)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33fdbae3",
   "metadata": {},
   "source": [
    "### Manual ReLu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af1f65b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network_relu(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(network_relu, self).__init__()\n",
    "               \n",
    "        self.relu = nn.ReLU()\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.relu(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bfab7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def relu_backward(dout, x):\n",
    "    x = x.clone()\n",
    "    x[x > 0.0] = 1.0\n",
    "    x[x <= 0.0] = 0.0\n",
    "    dx = torch.mul(dout, x)\n",
    "    return dx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91933fb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network_relu(9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2973c990",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6aeab6",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7f003d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_gradients_relu = [Hook(model.relu, backward = True) for model in [model]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbaee8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_relu_pred = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57d20404",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_relu_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48bd0461",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_relu = (y_relu_pred - target).pow(2).sum(); loss_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2f7d9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_relu.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67738465",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_grad_backward = hook_gradients_relu[0].grad_output[0]; relu_grad_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48a898b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dL_dout_relu = 2*(y_relu_pred - target); dL_dout_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc7cd33",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c44e8e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.grad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9ff5386",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_backward(dL_dout_relu, images)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0d6a86e",
   "metadata": {},
   "source": [
    "### Manual Conv2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2031f03c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network_conv2d(nn.Module):\n",
    "    def __init__(self, channel_in, channel_out, kernel_size, padding):\n",
    "        super(network_conv2d, self).__init__()\n",
    "               \n",
    "        self.conv2d = nn.Conv2d(channel_in, channel_out, kernel_size=kernel_size, padding = padding)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.conv2d(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "880edd95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv2d_backward(dout, cache):\n",
    "\n",
    "    return dx, dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a4c6970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def linear_backward(dout, cache):\n",
    "    x, weight = cache\n",
    "    \n",
    "    dw = torch.matmul(dout.T, x)\n",
    "    db = dout.sum(dim = 0)\n",
    "    dx = torch.matmul(dout, weight)\n",
    "    return dx, dw, db"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8f1d966",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f8c3e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network_conv2d(9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b8c5988",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccdab229",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2b55db1",
   "metadata": {},
   "outputs": [],
   "source": [
    "hook_gradients_relu = [Hook(model.relu, backward = True) for model in [model]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420cbb80",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_relu_pred = model(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "660c9c93",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_relu_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79c58208",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_relu = (y_relu_pred - target).pow(2).sum(); loss_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e384f7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_relu.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aab286e",
   "metadata": {},
   "outputs": [],
   "source": [
    "relu_grad_backward = hook_gradients_relu[0].grad_output[0]; relu_grad_backward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d52b4fe8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "dL_dout_relu = 2*(y_relu_pred - target); dL_dout_relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5cc65be",
   "metadata": {},
   "outputs": [],
   "source": [
    "images2d = torch.tensor([[[[0.7, 0.1, -1.3, 1.1, 0.5],\n",
    "                        [0.1, 1.6, -0.6, 0.2, 0.0],\n",
    "                        [0.4, 3.6, -0.9, -0.2, 0.0],\n",
    "                        [0.3, .6, -0.6, 5.2, 0.3],\n",
    "                        [0.6, -1.6, -0.7, 2.2, 0.4]],\n",
    "                        [[0.7, 0.3, 0.1, 0.6, 0.8],\n",
    "                        [1.9, 1.5, 2.1, 0.3, 1.1],\n",
    "                        [0.4, 0.2, 1., 2.0, 1.1],\n",
    "                        [0.1, 3.5, 2.1, 0.3, 0.4],\n",
    "                        [0.7, 0.2, 1., 0.6, 0.4]]]], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88d1241d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target2d = torch.tensor([[[[0.8, 0.2, -1.1, 1.0, 0.4],\n",
    "                        [0.5, 1.6, -0.8, 0.1, 0.1],\n",
    "                        [0.3, 3.0, -0.9, -0.0, 0.6],\n",
    "                        [0.5, .2, -0.4, 5.0, 0.4],\n",
    "                        [0.9, -1.6, -0.5, 2.3, 0.8]],\n",
    "                        [[0.7, 0.9, 0.1, 0.0, 0.0],\n",
    "                        [1.8, 1.4, 2.8, 0.5, 1.8],\n",
    "                        [0.7, 0.5, 1.3, 2.5, 1.4],\n",
    "                        [0.7, 3.5, 2.4, 0.4, 0.5],\n",
    "                        [0.2, 0.6, 1.7, 0.0, 0.9]]]], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f40feb2",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "images2d.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05a11c4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.grad.zero_()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8c09c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = network_conv2d(9, 9)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef796159",
   "metadata": {},
   "source": [
    "## gp.ai MNIST test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60bfe6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pytorch equivalent model\n",
    "class network(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(network, self).__init__()\n",
    "        \n",
    "        self.linear1 = nn.Linear(784, 256)\n",
    "        self.batchnorm1d_1 = nn.BatchNorm1d(256)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        \n",
    "        self.linear2 = nn.Linear(256, 256)\n",
    "        self.batchnorm1d_2 = nn.BatchNorm1d(256)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        \n",
    "        self.linear2 = nn.Linear(256, 10)\n",
    "        self.batchnorm1d_2 = nn.BatchNorm1d(10)\n",
    "        self.relu2 = nn.ReLU()        \n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        \n",
    "        lin1_out = self.linear1(x)\n",
    "        bn1_out =  self.batchnorm1d_1(lin1_out)\n",
    "        relu1_out = self.relu1(bn1_out)\n",
    "        \n",
    "        lin2_out = self.linear2(relu1_out)\n",
    "        bn2_out =  self.batchnorm1d_2(lin2_out)\n",
    "        relu2_out = self.relu1(bn2_out)\n",
    "        \n",
    "        lin2_out = self.linear2(relu2_out)\n",
    "        bn2_out =  self.batchnorm1d_2(lin2_out)\n",
    "        out = self.relu1(bn2_out)\n",
    "        \n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cc3902b",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_input = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57aa630b",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(\"../FC_MNIST_V_gpai/logs/model_FC_MNIST_V_gpai.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0b0e46",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2759feb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict['batchnorm1d_1.running_var'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe010a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt = [1e-5] + [0 for _ in range(32 * 32 - 1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56541b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tt)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "257feff5",
   "metadata": {},
   "source": [
    "# Batch Norm from https://d2l.ai/chapter_convolutional-modern/batch-norm.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83f4a698",
   "metadata": {},
   "outputs": [],
   "source": [
    "class network_1d(nn.Module):\n",
    "    def __init__(self, input_dim, output_dim):\n",
    "        super(network_1d, self).__init__()\n",
    "               \n",
    "        self.batchnorm1d = nn.BatchNorm1d(output_dim)\n",
    "\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.batchnorm1d(x)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e67a5032",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_torch = network_1d(9, 9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d260fb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b50fa6db",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_torch_out = bn_torch(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ac4aa64",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_torch.batchnorm1d.running_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "323f87ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_torch.batchnorm1d.bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288c4b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_torch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08859ca7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73a7c745",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.set_grad_enabled(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33cb9a51",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.is_grad_enabled()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742769d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tt_batch_norm(X, gamma_tt, beta_tt, moving_mean, moving_var, eps_tt, momentum):\n",
    "        mean = X.mean(dim=0)\n",
    "        var = ((X - mean) ** 2).mean(dim=0)\n",
    "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "        # Update the mean and variance using moving average\n",
    "        moving_mean = (1.0 - momentum) * moving_mean + momentum * mean\n",
    "        moving_var = (1.0 - momentum) * moving_var + momentum * var\n",
    "        Y = gamma * X_hat + beta  # Scale and shift\n",
    "        print(X_hat, gamma, beta, Y)\n",
    "        return Y, moving_mean.data, moving_var.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec849a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    def __init__(self, num_features, num_dims):\n",
    "        super().__init__()\n",
    "        self.gamma = nn.Parameter(torch.ones(shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(shape))\n",
    "        self.moving_mean = torch.zeros(shape)\n",
    "        self.moving_var = torch.ones(shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # If X is not on the main memory, copy moving_mean and moving_var to\n",
    "        # the device where X is located\n",
    "        if self.moving_mean.device != X.device:\n",
    "            self.moving_mean = self.moving_mean.to(X.device)\n",
    "            self.moving_var = self.moving_var.to(X.device)\n",
    "        # Save the updated moving_mean and moving_var\n",
    "        Y, self.moving_mean, self.moving_var = batch_norm(X, self.gamma, self.beta, self.moving_mean, self.moving_var, eps=1e-5, momentum=0.1)\n",
    "        print('Y:', Y,'moving_mean:', self.moving_mean, 'moving_var:', self.moving_var, '\\n')\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05f915d5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1d499f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdc1a7e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92dba405",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
    "    # Use is_grad_enabled to determine whether we are in training mode\n",
    "    if not torch.is_grad_enabled():\n",
    "        # In prediction mode, use mean and variance obtained by moving average\n",
    "        print('pred mode') \n",
    "        print(moving_mean, moving_var, '\\n')\n",
    "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
    "    else:\n",
    "        print('train mode')\n",
    "        assert len(X.shape) in (2, 4)\n",
    "        if len(X.shape) == 2:\n",
    "            # When using a fully connected layer, calculate the mean and\n",
    "            # variance on the feature dimension\n",
    "            mean = X.mean(dim=0)\n",
    "            var = ((X - mean) ** 2).mean(dim=0)\n",
    "        else:\n",
    "            # When using a two-dimensional convolutional layer, calculate the\n",
    "            # mean and variance on the channel dimension (axis=1). Here we\n",
    "            # need to maintain the shape of X, so that the broadcasting\n",
    "            # operation can be carried out later\n",
    "            mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
    "            var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
    "        # In training mode, the current mean and variance are used\n",
    "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "        # Update the mean and variance using moving average\n",
    "        moving_mean = (1.0 - momentum) * moving_mean + momentum * mean\n",
    "        moving_var = (1.0 - momentum) * moving_var + momentum * var\n",
    "    Y = gamma * X_hat + beta  # Scale and shift\n",
    "    print(X_hat, gamma, beta, Y)\n",
    "    return Y, moving_mean.data, moving_var.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0e456ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    # num_features: the number of outputs for a fully connected layer or the\n",
    "    # number of output channels for a convolutional layer. num_dims: 2 for a\n",
    "    # fully connected layer and 4 for a convolutional layer\n",
    "    def __init__(self, num_features, num_dims):\n",
    "        super().__init__()\n",
    "        if num_dims == 2:\n",
    "            shape = (1, num_features)\n",
    "        else:\n",
    "            shape = (1, num_features, 1, 1)\n",
    "        # The scale parameter and the shift parameter (model parameters) are\n",
    "        # initialized to 1 and 0, respectively\n",
    "        self.gamma = nn.Parameter(torch.ones(shape))\n",
    "        self.beta = nn.Parameter(torch.zeros(shape))\n",
    "        # The variables that are not model parameters are initialized to 0 and\n",
    "        # 1\n",
    "        self.moving_mean = torch.zeros(shape)\n",
    "        self.moving_var = torch.ones(shape)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # If X is not on the main memory, copy moving_mean and moving_var to\n",
    "        # the device where X is located\n",
    "        if self.moving_mean.device != X.device:\n",
    "            self.moving_mean = self.moving_mean.to(X.device)\n",
    "            self.moving_var = self.moving_var.to(X.device)\n",
    "        # Save the updated moving_mean and moving_var\n",
    "        Y, self.moving_mean, self.moving_var = batch_norm(\n",
    "            X, self.gamma, self.beta, self.moving_mean,\n",
    "            self.moving_var, eps=1e-5, momentum=0.1)\n",
    "        print('Y:', Y,'moving_mean:', self.moving_mean, 'moving_var:', self.moving_var, '\\n')\n",
    "        return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6543b6d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.tensor([[0.7, 0.1, -1.3, 1.1, 0.5, 0.3, .6, -0.6, 0.2],\n",
    "        [0.7, 0.3, 0.1, 0.6, 0.8, 0.9, 0.5, 2., 0.0]], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1d1e629",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = torch.tensor([0.9, 1., 0.89, 0.92, 1., 1., 0.96, 1., 0.94], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944c920b",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.tensor([0.0, 0.1, 0.0, 0.0, 0.05, 0.06, 0.0, 0.03, 0.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b17dcbe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dce492bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8e36e4ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = BatchNorm(9, num_dims=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "150d8d7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_out = bn(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ccdd734",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31814cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_torch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6abb9579",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn.moving_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2ea4bc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytorchMnistModel(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, state_dict):\n",
    "        super(PytorchMnistModel, self).__init__()\n",
    "\n",
    "        self.linear1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.batchnorm1d_1 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.relu1 = nn.ReLU()\n",
    "\n",
    "        self.linear2 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.batchnorm1d_2 = nn.BatchNorm1d(hidden_dim)\n",
    "        self.relu2 = nn.ReLU()\n",
    "\n",
    "        self.linear3 = nn.Linear(hidden_dim, output_dim)\n",
    "        self.batchnorm1d_3 = nn.BatchNorm1d(output_dim)\n",
    "        self.relu3 = nn.ReLU()\n",
    "\n",
    "        self.load_state_dict(state_dict)\n",
    "\n",
    "    def forward(self, X):\n",
    "        x, labels = X\n",
    "        x = x.view(x.shape[0], -1)\n",
    "\n",
    "        lin1_out = self.linear1(x)\n",
    "        bn1_out =  self.batchnorm1d_1(lin1_out)\n",
    "        relu1_out = self.relu1(bn1_out)\n",
    "\n",
    "        lin2_out = self.linear2(relu1_out)\n",
    "        bn2_out =  self.batchnorm1d_2(lin2_out)\n",
    "        relu2_out = self.relu1(bn2_out)\n",
    "\n",
    "        lin3_out = self.linear3(relu2_out)\n",
    "        bn3_out =  self.batchnorm1d_3(lin3_out)\n",
    "        relu3_out = self.relu3(bn3_out)\n",
    "\n",
    "        out = nn.functional.softmax(relu3_out)\n",
    "\n",
    "        return out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6be9cebd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69631f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataloader = DataLoader(testset, batch_size=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7310c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_mnist_model = PytorchMnistModel(784, 256, 10, state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4853143c",
   "metadata": {},
   "outputs": [],
   "source": [
    "first_input = next(iter(dataloader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28803994",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_out = pytorch_mnist_model(first_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6b7f3f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f99f454e",
   "metadata": {},
   "outputs": [],
   "source": [
    "x, label = first_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9551e547",
   "metadata": {},
   "outputs": [],
   "source": [
    "x.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97bc8c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = x.view(x.shape[0], -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed9deca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_mnist_model(first_input)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6cd0207",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytorchBatchNorm1D(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(PytorchBatchNorm1D, self).__init__()\n",
    "\n",
    "        self.batchnorm1d_1 = nn.BatchNorm1d(input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "       # x, labels = X\n",
    "       # x = x.view(x.shape[0], -1)\n",
    "\n",
    "        bn1_out =  self.batchnorm1d_1(x)\n",
    "\n",
    "        return bn1_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36abb2c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.tensor([[0.54, 0.1, -1.3, 1.1, 0.5, 0.3, .6, -0.6, 0.2],\n",
    "        [0.7, 0.3, 0.1, 0.6, 0.8, 0.9, 0.5, 2., 0.0]], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ff88b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "images[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0d37bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = torch.tensor([0.9, 1., 0.89, 0.92, 1., 1., 0.96, 1., 0.94], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44004eb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.tensor([0.0, 0.1, 0.0, 0.0, 0.05, 0.06, 0.0, 0.03, 0.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65ffe7ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean = torch.tensor([0.1, 0.07, 0.09, 0.11, 0.12, 0.086, 0.06, 0.2, 0.21], requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be2daaef",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_var =   torch.tensor([0.44, 0.87, 0.96, 0.92, 1.2, 0.12, 0.43, 0.76, 0.91], requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85f5b13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6760323",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d = PytorchBatchNorm1D(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d19812c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b11d08",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = torch.nn.Parameter(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b98fcf15",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.nn.Parameter(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60650ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.batchnorm1d_1.weight = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc8517",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.batchnorm1d_1.bias = beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18ab142",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.batchnorm1d_1.running_mean = running_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88bbcc64",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.batchnorm1d_1.running_var = running_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6da3ffb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.batchnorm1d_1.eps = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03167e24",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_out = pytorch_bn1d(images); torch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ad8152",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(pytorch_bn1d.state_dict(), 'bn1d.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85a5c145",
   "metadata": {},
   "source": [
    "### Manual for TT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "477910a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_plus_eps = running_var + eps; var_plus_eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61563904",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_var = torch.sqrt(var_plus_eps); sqrt_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b120079",
   "metadata": {},
   "outputs": [],
   "source": [
    "sqrt_inv = torch.reciprocal(sqrt_var); sqrt_inv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b8e637",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_minus_mean = images - running_mean; x_minus_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cd7e657",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_div_sqrt = x_minus_mean * sqrt_inv; x_div_sqrt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050390ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_gamma = x_div_sqrt * gamma; x_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7475a44",
   "metadata": {},
   "outputs": [],
   "source": [
    "y = x_gamma + beta; y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d36fc47f",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(f\"bn1d.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d259ce51",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4de5331",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt32 = torch.randn(1, 1, 32, 32, requires_grad = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3e89619",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d989230",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt32.reshape(1, 1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a96f4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_32 = {'batchnorm1d_1.weight': torch.randn(32, requires_grad = False), 'batchnorm1d_1.bias': torch.randn(32, requires_grad = False),\n",
    "                'batchnorm1d_1.running_mean': torch.randn(32, requires_grad = False), 'batchnorm1d_1.running_var': torch.randn(32, requires_grad = False)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f1b8200",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict_32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04a33319",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(state_dict_32, 'bn1d_32.pt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8f4182f",
   "metadata": {},
   "source": [
    "# ttmetal Codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7181c71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd /home/farbabi/git/tt-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f9429e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math, os\n",
    "from pathlib import Path\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d39d24f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%env TT_METAL_ENV=dev\n",
    "%env TT_METAL_HOME=/home/farbabi/git/tt-metal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dffac55",
   "metadata": {},
   "outputs": [],
   "source": [
    "f = f\"{Path}(__file__).parent\"\n",
    "sys.path.append(f\"{f}/..\")\n",
    "sys.path.append(f\"{f}/../..\")\n",
    "sys.path.append('/home/farbabi/git/tt-metal/python_api_testing/models')\n",
    "sys.path.append('/home/farbabi/git/tt-metal/python_api_testing/sweep_tests')\n",
    "sys.path.append('/home/farbabi/git/tt-metal/python_api_testing/models/synthetic_gradients')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761043d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9b3aa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "from libs import tt_lib as ttl\n",
    "from models.utility_functions import tilize_to_list, untilize, comp_allclose_and_pcc, tt2torch, torch2tt_tensor\n",
    "from libs.tt_lib.utils import pad_activation, pad_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d5a64e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_dim = 32\n",
    "batch_size = 1\n",
    "eps = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7f27874",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = ttl.device.CreateDevice(ttl.device.Arch.GRAYSKULL, 0)\n",
    "ttl.device.InitializeDevice(device)\n",
    "host = ttl.device.GetHost()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d755462",
   "metadata": {},
   "outputs": [],
   "source": [
    "state_dict = torch.load(f\"tests/python_api_testing/models/synthetic_gradients/lfs/synthetic_grads/sg_mnist_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5212abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1 = state_dict[\"fc1.weight\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a07ce862",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3a9485",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1 = torch.randn(1, 1, 256, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e504435",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e7065a",
   "metadata": {},
   "outputs": [],
   "source": [
    "tilized_gamma = tilize_to_list(gamma1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be066db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1.shape[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1318b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_tt = ttm.tensor.Tensor(tilized_gamma, *gamma1.shape[-2:], ttm.tensor.DataType.BFLOAT16, ttm.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5417fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1 = torch.randn(1, 1, 1, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7abff11a",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1_targ = torch.zeros(1, 1, 32, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2509eca7",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1_targ[:, :, :1, :] = beta1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e31a74f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tilized_beta = tilize_to_list(beta1_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9283058",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_tt = ttm.tensor.Tensor(tilized_beta, beta1_targ.shape[-], ttm.tensor.DataType.BFLOAT16, ttm.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9023df5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = torch.randn(1, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c5b0999",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_reshape = inputs.reshape(1, 1, 1, -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033fd5e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_reshape.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f9d48bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_targ = torch.zeros(1, 1, 32, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc3c76b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_targ[:, :, :1, :] = inputs_reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d039b74e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0ca049f",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_targ.reshape(32, 1024)[0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf310389",
   "metadata": {},
   "outputs": [],
   "source": [
    "tilized_inputs = tilize_to_list(inputs_targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aca54f37",
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs_tt = ttm.tensor.Tensor(tilized_inputs, inputs_targ.shape, ttm.tensor.DataType.BFLOAT16, ttm.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4b7f6a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_T = ttm.tensor.transpose(gamma_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82691827",
   "metadata": {},
   "outputs": [],
   "source": [
    "weight_T.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e053e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = ttm.tensor.matmul(inputs_tt, gamma1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b2a6b88",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_plus_bias = ttm.tensor.bcast(output, beta_tt, ttm.tensor.BcastOpMath.ADD, ttm.tensor.BcastOpDim.H)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cacd9f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_plus_bias.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af8f98cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_torch = torch.nn.Linear(1024, 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7f818d",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1_torch = gamma1.view(256, 1024)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f81e2859",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809286b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_torch.weight = nn.Parameter(gamma1_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14fbc0ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta1_torch = beta1.view(256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74f693d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_torch.bias = nn.Parameter(beta1_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "231dad59",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_out = linear_torch(inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d2047b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_out.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed0ac63d",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_plus_bias.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6c55cf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_out_cpu = output_plus_bias.to(host)\n",
    "tt_out_cpu_pytorch = torch.Tensor(tt_out_cpu.data()).reshape(tt_out_cpu.shape())[:, 0, 0, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2d2d7c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_out_cpu_pytorch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1092654d",
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_pcc(torch_out, tt_out_cpu_pytorch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed96b9e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch_out[0][0:20]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1face8a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "tt_out_cpu_pytorch[0][0:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09892b95",
   "metadata": {},
   "source": [
    "## tt Batch Norm Forward"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7aba0b8",
   "metadata": {},
   "source": [
    "pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "d546d9ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "images = torch.tensor([[0.7, 0.1, -1.3, 1.1, 0.5, 0.3, .6, -0.6, 0.2],\n",
    "        [0.7, 0.3, 0.1, 0.6, 0.8, 0.9, 0.5, 2., 0.0]], requires_grad = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "f1ea2e69",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = torch.tensor([0.9, 1., 0.89, 0.92, 1., 1., 0.96, 1., 0.94], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "2323f873",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.tensor([0.0, 0.1, 0.0, 0.0, 0.05, 0.06, 0.0, 0.03, 0.0], requires_grad=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "f5ec485f",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "98591041",
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "484993f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean = torch.tensor([0.1, 0.07, 0.09, 0.11, 0.12, 0.086, 0.06, 0.2, 0.21], requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "88947dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_var =   torch.tensor([0.44, 0.87, 0.96, 0.92, 1.2, 0.12, 0.43, 0.76, 0.91], requires_grad=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "fdebc82f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PytorchBatchNorm1D(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(PytorchBatchNorm1D, self).__init__()\n",
    "\n",
    "        self.batchnorm1d_1 = nn.BatchNorm1d(input_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "       # x, labels = X\n",
    "       # x = x.view(x.shape[0], -1)\n",
    "\n",
    "        bn1_out =  self.batchnorm1d_1(x)\n",
    "\n",
    "        return bn1_out\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "78946294",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d = PytorchBatchNorm1D(9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "82d14c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma = torch.nn.Parameter(gamma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "b4e4e8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = torch.nn.Parameter(beta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "9fc954a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.batchnorm1d_1.weight = gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "11a30a74",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.batchnorm1d_1.bias = beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "59056b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.batchnorm1d_1.running_mean = running_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "d7e509ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.batchnorm1d_1.running_var = running_var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "8a0ca445",
   "metadata": {},
   "outputs": [],
   "source": [
    "pytorch_bn1d.batchnorm1d_1.eps = eps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "e56e2bbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.3001e-07, -8.5346e-01, -8.8909e-01,  9.1273e-01, -9.2849e-01,\n",
       "         -9.3449e-01,  8.1135e-01, -9.6970e-01,  8.9625e-01],\n",
       "        [-5.3001e-07,  1.0535e+00,  8.8909e-01, -9.1273e-01,  1.0285e+00,\n",
       "          1.0545e+00, -8.1135e-01,  1.0297e+00, -8.9625e-01]],\n",
       "       grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out = pytorch_bn1d(images); torch_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "181ba446",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_norm(X, gamma, beta, moving_mean, moving_var, eps, momentum):\n",
    "    # Use is_grad_enabled to determine whether we are in training mode\n",
    "    if not torch.is_grad_enabled():\n",
    "        # In prediction mode, use mean and variance obtained by moving average\n",
    "        print('pred mode') \n",
    "        print(moving_mean, moving_var, '\\n')\n",
    "        X_hat = (X - moving_mean) / torch.sqrt(moving_var + eps)\n",
    "    else:\n",
    "        print('train mode')\n",
    "        assert len(X.shape) in (2, 4)\n",
    "        if len(X.shape) == 2:\n",
    "            # When using a fully connected layer, calculate the mean and\n",
    "            # variance on the feature dimension\n",
    "            mean = X.mean(dim=0)\n",
    "            print('mean:', mean)\n",
    "            var = ((X - mean) ** 2).mean(dim=0)\n",
    "            print('var:', var)\n",
    "        else:\n",
    "            # When using a two-dimensional convolutional layer, calculate the\n",
    "            # mean and variance on the channel dimension (axis=1). Here we\n",
    "            # need to maintain the shape of X, so that the broadcasting\n",
    "            # operation can be carried out later\n",
    "            mean = X.mean(dim=(0, 2, 3), keepdim=True)\n",
    "            var = ((X - mean) ** 2).mean(dim=(0, 2, 3), keepdim=True)\n",
    "        # In training mode, the current mean and variance are used\n",
    "        X_hat = (X - mean) / torch.sqrt(var + eps)\n",
    "        # Update the mean and variance using moving average\n",
    "        moving_mean = (1.0 - momentum) * moving_mean + momentum * mean\n",
    "        moving_var = (1.0 - momentum) * moving_var + momentum * var\n",
    "    Y = gamma * X_hat + beta  # Scale and shift\n",
    "    print('X_hat:', X_hat,'\\n','gamma:', gamma,'\\n','beta:', beta,'\\n', 'Y:', Y)\n",
    "    return Y, moving_mean.data, moving_var.data, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 253,
   "id": "aec510b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BatchNorm(nn.Module):\n",
    "    # num_features: the number of outputs for a fully connected layer or the\n",
    "    # number of output channels for a convolutional layer. num_dims: 2 for a\n",
    "    # fully connected layer and 4 for a convolutional layer\n",
    "    def __init__(self, num_features, num_dims, gamma, beta, moving_mean, moving_var, epsilon):\n",
    "        super().__init__()\n",
    "        if num_dims == 2:\n",
    "            shape = (1, num_features)\n",
    "        else:\n",
    "            shape = (1, num_features, 1, 1)\n",
    "        # The scale parameter and the shift parameter (model parameters) are\n",
    "        # initialized to 1 and 0, respectively\n",
    "#         self.gamma = nn.Parameter(torch.ones(shape))\n",
    "#         self.beta = nn.Parameter(torch.zeros(shape))\n",
    "#         # The variables that are not model parameters are initialized to 0 and\n",
    "#         # 1\n",
    "#         self.moving_mean = torch.zeros(shape)\n",
    "#         self.moving_var = torch.ones(shape)\n",
    "        \n",
    "        self.gamma = nn.Parameter(gamma)\n",
    "        self.beta = nn.Parameter(beta)\n",
    "        # The variables that are not model parameters are initialized to 0 and\n",
    "        # 1\n",
    "        self.moving_mean = moving_mean\n",
    "        self.moving_var = moving_var\n",
    "        self.epsilon = epsilon\n",
    "\n",
    "    def forward(self, X):\n",
    "        # If X is not on the main memory, copy moving_mean and moving_var to\n",
    "        # the device where X is located\n",
    "        if self.moving_mean.device != X.device:\n",
    "            self.moving_mean = self.moving_mean.to(X.device)\n",
    "            self.moving_var = self.moving_var.to(X.device)\n",
    "        # Save the updated moving_mean and moving_var\n",
    "        Y, self.moving_mean, self.moving_var, mean = batch_norm(X, self.gamma, self.beta, self.moving_mean, self.moving_var, eps=self.epsilon, momentum=0.1)\n",
    "        print('Y:', Y,'\\nmoving_mean:', self.moving_mean, '\\nmoving_var:', self.moving_var, '\\n')\n",
    "        return Y, mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "dd3d05e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.autograd.grad_mode.set_grad_enabled at 0x7ff30fb96310>"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.set_grad_enabled(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "fa75e257",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn = BatchNorm(9, 2, gamma, beta, running_mean, running_var, eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "id": "a4e74859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BatchNorm()"
      ]
     },
     "execution_count": 256,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "537c7be8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train mode\n",
      "mean: tensor([ 0.7000,  0.2000, -0.6000,  0.8500,  0.6500,  0.6000,  0.5500,  0.7000,\n",
      "         0.1000], grad_fn=<MeanBackward1>)\n",
      "var: tensor([0.0000, 0.0100, 0.4900, 0.0625, 0.0225, 0.0900, 0.0025, 1.6900, 0.0100],\n",
      "       grad_fn=<MeanBackward1>)\n",
      "X_hat: tensor([[ 0.0000, -0.9535, -0.9990,  0.9921, -0.9785, -0.9945,  0.8452, -0.9997,\n",
      "          0.9535],\n",
      "        [ 0.0000,  0.9535,  0.9990, -0.9921,  0.9785,  0.9945, -0.8452,  0.9997,\n",
      "         -0.9535]], grad_fn=<DivBackward0>) \n",
      " gamma: Parameter containing:\n",
      "tensor([0.9000, 1.0000, 0.8900, 0.9200, 1.0000, 1.0000, 0.9600, 1.0000, 0.9400],\n",
      "       requires_grad=True) \n",
      " beta: Parameter containing:\n",
      "tensor([0.0000, 0.1000, 0.0000, 0.0000, 0.0500, 0.0600, 0.0000, 0.0300, 0.0000],\n",
      "       requires_grad=True) \n",
      " Y: tensor([[ 0.0000, -0.8535, -0.8891,  0.9127, -0.9285, -0.9345,  0.8113, -0.9697,\n",
      "          0.8963],\n",
      "        [ 0.0000,  1.0535,  0.8891, -0.9127,  1.0285,  1.0545, -0.8113,  1.0297,\n",
      "         -0.8963]], grad_fn=<AddBackward0>)\n",
      "Y: tensor([[ 0.0000, -0.8535, -0.8891,  0.9127, -0.9285, -0.9345,  0.8113, -0.9697,\n",
      "          0.8963],\n",
      "        [ 0.0000,  1.0535,  0.8891, -0.9127,  1.0285,  1.0545, -0.8113,  1.0297,\n",
      "         -0.8963]], grad_fn=<AddBackward0>) \n",
      "moving_mean: tensor([ 0.2140,  0.0947, -0.0411,  0.2506,  0.2207,  0.1837,  0.1531,  0.2950,\n",
      "         0.1891]) \n",
      "moving_var: tensor([0.3564, 0.7075, 0.9148, 0.7627, 0.9783, 0.1224, 0.3490, 1.0888, 0.7399]) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "bn_out, mean_torch = bn(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "e575a948",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.7000,  0.2000, -0.6000,  0.8500,  0.6500,  0.6000,  0.5500,  0.7000,\n",
       "         0.1000], grad_fn=<MeanBackward1>)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "ed2fec7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0000, -0.8535, -0.8891,  0.9127, -0.9285, -0.9345,  0.8113, -0.9697,\n",
       "          0.8963],\n",
       "        [ 0.0000,  1.0535,  0.8891, -0.9127,  1.0285,  1.0545, -0.8113,  1.0297,\n",
       "         -0.8963]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 259,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bn_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "d4d237fb",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-5.3001e-07, -8.5346e-01, -8.8909e-01,  9.1273e-01, -9.2849e-01,\n",
       "         -9.3449e-01,  8.1135e-01, -9.6970e-01,  8.9625e-01],\n",
       "        [-5.3001e-07,  1.0535e+00,  8.8909e-01, -9.1273e-01,  1.0285e+00,\n",
       "          1.0545e+00, -8.1135e-01,  1.0297e+00, -8.9625e-01]],\n",
       "       grad_fn=<NativeBatchNormBackward0>)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch_out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "31719823",
   "metadata": {},
   "outputs": [],
   "source": [
    "#tensor.DataType.BFLOAT16\n",
    "RSUM = ttl.tensor.ReduceOpMath.SUM\n",
    "RW = ttl.tensor.ReduceOpDim.W\n",
    "BCSUB = ttl.tensor.BcastOpMath.SUB\n",
    "BCW = ttl.tensor.BcastOpDim.W\n",
    "\n",
    "\n",
    "# RH = tensor.ReduceOpDim.H\n",
    "# BCH = tensor.BcastOpDim.H\n",
    "# BCHW = tensor.BcastOpDim.HW\n",
    "# BCMUL = tensor.BcastOpMath.MUL\n",
    "# BCADD = tensor.BcastOpMath.ADD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "bcf6ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "ec9b3788",
   "metadata": {},
   "outputs": [],
   "source": [
    "bn_size = images.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "6ed79de4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 9])"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "76d7bf71",
   "metadata": {},
   "outputs": [],
   "source": [
    "W = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "id": "80b1554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "H = 32"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "id": "a5b6d103",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_reshaped = images.view(images.shape[0], 1, 1, images.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "id": "ff50aecd",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_padded = pad_activation(images_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "id": "76680ade",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_tilized = tilize_to_list(images_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "id": "6b19ff16",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_tt = ttl.tensor.Tensor(images_tilized, [batch_size, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "id": "4b263e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_tt = gamma.view(1, 1, 1, gamma.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "id": "222d3429",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_tt = pad_weight(gamma_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "id": "bebfc302",
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma_tt = tilize_to_list(gamma_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "id": "75a29026",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_tt = beta.view(1, 1, 1, beta.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "id": "621ef2ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_tt = pad_weight(beta_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "id": "dfd4eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_tt = tilize_to_list(beta_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "id": "a0ee2edf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 32, 32]"
      ]
     },
     "execution_count": 277,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_tt.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "id": "7ac10fd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "images_tt_data = images_tt.to(host).data()\n",
    "images_tt_data = torch.Tensor(images_tt_data).reshape((batch_size,1,H,W))\n",
    "images_tt_data = untilize(images_tt_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "id": "88e9e5ef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 1, 32, 32])"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_tt_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "id": "4bc07970",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0.6992, 0.2988, 0.0996, 0.5977, 0.7969, 0.8984, 0.5000, 2.0000, 0.0000,\n",
       "        0.0000, 0.0000, 0.0000])"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_tt_data[1][0][0][0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "id": "528df491",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = images_tt_data.mean(dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "id": "1df5adad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32])"
      ]
     },
     "execution_count": 282,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "id": "21ff81bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "var = ((images_padded - mean) ** 2).mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "id": "5adfa2e3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32])"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "var.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "id": "bf675ad5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_reshaped = mean.view(1, 1, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "id": "3c984f16",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tilized = tilize_to_list(mean_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "5d5e1520",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_tt = ttl.tensor.Tensor(mean_tilized, [1, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "id": "6e0eee0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_reshaped = var.view(1, 1, 32, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "id": "c12ef778",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_tilized = tilize_to_list(var_reshaped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "id": "cf22e3f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_tt = ttl.tensor.Tensor(var_tilized, [1, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "id": "f5886bdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_torch = torch.tensor([[[W*[eps]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "f8fcb743",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_padded = pad_activation(epsilon_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "id": "cbee998e",
   "metadata": {},
   "outputs": [],
   "source": [
    "epsilon_tilized = tilize_to_list(epsilon_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "id": "d4239760",
   "metadata": {},
   "outputs": [],
   "source": [
    "eps_tt = ttl.tensor.Tensor(epsilon_tilized, [1, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "id": "07f95cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "var_plus_eps = ttl.tensor.add(eps_tt, var_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "id": "1635dd2f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=4\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=0\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Generating defines for TRISCs\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=1\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=2\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=3\n"
     ]
    }
   ],
   "source": [
    "sqrt_var = ttl.tensor.sqrt(var_plus_eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "51baab41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | \u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=4\n",
      "Generating defines for TRISCs\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=0\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=1\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=2\n",
      "\u001b[38;2;000;128;000m           BuildKernels\u001b[0m | \u001b[1m\u001b[38;2;100;149;237mINFO    \u001b[0m | Compiling RISCID=3\n"
     ]
    }
   ],
   "source": [
    "sqrt_inv = ttl.tensor.recip(sqrt_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "5e70a724",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean_padded = pad_activation(running_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "fe0500fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean_tilized = tilize_to_list(running_mean_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "id": "efa5ee27",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean_tt = ttl.tensor.Tensor(running_mean_tilized, [1, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "id": "2134592e",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_var_padded = pad_activation(running_var)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "c018d1f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_var_tilized = tilize_to_list(running_var_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "id": "a7e995c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_var_tt = ttl.tensor.Tensor(running_var_tilized, [1, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "id": "7b56ceb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[2, 1, 32, 32]"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images_tt.shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "id": "cd7f003d",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "TT_ASSERT @ libs/tt_dnn/op_library/eltwise_binary/multi_core/eltwise_binary_op_multi_core.cpp:27: src0_dram_buffer->size() == src1_dram_buffer->size()\ninfo:\nOperand to eltwise binary need to be the same size!\nbacktrace:\n --- tt::tt_metal::eltwise_binary(tt::tt_metal::Tensor const&, tt::tt_metal::Tensor const&, tt::tt_metal::BinaryOpType::Enum)\n --- /home/farbabi/git/tt-metal/libs/tt_lib/_C.so(+0x27be7) [0x7ff350e63be7]\n --- /home/farbabi/git/tt-metal/libs/tt_lib/_C.so(+0x5467a) [0x7ff350e9067a]\n --- /home/farbabi/git/tt-metal/libs/tt_lib/_C.so(+0x4da96) [0x7ff350e89a96]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(PyCFunction_Call+0x59) [0x5f6489]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyObject_MakeTpCall+0x296) [0x5f7056]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x5dae) [0x57107e]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalCodeWithName+0x26a) [0x569cea]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(PyEval_EvalCode+0x27) [0x68e7b7]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x601174]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x5c52f0]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x72d) [0x56b9fd]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x500a78]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x212d) [0x56d3fd]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x500a78]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x212d) [0x56d3fd]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x500a78]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x5047d6]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x90f) [0x56bbdf]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyFunction_Vectorcall+0x1b6) [0x5f6836]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x72d) [0x56b9fd]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyFunction_Vectorcall+0x1b6) [0x5f6836]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x90f) [0x56bbdf]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalCodeWithName+0x26a) [0x569cea]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyFunction_Vectorcall+0x393) [0x5f6a13]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x50b23c]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(PyObject_Call+0x62) [0x5f5c02]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x1f2c) [0x56d1fc]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalCodeWithName+0x26a) [0x569cea]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x50b2b0]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x1901) [0x56cbd1]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x500a78]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x212d) [0x56d3fd]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x500a78]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x212d) [0x56d3fd]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x500a78]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x212d) [0x56d3fd]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x500a78]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x212d) [0x56d3fd]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x500a78]\n --- /usr/lib/python3.8/lib-dynload/_asyncio.cpython-38-x86_64-linux-gnu.so(+0x7ef9) [0x7ff43e721ef9]\n --- /usr/lib/python3.8/lib-dynload/_asyncio.cpython-38-x86_64-linux-gnu.so(+0x9083) [0x7ff43e723083]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyObject_MakeTpCall+0x296) [0x5f7056]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x5ffd13]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x5c51d7]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(PyVectorcall_Call+0x58) [0x5f61c8]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x6647) [0x571917]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyFunction_Vectorcall+0x1b6) [0x5f6836]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x90f) [0x56bbdf]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyFunction_Vectorcall+0x1b6) [0x5f6836]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x90f) [0x56bbdf]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyFunction_Vectorcall+0x1b6) [0x5f6836]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x90f) [0x56bbdf]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyFunction_Vectorcall+0x1b6) [0x5f6836]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x90f) [0x56bbdf]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyFunction_Vectorcall+0x1b6) [0x5f6836]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x90f) [0x56bbdf]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalCodeWithName+0x26a) [0x569cea]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x50b2b0]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x57f2) [0x570ac2]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalCodeWithName+0x26a) [0x569cea]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(PyEval_EvalCode+0x27) [0x68e7b7]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x601174]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x5c52f0]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x72d) [0x56b9fd]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalCodeWithName+0x26a) [0x569cea]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyFunction_Vectorcall+0x393) [0x5f6a13]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x72d) [0x56b9fd]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalCodeWithName+0x26a) [0x569cea]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyFunction_Vectorcall+0x393) [0x5f6a13]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(PyObject_Call+0x62) [0x5f5c02]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x6b7e82]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(Py_RunMain+0x379) [0x6b8289]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(Py_BytesMain+0x2d) [0x6b84ad]\n --- /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x7ff44104b083]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_start+0x2e) [0x5fb39e]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[322], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m x_minus_mean \u001b[38;5;241m=\u001b[39m \u001b[43mttl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msub\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimages_tt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrunning_mean_tt\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: TT_ASSERT @ libs/tt_dnn/op_library/eltwise_binary/multi_core/eltwise_binary_op_multi_core.cpp:27: src0_dram_buffer->size() == src1_dram_buffer->size()\ninfo:\nOperand to eltwise binary need to be the same size!\nbacktrace:\n --- tt::tt_metal::eltwise_binary(tt::tt_metal::Tensor const&, tt::tt_metal::Tensor const&, tt::tt_metal::BinaryOpType::Enum)\n --- /home/farbabi/git/tt-metal/libs/tt_lib/_C.so(+0x27be7) [0x7ff350e63be7]\n --- /home/farbabi/git/tt-metal/libs/tt_lib/_C.so(+0x5467a) [0x7ff350e9067a]\n --- /home/farbabi/git/tt-metal/libs/tt_lib/_C.so(+0x4da96) [0x7ff350e89a96]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(PyCFunction_Call+0x59) [0x5f6489]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyObject_MakeTpCall+0x296) [0x5f7056]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x5dae) [0x57107e]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalCodeWithName+0x26a) [0x569cea]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(PyEval_EvalCode+0x27) [0x68e7b7]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x601174]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x5c52f0]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x72d) [0x56b9fd]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x500a78]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x212d) [0x56d3fd]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x500a78]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x212d) [0x56d3fd]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x500a78]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x5047d6]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x90f) [0x56bbdf]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyFunction_Vectorcall+0x1b6) [0x5f6836]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x72d) [0x56b9fd]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyFunction_Vectorcall+0x1b6) [0x5f6836]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x90f) [0x56bbdf]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalCodeWithName+0x26a) [0x569cea]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyFunction_Vectorcall+0x393) [0x5f6a13]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x50b23c]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(PyObject_Call+0x62) [0x5f5c02]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x1f2c) [0x56d1fc]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalCodeWithName+0x26a) [0x569cea]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x50b2b0]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x1901) [0x56cbd1]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x500a78]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x212d) [0x56d3fd]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x500a78]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x212d) [0x56d3fd]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x500a78]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x212d) [0x56d3fd]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x500a78]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x212d) [0x56d3fd]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x500a78]\n --- /usr/lib/python3.8/lib-dynload/_asyncio.cpython-38-x86_64-linux-gnu.so(+0x7ef9) [0x7ff43e721ef9]\n --- /usr/lib/python3.8/lib-dynload/_asyncio.cpython-38-x86_64-linux-gnu.so(+0x9083) [0x7ff43e723083]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyObject_MakeTpCall+0x296) [0x5f7056]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x5ffd13]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x5c51d7]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(PyVectorcall_Call+0x58) [0x5f61c8]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x6647) [0x571917]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyFunction_Vectorcall+0x1b6) [0x5f6836]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x90f) [0x56bbdf]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyFunction_Vectorcall+0x1b6) [0x5f6836]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x90f) [0x56bbdf]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyFunction_Vectorcall+0x1b6) [0x5f6836]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x90f) [0x56bbdf]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyFunction_Vectorcall+0x1b6) [0x5f6836]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x90f) [0x56bbdf]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyFunction_Vectorcall+0x1b6) [0x5f6836]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x90f) [0x56bbdf]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalCodeWithName+0x26a) [0x569cea]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x50b2b0]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x57f2) [0x570ac2]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalCodeWithName+0x26a) [0x569cea]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(PyEval_EvalCode+0x27) [0x68e7b7]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x601174]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x5c52f0]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x72d) [0x56b9fd]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalCodeWithName+0x26a) [0x569cea]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyFunction_Vectorcall+0x393) [0x5f6a13]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalFrameDefault+0x72d) [0x56b9fd]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyEval_EvalCodeWithName+0x26a) [0x569cea]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_PyFunction_Vectorcall+0x393) [0x5f6a13]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(PyObject_Call+0x62) [0x5f5c02]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8() [0x6b7e82]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(Py_RunMain+0x379) [0x6b8289]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(Py_BytesMain+0x2d) [0x6b84ad]\n --- /lib/x86_64-linux-gnu/libc.so.6(__libc_start_main+0xf3) [0x7ff44104b083]\n --- /home/farbabi/git/tt-metal/build/python_env/bin/python3.8(_start+0x2e) [0x5fb39e]\n"
     ]
    }
   ],
   "source": [
    "x_minus_mean = ttl.tensor.sub(images_tt, running_mean_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "id": "453c1193",
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum_torch = torch.tensor([[[W*[momentum]]]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "id": "a3cd6e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum_padded = pad_activation(momentum_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "id": "2e3ab60d",
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum_tilized = tilize_to_list(momentum_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "id": "7b8e30cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "momentum_tt = ttl.tensor.Tensor(momentum_tilized, [1, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "id": "d657e046",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_torch = torch.ones(1, 1, 1, W)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "id": "a7671f66",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_padded = pad_activation(one_torch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "id": "2b734189",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_tilized = tilize_to_list(one_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "id": "db8e1018",
   "metadata": {},
   "outputs": [],
   "source": [
    "one_tt = ttl.tensor.Tensor(one_tilized, [1, 1, H, W], ttl.tensor.DataType.BFLOAT16, ttl.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 310,
   "id": "0ad1dd0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean_left = ttl.tensor.mul(ttl.tensor.sub(one_tt, momentum_tt), running_mean_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "id": "346e0089",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean_right = ttl.tensor.mul(momentum_tt, mean_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "id": "67e00a4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean_tt_new = ttl.tensor.add(running_mean_left, running_mean_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "48c54c87",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean_tt_new_data = running_mean_tt_new.to(host).data()\n",
    "running_mean_tt_new_data = torch.Tensor(running_mean_tt_new_data).reshape((1,1,H,W))\n",
    "running_mean_tt_new_data = untilize(running_mean_tt_new_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 314,
   "id": "242c205f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2139,  0.0947, -0.0408,  0.2500,  0.2207,  0.1836,  0.1523,  0.2949,\n",
       "         0.1895,  0.0000,  0.0000,  0.0000])"
      ]
     },
     "execution_count": 314,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_mean_tt_new_data[0][0][0][0:12]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 315,
   "id": "2483a2e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 32, 32])"
      ]
     },
     "execution_count": 315,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 316,
   "id": "a2c2d57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "running_mean_new = (1.0 - momentum) * running_mean + momentum * mean_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 317,
   "id": "b9a333af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.2140,  0.0947, -0.0411,  0.2506,  0.2207,  0.1837,  0.1531,  0.2950,\n",
       "         0.1891], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 317,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "running_mean_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "id": "8105b937",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "mul(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: tt_lib.tensor.Tensor, arg1: tt_lib.tensor.Tensor) -> tt_lib.tensor.Tensor\n\nInvoked with: [0.8999999761581421, 1.0, 0.8899999856948853, 0.9200000166893005, 1.0, 1.0, 0.9599999785423279, 1.0, 0.9399999976158142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], <tt_lib.tensor.Tensor object at 0x7ff30fc3b8b0>",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[319], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m Y_tt \u001b[38;5;241m=\u001b[39mttl\u001b[38;5;241m.\u001b[39mtensor\u001b[38;5;241m.\u001b[39madd(\u001b[43mttl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmul\u001b[49m\u001b[43m(\u001b[49m\u001b[43mgamma_tt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvar_plus_eps\u001b[49m\u001b[43m)\u001b[49m, beta_tt)\n",
      "\u001b[0;31mTypeError\u001b[0m: mul(): incompatible function arguments. The following argument types are supported:\n    1. (arg0: tt_lib.tensor.Tensor, arg1: tt_lib.tensor.Tensor) -> tt_lib.tensor.Tensor\n\nInvoked with: [0.8999999761581421, 1.0, 0.8899999856948853, 0.9200000166893005, 1.0, 1.0, 0.9599999785423279, 1.0, 0.9399999976158142, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0], <tt_lib.tensor.Tensor object at 0x7ff30fc3b8b0>"
     ]
    }
   ],
   "source": [
    "Y_tt =ttl.tensor.add(ttl.tensor.mul(gamma_tt, var_plus_eps), beta_tt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf1f430",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcd789be",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e5e3e0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75223848",
   "metadata": {},
   "outputs": [],
   "source": [
    "#epsilon_tor = torch.zeros(1, 1, 32, bn_size)\n",
    "#epsilon_tor[:, :, :1, :] = epsilon_torch\n",
    "tilized_eps_tt= tilize_to_list(epsilon_tor)\n",
    "eps_tt = ttl.tensor.Tensor(tilized_eps_tt, [1, 1, 32, bn_size], ttl.tensor.DataType.BFLOAT16,ttl.tensor.Layout.TILE, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be32516b",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_hat = ttl.tensor.sub(images - mean_tt) / torch.sqrt(var_tt + eps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c39c41d9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b42a53d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43b51596",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_torch = images.mean(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf57cf5",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafd4700",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1f73a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "x_minus_mean = tensor.bcast(x, means, BCSUB, BCW) # need to blank out the H for non-multiple of 32\n",
    "if False and refx is not None:\n",
    "    ry, rmean, rvar, rstd, rinvstd, ry1 = ref_ln(refx, refgamma, refbeta)\n",
    "\n",
    "var = tensor.mul(x_minus_mean, x_minus_mean) # (x-m)^2\n",
    "var_redW = tensor.reduce(var, RSUM, RW, 1.0) # sum[(x-m)^2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d4524",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

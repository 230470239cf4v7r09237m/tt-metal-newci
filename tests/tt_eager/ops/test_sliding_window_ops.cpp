// SPDX-FileCopyrightText: Â© 2024 Tenstorrent Inc.
//
// SPDX-License-Identifier: Apache-2.0

#include <tuple>

#include "tensor/host_buffer/functions.hpp"
#include "tensor/host_buffer/types.hpp"
#include "tensor/tensor.hpp"
#include "tt_dnn/op_library/sliding_window_op_infra/reference_sliding_window.hpp"
#include "tt_eager/tensor/tensor.hpp"
#include "tt_metal/host_api.hpp"
#include "tt_numpy/functions.hpp"

using tt::tt_metal::Shape;
using tt::tt_metal::Tensor;
using tt::tt_metal::sliding_window::ConvUsingOpTraceMetadata;
using tt::tt_metal::sliding_window::ConvUsingShardBoundaries;
using tt::tt_metal::sliding_window::ConvUsingSlidingWindowOpConfig;
using tt::tt_metal::sliding_window::InputIndicesFromFlattenedLocalConfig;
using tt::tt_metal::sliding_window::InputIndicesFromFlattenedRemoteConfig;
using tt::tt_metal::sliding_window::PadIndicesFromFlattenedPadConfig;
using tt::tt_metal::sliding_window::PadMetadataFromTensorMetadata;
using tt::tt_metal::sliding_window::RefConvOp;

// From owned_buffer of type bfloat16 of create float vector for convolution operation.
vector<float> CreateFilterVec(const owned_buffer::Buffer<bfloat16> &filter_tensor_buf, uint32_t filter_h, uint32_t filter_w) {
    vector<float> filter_vector;
    for (auto h = 0; h < filter_h; h++) {
        for (auto w = 0; w < filter_w; w++) {
            filter_vector.push_back(filter_tensor_buf[h * filter_w + w].to_float());
        }
    }
    return filter_vector;
}

// Compare calculated convolution buffer with Golden convolution
uint32_t CompareOutwithGolden(
    const owned_buffer::Buffer<bfloat16> &out_golden_tensor_buf,
    const owned_buffer::Buffer<bfloat16> &conv_tensor_buf) {
    uint32_t diff = 0;
    if (out_golden_tensor_buf != conv_tensor_buf) {
        assert(out_golden_tensor_buf.size() == conv_tensor_buf.size());
        for (uint32_t i = 0; i < out_golden_tensor_buf.size(); i++) {
            if (out_golden_tensor_buf[i] != conv_tensor_buf[i]) {
                log_info(
                    tt::LogTest,
                    "Error at i = {}, Golden = {}, Calculated = {}",
                    i,
                    out_golden_tensor_buf[i].to_float(),
                    conv_tensor_buf[i].to_float());
                diff++;
            }
        }
    }
    return diff;
}

// Validate Flattened_* configs generated by generate_halo_kernel_config_tensors using pad_metadata.
// It is ok to use pad_metadata since its correctness is validated in other test cases.
uint32_t ValidateGenerateHaloKernelConfig(
    tt::tt_metal::Device *device,
    const vector<std::pair<uint32_pair_t, uint32_pair_t>> &shard_boundaries,
    const tuple<vector<vector<uint16_t>>, vector<vector<uint16_t>>, vector<vector<uint16_t>>, uint32_t>
        &halo_kernel_config,
    const vector<bool> &pad_metadata,
    bool remote_read = false,
    bool is_block_sharded = false,
    bool transpose_mcast = false) {
    auto [flattened_pad_config, flattened_local_config, flattened_remote_config, max_out_n_sticks_per_core] =
        halo_kernel_config;

    uint32_t padded_input_tensor_buf_idx = 0;
    uint32_t invalid_pads = 0, invalid_indices = 0;
    uint32_t failed_tests = 0;

    auto find_invalids = [&](vector<uint16_t> &indices, bool val) -> int {
        auto invalids = 0;
        for (auto idx : indices) {
            if (pad_metadata[idx] != val) {
                invalids++;
                log_info(
                    tt::LogTest, "Error at index = {}, Expected = {}, Calculated = {}", idx, val, pad_metadata[idx]);
            }
        }
        return invalids;
    };

    auto pad_indices = PadIndicesFromFlattenedPadConfig(flattened_pad_config, shard_boundaries);
    invalid_pads = find_invalids(pad_indices, true);
    if (invalid_pads != 0) {
        log_error(
            tt::LogTest,
            "Failed to validate flattened_pad_config of halo_kernel_config, invalid pads = {}",
            invalid_pads);
        failed_tests++;
    }

    auto local_indices = InputIndicesFromFlattenedLocalConfig(flattened_local_config, shard_boundaries);
    invalid_indices = find_invalids(local_indices, false);
    if (invalid_indices != 0) {
        log_error(
            tt::LogTest,
            "Failed to validate flattened_local_config of halo_kernel_config, invalid indices = {}",
            invalid_indices);
        failed_tests++;
    }
    auto remote_indices = InputIndicesFromFlattenedRemoteConfig(
        device, flattened_remote_config, shard_boundaries, remote_read, is_block_sharded, transpose_mcast);
    invalid_indices = find_invalids(remote_indices, false);
    if (invalid_indices != 0) {
        log_error(
            tt::LogTest,
            "Failed to validate flattened_remote_config of halo_kernel_config, invalid indices = {}",
            invalid_indices);
        failed_tests++;
    }

    return failed_tests;
}

// Validate
// 1) various generate_* functions using reference convolution and convolution Calculated
// using outputs of these generate functions.
// 2) halo kernel configs using pad_metadata
uint32_t ValidateGenerateFunctions(
    tt::tt_metal::Device *device,
    const SlidingWindowConfig &config,
    const owned_buffer::Buffer<bfloat16> &input_padded_tensor_buf,
    const vector<float> &filter_vector,
    const owned_buffer::Buffer<bfloat16> &out_golden_tensor_buf,
    uint32_t reshard_num_cores_nhw = 0,
    bool remote_read = false) {
    owned_buffer::Buffer<bfloat16> conv_tensor_buf;
    uint32_t diff;
    uint32_t failed_tests = 0;
    auto pad_metadata = sliding_window::generate_pad_metadata(config);
    auto tensor_metadata = sliding_window::generate_tensor_metadata(pad_metadata, config, reshard_num_cores_nhw);
    auto op_trace_metadata = sliding_window::generate_op_trace_metadata(config);
    auto shard_boundaries = sliding_window::generate_shard_boundaries(config, op_trace_metadata);
    auto sharded_input_top_left_indices =
        sliding_window::generate_sliding_window_op_config(op_trace_metadata, shard_boundaries, false, false);
    auto halo_kernel_config = sliding_window::generate_halo_kernel_config_tensors(
        tensor_metadata, shard_boundaries, false, false, remote_read, device);

    auto [filter_h, filter_w] = config.window_hw_;
    auto [input_h, input_w] = config.input_hw_;
    auto [stride_h, stride_w] = config.stride_hw_;
    auto output_shape = config.get_output_shape();
    uint32_t output_n, output_h, output_w;
    std::tie(output_n, output_h, output_w) = std::tie(output_shape[0], output_shape[1], output_shape[2]);

    uint32_t padded_input_h = input_h + 2 * config.pad_hw_.first;
    uint32_t padded_input_w = input_w + 2 * config.pad_hw_.second;

    auto ref_pad_metadata = PadMetadataFromTensorMetadata(tensor_metadata);
    if (ref_pad_metadata != pad_metadata) {
        for (auto i = 0; i < ref_pad_metadata.size(); i++) {
            if (ref_pad_metadata[i] != pad_metadata[i])
                log_info(tt::LogTest, "Error at i = {}, Calculated = {}", i, ref_pad_metadata[i]);
        }
        log_error(
            tt::LogTest,
            "Failed to validate generate_tensor_metadata, convolution calculated with op_trace_metadata differs at "
            "locations = {}",
            diff);
        failed_tests++;
    }

    conv_tensor_buf = ConvUsingOpTraceMetadata(
        input_padded_tensor_buf,
        filter_vector,
        op_trace_metadata,
        stride_h,
        stride_w,
        filter_h,
        filter_w,
        padded_input_w,
        out_golden_tensor_buf.size());
    diff = CompareOutwithGolden(out_golden_tensor_buf, conv_tensor_buf);
    if (diff) {
        log_error(
            tt::LogTest,
            "Failed to validate generate_tensor_metadata, convolution calculated with op_trace_metadata differs at "
            "locations = {}",
            diff);
        failed_tests++;
    }

    conv_tensor_buf = ConvUsingShardBoundaries(
        input_padded_tensor_buf,
        filter_vector,
        shard_boundaries,
        input_h,
        input_w,
        stride_h,
        stride_w,
        padded_input_h,
        padded_input_w,
        filter_h,
        filter_w,
        output_h,
        output_w,
        out_golden_tensor_buf.size());
    diff = CompareOutwithGolden(out_golden_tensor_buf, conv_tensor_buf);
    if (diff) {
        log_error(
            tt::LogTest,
            "Failed to validate generate_shard_boundaries, convolution calculated with op_trace_metadata differs at "
            "locations = {}",
            diff);
        failed_tests++;
    }

    conv_tensor_buf = ConvUsingSlidingWindowOpConfig(
        input_padded_tensor_buf,
        filter_vector,
        op_trace_metadata,
        shard_boundaries,
        sharded_input_top_left_indices,
        input_h,
        input_w,
        stride_h,
        stride_w,
        padded_input_w,
        filter_h,
        filter_w,
        out_golden_tensor_buf.size());
    diff = CompareOutwithGolden(out_golden_tensor_buf, conv_tensor_buf);
    if (diff) {
        log_error(
            tt::LogTest,
            "Failed to validate generate_sliding_window_op_config, convolution calculated with op_trace_metadata "
            "differs at locations = {}",
            diff);
        failed_tests++;
    }
    failed_tests +=
        ValidateGenerateHaloKernelConfig(device, shard_boundaries, halo_kernel_config, pad_metadata, remote_read);
    return failed_tests;
}

// Container for testcase configurations
struct testcase_config {
    uint32_t batch_size;
    uint32_t input_h, input_w;
    uint32_t filter_h, filter_w;
    uint32_t stride_h, stride_w;
    uint32_t pad_h, pad_w;
    uint32_t dilation_h, dilation_w;
    uint32_t num_cores_nhw;
    uint32_t reshard_num_cores_nhw;
    bool remote_read;
};

// Test cases
vector<struct testcase_config> configs = {
    {2, 5, 5, 3, 3, 1, 1, 1, 1, 1, 1, 2, 0, false},
    {2, 5, 5, 3, 3, 2, 2, 1, 1, 1, 1, 1, 4, true},
    {2, 10, 10, 7, 7, 4, 4, 3, 3, 1, 1, 4, 5, false},
    {7, 64, 64, 13, 13, 2, 2, 6, 6, 1, 1, 5, 4, true},
};

int main() {
    int device_id = 0;
    auto device = tt::tt_metal::CreateDevice(device_id);

    log_info(tt::LogTest, "Tests for Sliding window metadata calcations starts");
    for (auto tc : configs) {
        SlidingWindowConfig config = SlidingWindowConfig(
            tc.batch_size,
            tc.input_h,
            tc.input_w,
            tc.filter_h,
            tc.filter_w,
            tc.stride_h,
            tc.stride_w,
            tc.pad_h,
            tc.pad_w,
            tc.dilation_h,
            tc.dilation_w,
            tc.num_cores_nhw);
        Shape input_tensor_shape = {
            config.batch_size_,
            config.input_hw_.first + 2 * config.pad_hw_.first,
            config.input_hw_.second + 2 * config.pad_hw_.second};
        Shape output_tensor_shape = config.get_output_shape();
        Shape filter_tensor_shape = {config.window_hw_.first, config.window_hw_.second};

        Tensor input_padded_tensor =
            tt::numpy::random::random(input_tensor_shape, DataType::BFLOAT16).to(Layout::ROW_MAJOR).cpu();
        Tensor filter_tensor =
            tt::numpy::random::random(filter_tensor_shape, DataType::BFLOAT16).to(Layout::ROW_MAJOR).cpu();
        auto input_padded_tensor_buf = owned_buffer::get_as<bfloat16>(input_padded_tensor);
        auto filter_tensor_buf = owned_buffer::get_as<bfloat16>(filter_tensor);

        vector<float> filter_vector = CreateFilterVec(filter_tensor_buf, tc.filter_h, tc.filter_w);
        owned_buffer::Buffer<bfloat16> out_golden_tensor_buf = RefConvOp(
            input_padded_tensor,
            input_tensor_shape,
            tc.stride_h,
            tc.stride_w,
            filter_vector,
            filter_tensor_shape,
            output_tensor_shape);

        auto failed_tests = ValidateGenerateFunctions(
            device,
            config,
            input_padded_tensor_buf,
            filter_vector,
            out_golden_tensor_buf,
            tc.reshard_num_cores_nhw,
            tc.remote_read);
        if (failed_tests) {
            log_error(
                tt::LogTest,
                "Tests({}) failed for config ({}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {}, {})",
                failed_tests,
                tc.batch_size,
                tc.input_h,
                tc.input_w,
                tc.filter_h,
                tc.filter_w,
                tc.stride_h,
                tc.stride_w,
                tc.pad_h,
                tc.pad_w,
                tc.dilation_h,
                tc.dilation_w,
                tc.num_cores_nhw,
                tc.reshard_num_cores_nhw,
                tc.remote_read);
            TT_THROW("Tests Falied");
        } else {
            log_info(tt::LogTest, "Tests Passed");
        }
    }
    log_info(tt::LogTest, "Tests for Sliding window metadata calcations ends");
    TT_FATAL(tt::tt_metal::CloseDevice(device));
    return 0;
}
